{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broken-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import floor\n",
    "\n",
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../src')\n",
    "from legacy_metrics import *\n",
    "\n",
    "from pandas.core.common import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobidb-pdb_cnn_11_3_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Label, batch, and pad protein sequence data.\n",
    "\n",
    "    Only complete batches are returned, so a single epoch may not train on every example.\"\"\"\n",
    "    def __init__(self, records, batch_size, sym_codes, shuffle=True):\n",
    "        self.records = records\n",
    "        self.indices = np.arange(len(self.records))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.ctable = {}  # Category table\n",
    "        for i, sym_code in enumerate(sym_codes):\n",
    "            self.ctable[sym_code] = i\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of batches.\"\"\"\n",
    "        return floor(len(self.records) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        records = [self.records[i] for i in indices]\n",
    "        max_len = max([len(record[0]) for record in records])\n",
    "        x = np.zeros((self.batch_size, max_len))\n",
    "        y = np.zeros((self.batch_size, max_len))\n",
    "        for i, (syms, labels) in enumerate(records):\n",
    "            x[i, :len(syms)] = [self.ctable.get(sym, 0) for sym in syms]\n",
    "            y[i, :len(syms)] = [int(label) if label in [\"0\", \"1\"] else 2 for label in labels]\n",
    "            \n",
    "        sample_weights = np.ones((self.batch_size, max_len))\n",
    "        sample_weights[y == 1] = 15.0\n",
    "        sample_weights[y == 2] = 0.0\n",
    "\n",
    "        x = keras.utils.to_categorical(x, num_classes=len(self.ctable))\n",
    "        y = keras.utils.to_categorical(y, num_classes=3)\n",
    "        for i, (syms, _) in enumerate(records):\n",
    "            x[i, len(syms):, :] = 0\n",
    "            y[i, len(syms):, :] = 0\n",
    "        \n",
    "        return x, y, sample_weights\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffles data after each epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "searching-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seqs_path, labels_path):\n",
    "    # Load files\n",
    "    seqs = {}\n",
    "    for record in SeqIO.parse(seqs_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        seq = str(record.seq)\n",
    "        seqs[accession] = seq\n",
    "    labels = {}\n",
    "    for record in SeqIO.parse(labels_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        label = str(record.seq)\n",
    "        labels[accession] = label\n",
    "\n",
    "    # Bundle seqs and labels into single object\n",
    "    records = []\n",
    "    for accession, seq in seqs.items():\n",
    "        records.append((seq, labels[accession]))\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eastern-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sym(batch, sym_codes):\n",
    "    \"\"\"Decodes residue symbols in batch of proteins from encoded form.\"\"\"\n",
    "    ctable, i = {}, 0\n",
    "    for sym_code in sym_codes:\n",
    "        ctable[i] = sym_code\n",
    "        i += 1\n",
    "\n",
    "    decoded_sym = []\n",
    "    for protein in batch:\n",
    "        decoded_protein = []\n",
    "        for residue in protein:\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = ctable[np.argmax(residue)]\n",
    "                decoded_protein.append(decoded_residue)\n",
    "        decoded_sym.append(\"\".join(decoded_protein))\n",
    "\n",
    "    return decoded_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suspended-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label_by_protein(batch_to_be_decoded, original_batch):\n",
    "    \"\"\"\n",
    "    Decodes residue labels in batch of proteins from encoded form.\n",
    "    Outputs list of str where each str is labels of one protein.\n",
    "\n",
    "    batch_to_be_decoded:\n",
    "    batch of labels which want to be decoded\n",
    "\n",
    "    original_batch:\n",
    "    original batch of labels generated by BatchGenerator which\n",
    "    batch_to_be_decoded is derived from (this is needed in order\n",
    "    to remove unwanted masked values)\n",
    "    \"\"\"\n",
    "    decoded_labels = []\n",
    "    for x in np.arange(len(original_batch)):\n",
    "        protein = original_batch[x]\n",
    "        decoded_protein = []\n",
    "        for y in np.arange(len(protein)):\n",
    "            residue = protein[y]\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = np.argmax(batch_to_be_decoded[x][y])\n",
    "                if decoded_residue == 2:\n",
    "                    decoded_protein.append(\"-\")\n",
    "                else:\n",
    "                    decoded_protein.append(str(decoded_residue))\n",
    "        decoded_labels.append(\"\".join(decoded_protein))\n",
    "    return decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adolescent-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label_to_lst(batch_to_be_decoded, original_batch):\n",
    "    \"\"\"\n",
    "    Decodes residue labels in batch of proteins from encoded form.\n",
    "    Outputs list of int where each int is label for one residue.\n",
    "    Does not include residues labeled \"-\" in output.\n",
    "\n",
    "    batch_to_be_decoded:\n",
    "    batch of labels which want to be decoded\n",
    "\n",
    "    original_batch:\n",
    "    original batch of labels generated by BatchGenerator which\n",
    "    batch_to_be_decoded is derived from (this is needed in order\n",
    "    to remove unwanted masked values)\n",
    "    \"\"\"\n",
    "    decoded_labels = []\n",
    "    for x in np.arange(len(original_batch)):\n",
    "        protein = original_batch[x]\n",
    "        for y in np.arange(len(protein)):\n",
    "            residue = protein[y]\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            elif np.argmax(residue) == 2:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = np.argmax(batch_to_be_decoded[x][y])\n",
    "                decoded_labels.append(decoded_residue)\n",
    "                    \n",
    "    return decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "early-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv1D(keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(filters, kernel_size, **kwargs)\n",
    "        self.supports_masking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "described-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "understood-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_records = load_data('../../mobidb-pdb_validation/split_data/out/train_seqs.fasta', '../../mobidb-pdb_validation/split_data/out/train_labels.fasta')\n",
    "validation_records = load_data('../../mobidb-pdb_validation/split_data/out/validation_seqs.fasta', '../../mobidb-pdb_validation/split_data/out/validation_labels.fasta')\n",
    "test_records = load_data('../../mobidb-pdb_validation/split_data/out/test_seqs.fasta', '../../mobidb-pdb_validation/split_data/out/test_labels.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "obvious-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch data\n",
    "train_batches = BatchGenerator(train_records, 32, sym_codes)\n",
    "validation_batches = BatchGenerator(validation_records, 32, sym_codes)\n",
    "test_batches = BatchGenerator(test_records, 32, sym_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharp-blanket",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: out_model/mobidb-pdb_cnn_11_3_2.h5\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a823ac0a5c72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"out_model/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"MaskedConv1D\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMaskedConv1D\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    119\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: out_model/mobidb-pdb_cnn_11_3_2.h5\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"out_model/\" + model_name + \".h5\", custom_objects={\"MaskedConv1D\": MaskedConv1D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv (\"out_metrics/training_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-lecture",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy = (metrics_df[\"Sensitivity\"].values[49]+metrics_df[\"Specificity\"].values[49])/2\n",
    "balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-synthetic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_axis_ticks = np.arange(100)\n",
    "y_axis_ticks = np.arange(11)/10\n",
    "\n",
    "metrics_fig = metrics_df.plot(figsize = (12, 5), use_index = True, title = model_name + \" training metrics\", \n",
    "                              xticks = x_axis_ticks, yticks = y_axis_ticks)\n",
    "\n",
    "metrics_fig = metrics_fig.legend(bbox_to_anchor=(1, 1))\n",
    "metrics_fig = metrics_fig.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-outreach",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
