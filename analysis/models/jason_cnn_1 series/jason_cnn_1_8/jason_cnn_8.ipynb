{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decrease number of nodes even more\n",
    "\n",
    "import os\n",
    "from math import floor\n",
    "\n",
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Label, batch, and pad protein sequence data.\n",
    "\n",
    "    Only complete batches are returned, so a single epoch may not train on every example.\"\"\"\n",
    "    def __init__(self, records, batch_size, sym_codes, shuffle=True):\n",
    "        self.records = records\n",
    "        self.indices = np.arange(len(self.records))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.ctable = {}  # Category table\n",
    "        for i, sym_code in enumerate(sym_codes):\n",
    "            self.ctable[sym_code] = i\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of batches.\"\"\"\n",
    "        return floor(len(self.records) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        records = [self.records[i] for i in indices]\n",
    "        max_len = max([len(record[0]) for record in records])\n",
    "        x = np.zeros((self.batch_size, max_len))\n",
    "        y = np.zeros((self.batch_size, max_len))\n",
    "        for i, (syms, labels) in enumerate(records):\n",
    "            x[i, :len(syms)] = [self.ctable.get(sym, 0) for sym in syms]\n",
    "            y[i, :len(syms)] = [int(label) for label in labels]\n",
    "\n",
    "        x = keras.utils.to_categorical(x, num_classes=len(self.ctable))\n",
    "        y = keras.utils.to_categorical(y, num_classes=2)\n",
    "        for i, (syms, _) in enumerate(records):\n",
    "            x[i, len(syms):, :] = 0\n",
    "            y[i, len(syms):, :] = 0\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffles data after each epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def load_data(seqs_path, labels_path):\n",
    "    # Load files\n",
    "    seqs = {}\n",
    "    for record in SeqIO.parse(seqs_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        seq = str(record.seq)\n",
    "        seqs[accession] = seq\n",
    "    labels = {}\n",
    "    for record in SeqIO.parse(labels_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        label = str(record.seq)\n",
    "        labels[accession] = label\n",
    "\n",
    "    # Bundle seqs and labels into single object\n",
    "    records = []\n",
    "    for accession, seq in seqs.items():\n",
    "        records.append((seq, labels[accession]))\n",
    "\n",
    "    return records\n",
    "\n",
    "def decode(x, sym_codes):\n",
    "    \"\"\"Decodes a vector of indices to their amino acid symbols.\"\"\"\n",
    "    ctable, i = {0: 'X'}, 1\n",
    "    for sym_code in sym_codes:\n",
    "        ctable[i] = sym_code\n",
    "        i += 1\n",
    "    records = []\n",
    "    for indices in x:\n",
    "        syms = [ctable[index] for index in indices]\n",
    "        records.append(''.join(syms))\n",
    "    return records\n",
    "\n",
    "class MaskedConv1D(keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(filters, kernel_size, **kwargs)\n",
    "        self.supports_masking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "found-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sublime-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_records = load_data('../../mobidb_validation/split_data/out/train_as_fasta.fasta', '../../mobidb_validation/split_data/out/train_labels_as_fasta.fasta')\n",
    "validation_records = load_data('../../mobidb_validation/split_data/out/val_as_fasta.fasta', '../../mobidb_validation/split_data/out/val_labels_as_fasta.fasta')\n",
    "test_records = load_data('../../mobidb_validation/split_data/out/test_as_fasta.fasta', '../../mobidb_validation/split_data/out/test_labels_as_fasta.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch data\n",
    "train_batches = BatchGenerator(train_records, 32, sym_codes)\n",
    "validation_batches = BatchGenerator(validation_records, 1, sym_codes)\n",
    "test_batches = BatchGenerator(test_records, 1, sym_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "living-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"jason_cnn_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          [(None, None, 20)]        0         \n",
      "_________________________________________________________________\n",
      "mask1 (Masking)              (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv1d1 (MaskedConv1D)       (None, None, 32)          12832     \n",
      "_________________________________________________________________\n",
      "conv1d2 (MaskedConv1D)       (None, None, 32)          20512     \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, None, 2)           66        \n",
      "=================================================================\n",
      "Total params: 33,410\n",
      "Trainable params: 33,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "inputs = keras.layers.Input(shape=(None, 20), name='input1')\n",
    "x = layers.Masking(mask_value=0, name='mask1')(inputs)\n",
    "x = MaskedConv1D(32, 20, padding='same', activation='relu', name='conv1d1')(x)\n",
    "x = MaskedConv1D(32, 20, padding='same', activation='relu', name='conv1d2')(x)\n",
    "outputs = layers.Dense(2, activation='softmax', name='dense1')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"jason_cnn_8\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italic-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0577 - binary_accuracy: 0.9376\n",
      "LABEL ACCURACY: 0.9307718577280212\n",
      "\n",
      "EPOCH 1\n",
      "543/543 [==============================] - 88s 162ms/step - loss: 0.0546 - binary_accuracy: 0.9384\n",
      "LABEL ACCURACY: 0.9307718577280212\n",
      "\n",
      "EPOCH 2\n",
      "543/543 [==============================] - 87s 161ms/step - loss: 0.0548 - binary_accuracy: 0.9385\n",
      "LABEL ACCURACY: 0.9307718577280212\n",
      "\n",
      "EPOCH 3\n",
      "543/543 [==============================] - 87s 160ms/step - loss: 0.0535 - binary_accuracy: 0.9385\n",
      "LABEL ACCURACY: 0.930770903804438\n",
      "\n",
      "EPOCH 4\n",
      "543/543 [==============================] - 90s 165ms/step - loss: 0.0538 - binary_accuracy: 0.9384\n",
      "LABEL ACCURACY: 0.9307098526951203\n",
      "\n",
      "EPOCH 5\n",
      "543/543 [==============================] - 86s 157ms/step - loss: 0.0543 - binary_accuracy: 0.9385\n",
      "LABEL ACCURACY: 0.9306869585291262\n",
      "\n",
      "EPOCH 6\n",
      "543/543 [==============================] - 84s 155ms/step - loss: 0.0544 - binary_accuracy: 0.9384\n",
      "LABEL ACCURACY: 0.9306144603368114\n",
      "\n",
      "EPOCH 7\n",
      "543/543 [==============================] - 86s 159ms/step - loss: 0.0531 - binary_accuracy: 0.9385\n",
      "LABEL ACCURACY: 0.9304465697861876\n",
      "\n",
      "EPOCH 8\n",
      "543/543 [==============================] - 84s 155ms/step - loss: 0.0524 - binary_accuracy: 0.9384\n",
      "LABEL ACCURACY: 0.9306154142603944\n",
      "\n",
      "EPOCH 9\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0522 - binary_accuracy: 0.9384\n",
      "LABEL ACCURACY: 0.9302328909035755\n",
      "\n",
      "EPOCH 10\n",
      "543/543 [==============================] - 86s 158ms/step - loss: 0.0522 - binary_accuracy: 0.9386\n",
      "LABEL ACCURACY: 0.9304608786399339\n",
      "\n",
      "EPOCH 11\n",
      "543/543 [==============================] - 144s 265ms/step - loss: 0.0522 - binary_accuracy: 0.9387\n",
      "LABEL ACCURACY: 0.9304246295437765\n",
      "\n",
      "EPOCH 12\n",
      "543/543 [==============================] - 89s 165ms/step - loss: 0.0519 - binary_accuracy: 0.9386\n",
      "LABEL ACCURACY: 0.9301031572962754\n",
      "\n",
      "EPOCH 13\n",
      "543/543 [==============================] - 89s 164ms/step - loss: 0.0512 - binary_accuracy: 0.9387\n",
      "LABEL ACCURACY: 0.9304952198889251\n",
      "\n",
      "EPOCH 14\n",
      "543/543 [==============================] - 88s 161ms/step - loss: 0.0516 - binary_accuracy: 0.9387\n",
      "LABEL ACCURACY: 0.9300268434096282\n",
      "\n",
      "EPOCH 15\n",
      "543/543 [==============================] - 85s 157ms/step - loss: 0.0511 - binary_accuracy: 0.9387\n",
      "LABEL ACCURACY: 0.9304675561050155\n",
      "\n",
      "EPOCH 16\n",
      "543/543 [==============================] - 123s 227ms/step - loss: 0.0504 - binary_accuracy: 0.9389\n",
      "LABEL ACCURACY: 0.9289298312890751\n",
      "\n",
      "EPOCH 17\n",
      "543/543 [==============================] - 126s 233ms/step - loss: 0.0501 - binary_accuracy: 0.9389\n",
      "LABEL ACCURACY: 0.9301079269141908\n",
      "\n",
      "EPOCH 18\n",
      "543/543 [==============================] - 112s 206ms/step - loss: 0.0497 - binary_accuracy: 0.9388\n",
      "LABEL ACCURACY: 0.9304904502710097\n",
      "\n",
      "EPOCH 19\n",
      "543/543 [==============================] - 91s 167ms/step - loss: 0.0486 - binary_accuracy: 0.9392\n",
      "LABEL ACCURACY: 0.9298141184505991\n",
      "\n",
      "EPOCH 20\n",
      "543/543 [==============================] - 91s 168ms/step - loss: 0.0496 - binary_accuracy: 0.9391\n",
      "LABEL ACCURACY: 0.9301441760103482\n",
      "\n",
      "EPOCH 21\n",
      "543/543 [==============================] - 88s 163ms/step - loss: 0.0499 - binary_accuracy: 0.9391\n",
      "LABEL ACCURACY: 0.9289393705249059\n",
      "\n",
      "EPOCH 22\n",
      "543/543 [==============================] - 88s 162ms/step - loss: 0.0495 - binary_accuracy: 0.9394\n",
      "LABEL ACCURACY: 0.9296004395679871\n",
      "\n",
      "EPOCH 23\n",
      "543/543 [==============================] - 84s 155ms/step - loss: 0.0493 - binary_accuracy: 0.9393\n",
      "LABEL ACCURACY: 0.9298389204637595\n",
      "\n",
      "EPOCH 24\n",
      "543/543 [==============================] - 84s 154ms/step - loss: 0.0484 - binary_accuracy: 0.9394\n",
      "LABEL ACCURACY: 0.9292827830148183\n",
      "\n",
      "EPOCH 25\n",
      "543/543 [==============================] - 86s 158ms/step - loss: 0.0483 - binary_accuracy: 0.9393\n",
      "LABEL ACCURACY: 0.9292617966959903\n",
      "\n",
      "EPOCH 26\n",
      "543/543 [==============================] - 85s 157ms/step - loss: 0.0490 - binary_accuracy: 0.9395\n",
      "LABEL ACCURACY: 0.9292513035365763\n",
      "\n",
      "EPOCH 27\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0493 - binary_accuracy: 0.9396\n",
      "LABEL ACCURACY: 0.9297149103979578\n",
      "\n",
      "EPOCH 28\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0482 - binary_accuracy: 0.9396\n",
      "LABEL ACCURACY: 0.9300707238944502\n",
      "\n",
      "EPOCH 29\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0483 - binary_accuracy: 0.9397\n",
      "LABEL ACCURACY: 0.929333340964722\n",
      "\n",
      "EPOCH 30\n",
      "543/543 [==============================] - 84s 154ms/step - loss: 0.0485 - binary_accuracy: 0.9398\n",
      "LABEL ACCURACY: 0.9275046694559392\n",
      "\n",
      "EPOCH 31\n",
      "543/543 [==============================] - 85s 157ms/step - loss: 0.0479 - binary_accuracy: 0.9398\n",
      "LABEL ACCURACY: 0.9284347449494516\n",
      "\n",
      "EPOCH 32\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0492 - binary_accuracy: 0.9399\n",
      "LABEL ACCURACY: 0.9288716419505066\n",
      "\n",
      "EPOCH 33\n",
      "543/543 [==============================] - 84s 155ms/step - loss: 0.0482 - binary_accuracy: 0.9400\n",
      "LABEL ACCURACY: 0.9286808572338887\n",
      "\n",
      "EPOCH 34\n",
      "543/543 [==============================] - 85s 157ms/step - loss: 0.0487 - binary_accuracy: 0.9399\n",
      "LABEL ACCURACY: 0.9279272576032479\n",
      "\n",
      "EPOCH 35\n",
      "543/543 [==============================] - 107s 196ms/step - loss: 0.0486 - binary_accuracy: 0.9399\n",
      "LABEL ACCURACY: 0.9282182042960903\n",
      "\n",
      "EPOCH 36\n",
      "543/543 [==============================] - 105s 194ms/step - loss: 0.0477 - binary_accuracy: 0.9399\n",
      "LABEL ACCURACY: 0.9295985317208209\n",
      "\n",
      "EPOCH 37\n",
      "543/543 [==============================] - 112s 207ms/step - loss: 0.0484 - binary_accuracy: 0.9403\n",
      "LABEL ACCURACY: 0.9260957243237159\n",
      "\n",
      "EPOCH 38\n",
      "543/543 [==============================] - 106s 195ms/step - loss: 0.0479 - binary_accuracy: 0.9401\n",
      "LABEL ACCURACY: 0.9272671424837499\n",
      "\n",
      "EPOCH 39\n",
      "543/543 [==============================] - 108s 198ms/step - loss: 0.0479 - binary_accuracy: 0.9403\n",
      "LABEL ACCURACY: 0.9284051733183758\n",
      "\n",
      "EPOCH 40\n",
      "543/543 [==============================] - 89s 163ms/step - loss: 0.0481 - binary_accuracy: 0.9401\n",
      "LABEL ACCURACY: 0.9286541473735622\n",
      "\n",
      "EPOCH 41\n",
      "543/543 [==============================] - 87s 161ms/step - loss: 0.0479 - binary_accuracy: 0.9402\n",
      "LABEL ACCURACY: 0.9281752777348512\n",
      "\n",
      "EPOCH 42\n",
      "543/543 [==============================] - 88s 162ms/step - loss: 0.0480 - binary_accuracy: 0.9403\n",
      "LABEL ACCURACY: 0.9283555692920552\n",
      "\n",
      "EPOCH 43\n",
      "543/543 [==============================] - 83s 153ms/step - loss: 0.0477 - binary_accuracy: 0.9403\n",
      "LABEL ACCURACY: 0.9279768616295686\n",
      "\n",
      "EPOCH 44\n",
      "543/543 [==============================] - 84s 154ms/step - loss: 0.0481 - binary_accuracy: 0.94032s - loss: 0.0482 - bina\n",
      "LABEL ACCURACY: 0.9283479379033904\n",
      "\n",
      "EPOCH 45\n",
      "543/543 [==============================] - 84s 156ms/step - loss: 0.0475 - binary_accuracy: 0.9405\n",
      "LABEL ACCURACY: 0.927480821366362\n",
      "\n",
      "EPOCH 46\n",
      "543/543 [==============================] - 84s 154ms/step - loss: 0.0481 - binary_accuracy: 0.9405\n",
      "LABEL ACCURACY: 0.9288077290704396\n",
      "\n",
      "EPOCH 47\n",
      "543/543 [==============================] - 86s 158ms/step - loss: 0.0475 - binary_accuracy: 0.9406\n",
      "LABEL ACCURACY: 0.926789226768622\n",
      "\n",
      "EPOCH 48\n",
      "543/543 [==============================] - 85s 156ms/step - loss: 0.0472 - binary_accuracy: 0.9405\n",
      "LABEL ACCURACY: 0.9261024017887975\n",
      "\n",
      "EPOCH 49\n",
      "543/543 [==============================] - 118s 217ms/step - loss: 0.0476 - binary_accuracy: 0.9406\n",
      "LABEL ACCURACY: 0.9282277435319212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# Epochs are written explicitly in a training loop since Keras\n",
    "# does not support generators for calculating validation metrics\n",
    "histories = []\n",
    "validation_metrics = []\n",
    "for i in range(50):\n",
    "    # Fit\n",
    "    print(f'EPOCH {i}')\n",
    "    history = model.fit(train_batches, epochs=1)\n",
    "    histories.append(history)\n",
    "\n",
    "    # Evaluate\n",
    "    total = 0\n",
    "    l_count = 0\n",
    "    for batch in validation_batches:\n",
    "        true_labels = batch[1]\n",
    "        pred_labels = model.predict(batch[0])\n",
    "        for true_label, pred_label in zip(true_labels, pred_labels):\n",
    "            idxs = true_label.sum(axis=1).astype(bool)\n",
    "            total += idxs.sum()\n",
    "            l_count += (np.argmax(true_label[idxs], axis=1) == np.argmax(pred_label[idxs], axis=1)).sum()\n",
    "    validation_metrics.append({'total': total, 'l_count': l_count})\n",
    "\n",
    "    print('LABEL ACCURACY:', l_count / total)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "angry-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "if not os.path.exists('out/'):\n",
    "    os.mkdir('out/')\n",
    "\n",
    "model.save('out/jason_cnn_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "basic-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"out/jason_cnn_8.h5\", custom_objects={\"MaskedConv1D\": MaskedConv1D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "visible-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL ACCURACY: 0.9282277435319212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "total = 0\n",
    "l_count = 0\n",
    "for batch in validation_batches:\n",
    "    true_labels = batch[1]\n",
    "    pred_labels = model.predict(batch[0])\n",
    "    for true_label, pred_label in zip(true_labels, pred_labels):\n",
    "        idxs = true_label.sum(axis=1).astype(bool)\n",
    "        total += idxs.sum()\n",
    "        l_count += (np.argmax(true_label[idxs], axis=1) == np.argmax(pred_label[idxs], axis=1)).sum()\n",
    "\n",
    "print('LABEL ACCURACY:', l_count / total)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
