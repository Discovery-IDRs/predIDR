{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "alien-damage",
=======
   "execution_count": null,
   "id": "metropolitan-effectiveness",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate correlations between learned and known features.\"\"\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "apparent-nirvana",
=======
   "execution_count": null,
   "id": "little-detective",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# define desired model, model layer, and window size for analysis\n",
    "\n",
    "model_acc = \"6_2\" # [\"3_6_1\", \"6_2\", \"7_1_2\", \"7_2_2\", \"7_3_2\"]\n",
    "layer_name = \"conv1d2\"\n",
    "known_window = 20 # [10,20,30,40,50]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "prerequisite-scotland",
=======
   "execution_count": null,
   "id": "absolute-efficiency",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/marcsingleton/Documents/School/Berkeley/Projects/predIDR/')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import src.models.utils\n",
    "import src.utils\n",
    "\n",
    "class MaskedConv1D(tf.keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(filters, kernel_size, **kwargs)\n",
    "        self.supports_masking = True"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "nutritional-timber",
=======
   "execution_count": null,
   "id": "discrete-trouble",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "weights = {'0': 1, '1': 2, '-': 3}\n",
    "batch_size = 32\n",
    "\n",
    "batch_data = src.models.utils.load_data('../../mobidb-pdb_validation/split_data/out/all_seqs.fasta', \n",
    "                                        '../../mobidb-pdb_validation/split_data/out/all_labels.fasta')\n",
    "\n",
    "batches = src.models.utils.BatchGenerator(batch_data, batch_size, alphabet, weights,\n",
    "                                          shuffle=False, all_records=False)\n",
    "\n",
    "seq_fasta = src.utils.read_fasta('../../mobidb-pdb_validation/split_data/out/all_seqs.fasta')\n",
    "\n",
    "known_feature_dir = f\"../generate_maps/out/window_size{known_window}\"\n",
    "\n",
    "# load in names of known features from first file in known_feature_dir\n",
    "known_feature_names = np.loadtxt(f\"{known_feature_dir}/{os.listdir(known_feature_dir)[0]}\", dtype = str, max_rows = 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "competent-factory",
=======
   "execution_count": null,
   "id": "varying-elimination",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accessions\n",
    "protein_acc = []\n",
    "for accession, _, in seq_fasta:\n",
    "    protein_acc.append(accession.split(\"|\")[0][1:]) # Keep only acc"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "modified-canyon",
=======
   "execution_count": null,
   "id": "regular-malawi",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate learned features\n",
    "model_name = f\"mobidb-pdb_cnn_{model_acc}\"\n",
    "model_path = f\"../../models/{model_name}/out_model/{model_name}.h5\"\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"MaskedConv1D\":MaskedConv1D})\n",
    "\n",
    "layer = model.get_layer(layer_name)\n",
    "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=layer.output)\n",
    "    \n",
    "learned_features = []\n",
    "for input, _, training_weights, in batches:  # Predict method was acting strange, so extract individual batches\n",
    "    features = feature_extractor(input).numpy()\n",
    "    features = features[training_weights != 0]  # Drop padding\n",
    "    learned_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "discrete-surgery",
=======
   "execution_count": null,
   "id": "bigger-gibraltar",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct matrix of learned feature values\n",
    "learned_feature_array = [array for array in learned_features]\n",
    "learned_feature_array = np.concatenate(learned_feature_array, axis = 0)\n",
    "learned_feature_array = learned_feature_array.transpose()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "legendary-baking",
=======
   "execution_count": null,
   "id": "saving-wallpaper",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in known features\n",
    "known_features = []\n",
    "batch_protein_ct = len(batches)*batch_size\n",
    "for acc, _, in zip(protein_acc, np.arange(batch_protein_ct)): # Zip removes proteins not included in batches\n",
    "    acc_path = f\"{known_feature_dir}/{acc}_feature_map{known_window}.tsv\"\n",
    "    protein_known_features = np.loadtxt(acc_path, skiprows = 1)\n",
    "    known_features.append(protein_known_features)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "accepted-halifax",
=======
   "execution_count": null,
   "id": "engaged-evans",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct matrix of known feature values\n",
    "known_feature_array = [array for array in known_features]\n",
    "known_feature_array = np.concatenate(known_feature_array, axis = 0)\n",
    "known_feature_array = known_feature_array.transpose()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "loose-dealer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "bibliographic-version",
   "metadata": {},
   "outputs": [],
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "source": [
    "# Calculate correlation between known and learned features\n",
    "corr_matrix = np.corrcoef(learned_feature_array, known_feature_array)\n",
    "corr_matrix = corr_matrix[:128, -37:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "id": "arbitrary-trout",
=======
   "execution_count": null,
   "id": "essential-estonia",
>>>>>>> 04f0a12968e1151900a63c58f20154f226c4964f
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(test, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-horse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
