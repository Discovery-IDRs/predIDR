{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "local-screen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate correlations between learned and known features.'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Calculate correlations between learned and known features.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "alike-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import src.models.utils\n",
    "import src.utils\n",
    "\n",
    "class MaskedConv1D(tf.keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(filters, kernel_size, **kwargs)\n",
    "        self.supports_masking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "worst-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "weights = {'0': 1, '1': 2, '-': 3}\n",
    "batch_size = 32\n",
    "model_acc = [\"3_6_1\", \"6_2\", \"7_1_2\", \"7_2_2\", \"7_3_2\"]\n",
    "\n",
    "batch_data = src.models.utils.load_data('../../mobidb-pdb_validation/split_data/out/all_seqs.fasta', '../../mobidb-pdb_validation/split_data/out/all_labels.fasta')\n",
    "batches = src.models.utils.BatchGenerator(batch_data, batch_size, alphabet, weights, shuffle=False)\n",
    "\n",
    "seq_fasta = src.utils.read_fasta('../../mobidb-pdb_validation/split_data/out/all_seqs.fasta')\n",
    "\n",
    "window_sizes = [10,20,30,40,50]\n",
    "\n",
    "feature_dict = {\"S_frac\":lambda seq:get_X_frac(seq,\"S\"),\n",
    "                \"P_frac\":lambda seq:get_X_frac(seq,\"P\"),\n",
    "                \"T_frac\":lambda seq:get_X_frac(seq,\"T\"),\n",
    "                \"A_frac\":lambda seq:get_X_frac(seq,\"A\"),\n",
    "                \"H_frac\":lambda seq:get_X_frac(seq,\"H\"),\n",
    "                \"Q_frac\":lambda seq:get_X_frac(seq,\"Q\"),\n",
    "                \"N_frac\":lambda seq:get_X_frac(seq,\"N\"),\n",
    "                \"G_frac\":lambda seq:get_X_frac(seq,\"G\"),\n",
    "                \"charge_frac\":lambda seq:get_X_frac(seq,\"DERK\"),\n",
    "                \"net_charge\":lambda seq:get_X_frac(seq,\"RK\")-get_X_frac(seq,\"DE\"),\n",
    "                \"RK_ratio\":lambda seq:(get_X_frac(seq,\"R\")+1)/(get_X_frac(seq,\"K\")+1),\n",
    "                \"ED_ratio\":lambda seq:(get_X_frac(seq,\"E\")+1)/(get_X_frac(seq,\"D\")+1),\n",
    "                \"acidic_frac\":lambda seq:get_X_frac(seq,\"DE\"),\n",
    "                \"basic_frac\":lambda seq:get_X_frac(seq,\"RK\"),\n",
    "                \"hydrophobicity\":lambda seq:get_hydrophobicity(seq),\n",
    "                \"aliphatic_frac\":lambda seq:get_X_frac(seq,\"ALMIV\"),\n",
    "                \"polarity\":lambda seq:get_polarity(seq),\n",
    "                \"polar_frac\":lambda seq:get_X_frac(seq,\"QNSTGCH\"),\n",
    "                \"chain_expanding_frac\":lambda seq:get_X_frac(seq,\"EDRKP\"),\n",
    "                \"aromatic_frac\":lambda seq:get_X_frac(seq,\"FYW\"),\n",
    "                \"disorder_promoting_frac\":lambda seq:get_X_frac(seq,\"TAGRDHQKSEP\"),\n",
    "                \"Q_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"QQ\"),\n",
    "                \"N_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"NN\"),\n",
    "                \"S_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"SS\"),\n",
    "                \"G_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"GG\"),\n",
    "                \"E_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"EE\"),\n",
    "                \"D_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"DD\"),\n",
    "                \"K_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"KK\"),\n",
    "                \"R_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"RR\"),\n",
    "                \"P_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"PP\"),\n",
    "                \"QN_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"QN\"),\n",
    "                \"RG_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"RG\"),\n",
    "                \"FG_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"FG\"),\n",
    "                \"SG_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"SG\"),\n",
    "                \"SR_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"SR\"),\n",
    "                \"KAP_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"KAP\"),\n",
    "                \"PTS_repeat_frac\":lambda seq:get_pair_repeat_frac(seq,\"PTS\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "acquired-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models as dictionary of mapping of model name to model\n",
    "model_dict = {}\n",
    "for acc in model_acc:\n",
    "    model_name = f\"mobidb-pdb_cnn_{acc}\"\n",
    "    model_path = f\"../../models/{model_name}/out_model/{model_name}.h5\"\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={\"MaskedConv1D\":MaskedConv1D})\n",
    "    model_dict[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "congressional-theater",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-365-4dbe2f029444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlearned_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Predict method was acting strange, so extract individual batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprotein_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotein_weights\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprotein_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprotein_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprotein_weights\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Drop padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m     name=None):\n\u001b[1;32m-> 1012\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1013\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1143\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 602\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 602\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1884\u001b[1;33m       result = gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   1885\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1886\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason hong\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    922\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate learned features\n",
    "model_learned_features = {}  # {\"model_name\":[features learned by model for each protein]}\n",
    "for model_key in model_dict:\n",
    "    model = model_dict[model_key]\n",
    "    layer = model.get_layer(\"conv1d2\")\n",
    "    feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=layer.output)\n",
    "    \n",
    "    learned_features = []\n",
    "    for input, _, training_weights, in batches:  # Predict method was acting strange, so extract individual batches\n",
    "        features = feature_extractor(input).numpy()\n",
    "        for protein_features, protein_weights in zip(features, training_weights):\n",
    "            protein_features = protein_features[protein_weights != 0]  # Drop padding\n",
    "            learned_features.append(protein_features)\n",
    "    \n",
    "    model_learned_features[model_key] = learned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accessions\n",
    "accessions = []\n",
    "for accession, _, in seq_fasta:\n",
    "    accessions.append(accession.split(\"|\")[0][1:]) # Keep only acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct new record objects that contain known and learned features\n",
    "records = {}  # {model_key:{accession:{seq:,labels:,learned_features:,known_features:{window_size:{known_feature:}}}}}\n",
    "for model_key in model_dict:\n",
    "    model_records = {}\n",
    "    \n",
    "    for accession, (seq, labels), learned_features in zip(accessions, batch_data, model_learned_features[model_key]):\n",
    "        known_features = {}\n",
    "        for window_size in window_sizes:\n",
    "            window_features = {}\n",
    "            with open(f\"../generate_maps/out/window_size{window_size}/{accession}_feature_map{window_size}.tsv\") as file:\n",
    "                for feature in feature_dict:\n",
    "                    window_features[feature] = []\n",
    "            \n",
    "                for line in file:\n",
    "                    line_values = line.split(\"\\t\")[:-1]  # Remove \\n\n",
    "                    for feature, value in zip(feature_dict.keys(), line_values):\n",
    "                        window_features[feature].append(value)\n",
    "            \n",
    "            known_features[f\"window{window_size}\"] = window_features\n",
    "        \n",
    "        model_records[accession] = {\"seq\": seq,\n",
    "                                    \"labels\":labels,\n",
    "                                    \"learned_features\":learned_features,\n",
    "                                    \"known_features\": known_features}\n",
    "              \n",
    "    records[model_key] = model_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
