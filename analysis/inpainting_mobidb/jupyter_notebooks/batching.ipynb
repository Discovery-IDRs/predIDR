{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for func load_data \n",
    "def convert_ohc(seq):\n",
    "    \"\"\"\n",
    "    One hot encodes given amino acid sequence string.\n",
    "    \n",
    "    :param seq: string of amino acid sequence \n",
    "    :return: 2D array of one hot encoded string \n",
    "    \n",
    "    \"\"\"\n",
    "    seq_idx = [sym_codes.index(sym) for sym in seq]\n",
    "    x = np.array(seq_idx)\n",
    "    x = keras.utils.to_categorical(x, num_classes=len(sym_codes), dtype='int32')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_ohc('ASSSSSSGGHH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seqs_path, label_path):\n",
    "    \"\"\"\n",
    "    Loads sequences and lables from fasta files. \n",
    "    \n",
    "    :param seq_path: path for fasta file of amino acid sequences \n",
    "    :param label_path: path fasta file of labels of amino acid sequences where disordered residues are labeled are labeled as 1 and ordered residues are labeled as 0\n",
    "    :return: array all one hot encoded sequences and array of all labels from \n",
    "    \"\"\"\n",
    "    seq_ohc_lst = []\n",
    "    label_lst = []\n",
    "    \n",
    "    for record_seq, record_label in zip(SeqIO.parse(seqs_path, 'fasta'), SeqIO.parse(label_path, 'fasta')):\n",
    "        \n",
    "        # one hot encode each record_seq \n",
    "        seq = str(record_seq.seq)\n",
    "        seq_ohc = convert_ohc(seq)\n",
    "        seq_ohc_lst.append(seq_ohc)\n",
    "        \n",
    "        # expand the dimension of record_label for broadcasting\n",
    "        label = [int(sym) for sym in record_label]\n",
    "        label_lst.append(label)\n",
    "        \n",
    "    return np.array(seq_ohc_lst), np.array(label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_target_context(seq_ohc, label):\n",
    "    \"\"\"\n",
    "    Gets the target, context, and weight from one hot encoded sequences and labels. \n",
    "    \n",
    "    :param seq_ohc: one hot ended 2D arrays of sequences \n",
    "    :param label: array of labels corresponding to seq_ohc \n",
    "    :return: target, context and weight according to seq_ohc and label \n",
    "    \n",
    "    \"\"\"\n",
    "    weight = np.expand_dims(label, axis = 2)\n",
    "\n",
    "    # get the target from the record \n",
    "    target = weight*seq_ohc\n",
    "        \n",
    "    # get the context from the record (inverted the weight)\n",
    "    context = (np.invert(weight) + 2)*seq_ohc\n",
    "    \n",
    "    return weight, target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make generative model\n",
    "def make_generative_model():\n",
    "    \"\"\"\n",
    "    Makes generative generative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of generative model \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # convolution \n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(8, 3, strides = 1, padding='same', name='first'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "\n",
    "    model.add(keras.layers.Conv1D(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(256, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    # deconvolution \n",
    "    model.add(keras.layers.Conv1DTranspose(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(8, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    #FIXEME: PLAY AROUND WITH THE RATIO OF FILTER \n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(20, 3, strides = 1, padding='same', activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (Conv1D)               (None, 180, 8)            488       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 180, 16)           400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 180, 32)           1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 180, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 180, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 180, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 180, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 180, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 180, 64)           24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 180, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 180, 16)           1552      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, 180, 8)            392       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTr (None, 180, 20)           500       \n",
      "=================================================================\n",
      "Total params: 266,628\n",
      "Trainable params: 265,124\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generative_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make discrimator model\n",
    "def make_discriminator_model():\n",
    "    \"\"\"\n",
    "    Makes adverserial/discriminative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of discriminative model \n",
    "    \n",
    "    \"\"\"\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(25, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(13, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(7, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(4, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 90, 25)            2025      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 90, 25)            100       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 90, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 45, 13)            1313      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 45, 13)            52        \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 45, 13)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 23, 7)             371       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 23, 7)             28        \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 23, 7)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 12, 4)             116       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 4)             16        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 12, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 4,070\n",
      "Trainable params: 3,972\n",
      "Non-trainable params: 98\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tensorflow.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, generated_target, target):\n",
    "    generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "    ones_like_fake_output = tensorflow.cast(tensorflow.ones_like(fake_output), tensorflow.int64)\n",
    "    print(ones_like_fake_output.dtype)\n",
    "    print(fake_output.dtype)\n",
    "    a = cross_entropy(ones_like_fake_output, fake_output)\n",
    "    print(generated_target.dtype)\n",
    "    print(target.dtype)\n",
    "    b = cross_entropy(generated_target, target)\n",
    "    print('a')\n",
    "    print(a)\n",
    "    print('b')\n",
    "    print(b)\n",
    "    print(tensorflow.shape(target))\n",
    "    print(tensorflow.shape(generated_target))\n",
    "    print(target[0][0])\n",
    "    print(generated_target[0][0])\n",
    "    return  a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, weight):\n",
    "    \n",
    "    real_loss = cross_entropy(tensorflow.cast(tensorflow.ones_like(real_output), tensorflow.int64), real_output, weight)\n",
    "    fake_loss = cross_entropy(tensorflow.cast(tensorflow.zeros_like(fake_output), tensorflow.int64), fake_output, weight)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(context, target, weight):\n",
    "\n",
    "    with tensorflow.GradientTape() as gen_tape, tensorflow.GradientTape() as disc_tape:\n",
    "        generated_target = generator(context, training=True)*weight\n",
    "        generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "        \n",
    "        real_output = discriminator(target, training=True)\n",
    "        fake_output = discriminator(generated_target, training=True)\n",
    "        \n",
    "        print(fake_output.shape)\n",
    "        print(generated_target.shape)\n",
    "        print(target.shape)\n",
    "        \n",
    "        target = tensorflow.cast(tensorflow.constant(target), dtype = tensorflow.float32)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output, generated_target, target)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, weight)\n",
    "    \n",
    "        #backpropogration \n",
    "        print(gen_loss)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        print(gradients_of_generator)\n",
    "        print(generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, target, weight, epochs):\n",
    "    \n",
    "    # batch data \n",
    "    context_batch = np.array_split(context, BATCH_SIZE)\n",
    "    target_batch = np.array_split(target, BATCH_SIZE)\n",
    "    weight_batch = np.array_split(weight, BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for context, target, weight in zip(context_batch, target_batch, weight_batch):\n",
    "            \n",
    "            train_step(context, target, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')\n",
    "train_weight, train_target, train_context = get_weight_target_context(train_seq, train_label)\n",
    "\n",
    "\n",
    "#test_data = load_data('../../inpainting_mobidb/out/test_seq.fasta','../../inpainting_mobidb/out/test_label.fasta')\n",
    "\n",
    "#valid_data = load_data('../../inpainting_mobidb/out/validation_seq.fasta','../../inpainting_mobidb/out/validation_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contxt = train_context[:5]\n",
    "trgt = train_target[:5]\n",
    "wght = train_weight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contxt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgt[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wght.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 180, 20), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(contxt, training=True)*wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = make_generative_model()\n",
    "g.predict(contxt)*wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n",
      "(150, 180, 20)\n",
      "(150, 180, 20)\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "a\n",
      "tf.Tensor(1.1920929e-07, shape=(), dtype=float32)\n",
      "b\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(20,), dtype=int64)\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[<tf.Variable 'first/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[-0.03277415, -0.21190068,  0.03732222,  0.231493  ,\n",
      "         -0.18375656,  0.16084334,  0.09951937, -0.07628353],\n",
      "        [ 0.15904891,  0.16044757,  0.06276673,  0.05397099,\n",
      "         -0.03805578, -0.12131327, -0.12872608, -0.05602355],\n",
      "        [-0.18837932,  0.25419804,  0.10700494, -0.17768806,\n",
      "         -0.17921218, -0.25821477,  0.03024644, -0.11311238],\n",
      "        [-0.12343898, -0.25641882,  0.19953728,  0.06299141,\n",
      "         -0.07600451,  0.11132255,  0.23330036,  0.05325416],\n",
      "        [ 0.26227757, -0.224814  ,  0.214508  ,  0.262862  ,\n",
      "          0.111653  , -0.18094938,  0.19215366, -0.03153193],\n",
      "        [-0.14651398,  0.21488726, -0.09217048,  0.25183198,\n",
      "         -0.07664101,  0.07276976, -0.181014  , -0.2059389 ],\n",
      "        [ 0.14314452,  0.05947018, -0.12528935, -0.21599674,\n",
      "          0.00970456,  0.10199431, -0.07857606, -0.16661109],\n",
      "        [ 0.17014825,  0.11217684,  0.01914838,  0.13664642,\n",
      "         -0.06642038,  0.08263776,  0.0328705 ,  0.0015375 ],\n",
      "        [-0.12791748,  0.07218766, -0.23947841, -0.16292146,\n",
      "          0.03131017, -0.25662795, -0.13296436, -0.1284043 ],\n",
      "        [ 0.19056556,  0.02996609,  0.23597386, -0.20494246,\n",
      "         -0.0631523 ,  0.17234585, -0.19716391,  0.08830515],\n",
      "        [-0.1440967 , -0.05772342,  0.24882153,  0.01769263,\n",
      "         -0.26681888,  0.24366257, -0.18654075,  0.03537604],\n",
      "        [ 0.11687657, -0.25844952, -0.12533319, -0.12086068,\n",
      "         -0.19154991,  0.0870623 , -0.05530569,  0.0682106 ],\n",
      "        [-0.11907773, -0.22124606,  0.24199143,  0.07252425,\n",
      "          0.07020268,  0.12447461,  0.12227169,  0.01186448],\n",
      "        [ 0.09359035, -0.22466898,  0.0408299 , -0.01613787,\n",
      "         -0.12676057,  0.08260003,  0.08645231, -0.18391892],\n",
      "        [ 0.12404457, -0.24555665, -0.24103433, -0.07313761,\n",
      "         -0.01941416,  0.13854739, -0.00027788, -0.01123065],\n",
      "        [ 0.21980599, -0.01493278,  0.12350428,  0.20582747,\n",
      "          0.1107429 ,  0.1075539 ,  0.16813383,  0.25106147],\n",
      "        [-0.2640649 ,  0.17984223, -0.14378504,  0.15651721,\n",
      "         -0.25493434, -0.03549156,  0.22552302, -0.18333188],\n",
      "        [ 0.23149964, -0.1331835 , -0.01373059,  0.14249548,\n",
      "          0.1770787 , -0.08940184, -0.19387364, -0.25987986],\n",
      "        [-0.12106113,  0.16469541, -0.25534865,  0.00453541,\n",
      "         -0.08729634,  0.01003775,  0.02477148, -0.08810151],\n",
      "        [-0.2542594 , -0.01981489,  0.13667   , -0.24081455,\n",
      "         -0.10565752, -0.05749919, -0.2459881 ,  0.13215569]],\n",
      "\n",
      "       [[ 0.14096957, -0.03912939, -0.26706147, -0.21596564,\n",
      "         -0.22327568, -0.00241417,  0.08739415,  0.08386093],\n",
      "        [-0.16053563,  0.07931411, -0.2074369 , -0.1536252 ,\n",
      "         -0.25733295,  0.10911152, -0.14957619,  0.11672053],\n",
      "        [ 0.18665397,  0.02502275, -0.16311975,  0.17527294,\n",
      "         -0.18480489, -0.19016655,  0.25788143, -0.05058396],\n",
      "        [-0.11174157, -0.14059865,  0.16539666,  0.155325  ,\n",
      "          0.16109231, -0.25144204,  0.21092021,  0.00247073],\n",
      "        [ 0.1642147 , -0.0926975 , -0.10070807, -0.07869369,\n",
      "         -0.06218694, -0.12145315, -0.23790821,  0.20562088],\n",
      "        [ 0.21882075,  0.083049  ,  0.2635331 , -0.15516743,\n",
      "         -0.22312313,  0.09345984,  0.1754328 ,  0.1584898 ],\n",
      "        [-0.24866977,  0.09904879,  0.10635066,  0.10712934,\n",
      "         -0.10088272, -0.06620628, -0.11726902, -0.12592578],\n",
      "        [-0.25608966, -0.04394861, -0.21261111, -0.09730394,\n",
      "         -0.08043917,  0.1641255 ,  0.12513953, -0.01565832],\n",
      "        [ 0.00243691, -0.03988518, -0.2009483 , -0.13631533,\n",
      "          0.23198545, -0.23428318, -0.23313513, -0.04317811],\n",
      "        [-0.01664355,  0.0095543 , -0.21042971, -0.12161894,\n",
      "         -0.22922477, -0.25406742,  0.23750874, -0.08097722],\n",
      "        [ 0.18336856,  0.01385313, -0.16852525, -0.2480708 ,\n",
      "          0.05021203, -0.13708909, -0.18390803, -0.01523483],\n",
      "        [-0.06843488, -0.13294047, -0.21183819, -0.01151556,\n",
      "          0.16136917, -0.11896883, -0.01980731,  0.00108808],\n",
      "        [ 0.16437623, -0.1666267 , -0.12494558,  0.07908952,\n",
      "          0.2175782 , -0.01928392, -0.26714042, -0.26186937],\n",
      "        [-0.07881813, -0.23471208,  0.09148401,  0.03572324,\n",
      "         -0.00477499,  0.12206009, -0.18016186, -0.199232  ],\n",
      "        [ 0.21680516,  0.22057101,  0.20064995,  0.10367322,\n",
      "         -0.16650271,  0.19300967, -0.20084321, -0.16917181],\n",
      "        [ 0.15556791, -0.01927786,  0.19202092,  0.03999516,\n",
      "         -0.21573797,  0.19898462,  0.2421867 , -0.13568948],\n",
      "        [ 0.2569097 ,  0.20263764,  0.01748013, -0.25897878,\n",
      "          0.25916955,  0.03068018,  0.21223068, -0.25747293],\n",
      "        [ 0.03612441,  0.04878119,  0.09585375, -0.21076201,\n",
      "         -0.0141674 , -0.0210935 ,  0.06738064,  0.04159066],\n",
      "        [-0.04273811, -0.25512302, -0.22439702,  0.02989757,\n",
      "         -0.2352848 ,  0.15099216, -0.04013464,  0.10090712],\n",
      "        [-0.14197317,  0.08252421,  0.08802968, -0.19591925,\n",
      "          0.13738036,  0.1804628 ,  0.04261068, -0.02535275]],\n",
      "\n",
      "       [[-0.10613886, -0.2475242 ,  0.19000074, -0.01345149,\n",
      "          0.14942929, -0.15586948, -0.22606935, -0.15555955],\n",
      "        [-0.04476161, -0.00710618,  0.10137153, -0.03597927,\n",
      "          0.18962371, -0.13268349,  0.10718018, -0.10550568],\n",
      "        [-0.12818803,  0.14681327, -0.04279916,  0.15949619,\n",
      "         -0.1570378 ,  0.08953819, -0.21407412, -0.08193384],\n",
      "        [-0.11941475,  0.04077441,  0.15706533,  0.08496347,\n",
      "          0.0203962 , -0.2351571 ,  0.02843419,  0.02233464],\n",
      "        [-0.12516694,  0.01911366,  0.12938195,  0.14283517,\n",
      "          0.18695939,  0.263427  ,  0.193836  , -0.06842992],\n",
      "        [-0.2403562 , -0.24228476, -0.0130963 , -0.04107068,\n",
      "         -0.06231356, -0.09098431,  0.10489607,  0.07995528],\n",
      "        [ 0.04961121, -0.12833032,  0.12580797,  0.25712237,\n",
      "          0.00562882,  0.01283067,  0.1129536 , -0.1518938 ],\n",
      "        [-0.22337666, -0.07840031, -0.04710141, -0.24663423,\n",
      "         -0.06588194,  0.11379898, -0.11849391,  0.19872263],\n",
      "        [-0.13713102,  0.03696698, -0.12845795,  0.00063384,\n",
      "          0.04928008, -0.0527502 ,  0.21107793,  0.23847315],\n",
      "        [ 0.24979392, -0.23501647, -0.06335148, -0.12108956,\n",
      "         -0.18498746,  0.17707303,  0.05433413,  0.07988486],\n",
      "        [-0.10981531, -0.02030395,  0.01300693,  0.1496557 ,\n",
      "          0.17224753,  0.12554792,  0.1054264 ,  0.2580869 ],\n",
      "        [-0.07153608, -0.1056321 , -0.24827878, -0.16513082,\n",
      "         -0.01646411, -0.05426489,  0.25177333,  0.17917827],\n",
      "        [-0.10208958, -0.02519192,  0.12504485, -0.25385988,\n",
      "          0.09804884, -0.20082691,  0.03964654,  0.111747  ],\n",
      "        [-0.03028302,  0.0631268 , -0.00188783, -0.12648925,\n",
      "          0.14953005,  0.18777767, -0.12033786,  0.2065821 ],\n",
      "        [-0.08597516, -0.16615002, -0.18683775, -0.08279477,\n",
      "          0.04736501,  0.14929613, -0.0437642 , -0.09393393],\n",
      "        [ 0.02209264, -0.19764912,  0.05120268,  0.2244271 ,\n",
      "         -0.21406718, -0.17992067, -0.23814952,  0.17295691],\n",
      "        [-0.10898447, -0.20362785,  0.14525717,  0.19408852,\n",
      "          0.05119383,  0.11322907, -0.07527268, -0.11160432],\n",
      "        [-0.14090835,  0.07208541, -0.05620414,  0.01559931,\n",
      "         -0.21136671, -0.14337303, -0.0607865 , -0.06590456],\n",
      "        [-0.20939037, -0.11878245, -0.25470853, -0.26439995,\n",
      "          0.2586966 ,  0.22922102, -0.2292305 ,  0.03858122],\n",
      "        [ 0.05886   ,  0.20422325,  0.25546476,  0.25767675,\n",
      "         -0.20864752,  0.14357746, -0.08174051, -0.05948871]]],\n",
      "      dtype=float32)>, <tf.Variable 'first/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[-2.09114835e-01, -1.04604453e-01,  2.22640157e-01,\n",
      "          8.17197561e-02, -4.67102230e-02,  1.69259489e-01,\n",
      "          5.49916625e-02,  7.18154311e-02, -1.53715387e-01,\n",
      "         -2.39947706e-01,  1.21094167e-01,  2.10315228e-01,\n",
      "          2.77061224e-01,  1.73124999e-01, -1.80932581e-02,\n",
      "         -2.44295329e-01],\n",
      "        [-2.25094393e-01,  2.65994787e-01,  9.39356685e-02,\n",
      "          4.67626154e-02,  1.88070059e-01,  1.46240324e-01,\n",
      "         -2.18875185e-01, -1.28427923e-01,  2.88026333e-01,\n",
      "          2.65597522e-01,  6.94934726e-02,  1.50958866e-01,\n",
      "         -2.61672437e-02,  7.11149871e-02,  7.53514767e-02,\n",
      "         -1.80091321e-01],\n",
      "        [-1.54980600e-01,  4.17214632e-03,  2.87622631e-01,\n",
      "          1.26441270e-01, -7.20127523e-02,  1.36052966e-01,\n",
      "          5.81252575e-03,  4.44342196e-02,  2.86391377e-01,\n",
      "         -2.72525907e-01,  2.79621422e-01, -4.65700328e-02,\n",
      "         -2.55693048e-01, -7.10631013e-02,  1.04469419e-01,\n",
      "          1.36809140e-01],\n",
      "        [-1.68708324e-01, -2.22926185e-01,  1.65423721e-01,\n",
      "         -1.88595265e-01, -1.22009814e-02,  1.95504308e-01,\n",
      "         -2.30798721e-02, -1.06662139e-01,  9.88501608e-02,\n",
      "         -1.09105989e-01,  2.81932652e-01, -2.85248727e-01,\n",
      "          3.55792940e-02, -4.00676727e-02,  2.61582732e-01,\n",
      "         -9.77162570e-02],\n",
      "        [ 9.24004614e-02,  1.66095644e-01,  1.51154310e-01,\n",
      "          1.30702883e-01,  1.78057104e-01,  1.76627964e-01,\n",
      "         -5.20801246e-02,  2.64666319e-01, -2.18150020e-02,\n",
      "         -1.12867922e-01,  2.82343268e-01,  4.17909026e-03,\n",
      "         -2.32612818e-01,  1.02510512e-01,  2.05303073e-01,\n",
      "          2.09454000e-02],\n",
      "        [ 8.63534510e-02, -5.79324365e-03, -2.51328409e-01,\n",
      "         -2.10191742e-01, -2.69334465e-01,  2.49609411e-01,\n",
      "         -8.12696517e-02,  2.73976564e-01, -1.19454727e-01,\n",
      "          2.41636336e-01,  2.41638720e-02,  1.65692568e-02,\n",
      "          2.39005089e-01, -1.96252167e-01, -1.80205360e-01,\n",
      "         -1.04267284e-01],\n",
      "        [ 7.03375340e-02, -1.85168505e-01,  2.60029316e-01,\n",
      "         -2.40626112e-01, -4.67892289e-02,  7.41287172e-02,\n",
      "          8.91680717e-02, -1.72051817e-01,  1.56816512e-01,\n",
      "          8.35639238e-03,  1.84581846e-01,  1.95588559e-01,\n",
      "         -1.71512216e-01, -2.49452636e-01,  2.68886447e-01,\n",
      "          1.78500772e-01],\n",
      "        [ 5.14553189e-02,  2.13047087e-01,  2.56655931e-01,\n",
      "          3.96991074e-02, -1.78433597e-01, -1.37006760e-01,\n",
      "          1.50053442e-01,  2.31367767e-01, -8.84630233e-02,\n",
      "         -1.52981773e-01,  2.35352397e-01,  1.70719206e-01,\n",
      "          2.00654030e-01, -5.29032201e-02, -2.55985409e-01,\n",
      "         -1.46848395e-01]],\n",
      "\n",
      "       [[ 1.69377059e-01,  2.44313478e-02, -2.57792085e-01,\n",
      "         -2.69985288e-01, -1.45756960e-01, -7.66851753e-02,\n",
      "          1.49201751e-01, -2.26502836e-01, -1.66262627e-01,\n",
      "          1.00276351e-01,  1.47199392e-01, -5.27332127e-02,\n",
      "          1.87339485e-02, -1.93224877e-01,  6.50429428e-02,\n",
      "         -1.39769003e-01],\n",
      "        [-2.02284455e-02,  2.64767170e-01, -1.33716762e-01,\n",
      "          1.14231229e-01,  1.09441578e-02, -2.06327736e-01,\n",
      "          1.05719417e-01, -2.12524235e-02,  4.63380218e-02,\n",
      "         -2.05948994e-01,  2.21203029e-01, -1.31242678e-01,\n",
      "         -1.58747017e-01,  1.40933931e-01, -2.35715136e-01,\n",
      "         -2.49869794e-01],\n",
      "        [-2.58473396e-01,  6.77720606e-02, -2.05525443e-01,\n",
      "          3.64249349e-02,  2.19319522e-01,  2.13248491e-01,\n",
      "         -1.62621677e-01,  2.07333475e-01, -3.09991539e-02,\n",
      "          2.65181065e-01, -2.52695620e-01, -7.54428804e-02,\n",
      "          1.79448694e-01, -2.71733373e-01, -2.59177059e-01,\n",
      "          2.27725685e-01],\n",
      "        [-1.54640540e-01,  2.77844548e-01,  2.86143541e-01,\n",
      "          1.28403634e-01,  2.01894492e-01,  9.63162780e-02,\n",
      "         -2.85338938e-01,  6.40495121e-02, -9.06498730e-02,\n",
      "         -2.59967387e-01, -1.55318677e-02,  2.45027065e-01,\n",
      "         -9.76826698e-02,  1.24734402e-01,  1.58312589e-01,\n",
      "          1.34719074e-01],\n",
      "        [ 2.28285909e-01, -2.06642449e-02, -1.95628256e-01,\n",
      "          2.56966293e-01,  1.83001876e-01, -9.16821212e-02,\n",
      "         -2.71323323e-03,  2.22267210e-02, -1.35133669e-01,\n",
      "         -4.35203314e-03, -7.64054060e-03,  2.78013170e-01,\n",
      "         -2.17937365e-01,  2.21329153e-01, -2.77172953e-01,\n",
      "          6.13940060e-02],\n",
      "        [-4.43968624e-02, -1.21870294e-01, -9.81667936e-02,\n",
      "         -2.69489259e-01, -2.67206460e-01,  1.83286875e-01,\n",
      "         -1.87378287e-01,  1.76642537e-01,  1.51269943e-01,\n",
      "          1.45542204e-01,  2.72751391e-01, -1.74546733e-01,\n",
      "         -7.82274902e-02,  9.39712524e-02,  2.68242478e-01,\n",
      "          1.45722270e-01],\n",
      "        [-2.90269554e-02, -2.63381273e-01, -1.68168947e-01,\n",
      "          2.21533418e-01, -2.33853608e-01, -2.25203216e-01,\n",
      "         -1.53403118e-01, -7.49909878e-03, -1.09024301e-01,\n",
      "          1.50248498e-01, -1.14533231e-01,  2.72754431e-01,\n",
      "          1.96926534e-01,  2.22666502e-01, -1.57156184e-01,\n",
      "          2.63230562e-01],\n",
      "        [ 8.76439214e-02, -4.44132388e-02, -8.68833065e-03,\n",
      "          1.54189676e-01, -2.42887169e-01, -2.32897341e-01,\n",
      "          1.73032016e-01, -2.67859071e-01, -2.59419262e-01,\n",
      "         -1.72050238e-01,  2.14747906e-01, -1.04588211e-01,\n",
      "         -1.10379949e-01, -1.53953180e-01, -4.32133675e-05,\n",
      "         -2.33288974e-01]],\n",
      "\n",
      "       [[ 9.40171778e-02,  3.28241885e-02, -1.65112138e-01,\n",
      "          2.82291472e-01, -1.13896042e-01,  2.73805678e-01,\n",
      "          1.39358640e-03, -8.60628486e-03,  1.74843937e-01,\n",
      "          8.46827626e-02, -3.34885120e-02, -1.97613806e-01,\n",
      "          2.81360686e-01, -2.01889247e-01, -2.70818770e-02,\n",
      "         -2.26468012e-01],\n",
      "        [-2.33387247e-01,  4.89205122e-04, -2.10747570e-01,\n",
      "         -2.38490254e-01,  4.83289957e-02,  3.94605696e-02,\n",
      "         -2.33123437e-01,  2.11022109e-01, -1.70767188e-01,\n",
      "         -2.41367161e-01,  9.58391726e-02, -1.08382910e-01,\n",
      "         -1.90290987e-01, -2.84405053e-01, -2.59456784e-01,\n",
      "          2.45511949e-01],\n",
      "        [ 2.16001630e-01,  2.13061988e-01, -2.75460899e-01,\n",
      "         -2.17753530e-01, -2.66455442e-01,  1.28623605e-01,\n",
      "         -9.62736756e-02, -2.44228855e-01, -5.66861331e-02,\n",
      "         -2.20529199e-01,  1.30654514e-01, -1.88921988e-02,\n",
      "          1.30479008e-01,  2.19568670e-01, -1.35929585e-02,\n",
      "          1.56491041e-01],\n",
      "        [ 9.37958956e-02, -5.62060773e-02, -1.74340129e-01,\n",
      "          2.25324571e-01, -2.83746541e-01,  2.33221650e-01,\n",
      "         -4.60951924e-02, -9.87961292e-02,  8.78999531e-02,\n",
      "          7.86771178e-02, -1.55615658e-01,  1.37474358e-01,\n",
      "         -9.89397764e-02, -2.76452810e-01,  2.65739560e-01,\n",
      "         -2.77205020e-01],\n",
      "        [ 2.62833059e-01, -1.88087732e-01, -1.57891512e-01,\n",
      "          6.68380260e-02, -2.24717915e-01, -2.44558603e-01,\n",
      "          8.06069374e-03,  2.22171187e-01, -2.27365851e-01,\n",
      "         -5.07400930e-02, -1.47453919e-01,  1.03668720e-01,\n",
      "         -1.38150156e-02, -2.07585320e-01,  2.78178453e-01,\n",
      "         -2.30077565e-01],\n",
      "        [ 1.60150647e-01,  1.12792492e-01,  3.74105275e-02,\n",
      "         -2.17854023e-01, -1.50006711e-02, -1.04337960e-01,\n",
      "          2.50800371e-01,  1.02843076e-01,  2.37915397e-01,\n",
      "          2.38971353e-01,  1.84993148e-01,  2.66741395e-01,\n",
      "          2.90618539e-02, -1.72351122e-01,  1.01305783e-01,\n",
      "         -2.12442473e-01],\n",
      "        [-2.42964178e-01, -2.35496193e-01,  1.56023383e-01,\n",
      "          1.29571527e-01, -6.92192614e-02, -4.73704934e-03,\n",
      "         -1.65127546e-01, -7.09941983e-03, -4.62360233e-02,\n",
      "          2.28556097e-01,  1.89631760e-01, -2.37938195e-01,\n",
      "         -1.91487044e-01,  2.48868108e-01,  1.97716504e-01,\n",
      "          1.87060595e-01],\n",
      "        [-8.18878412e-04,  1.98265612e-02, -1.11006498e-02,\n",
      "          1.62270665e-03,  2.15616524e-02, -2.37497166e-01,\n",
      "          1.04496539e-01, -2.43200660e-01, -1.04291096e-01,\n",
      "          1.69993252e-01, -1.64211959e-01, -1.70228779e-02,\n",
      "         -3.88089865e-02,  2.87977457e-01,  6.66609406e-03,\n",
      "         -2.67934978e-01]]], dtype=float32)>, <tf.Variable 'conv1d/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_1/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[-0.04713699, -0.06876154,  0.18680626, ...,  0.2013911 ,\n",
      "          0.16153541, -0.06064545],\n",
      "        [ 0.03391564,  0.08348823, -0.10837901, ..., -0.03230466,\n",
      "         -0.18935767,  0.10498068],\n",
      "        [-0.20201226,  0.09415573, -0.09426455, ..., -0.19233823,\n",
      "         -0.09744047, -0.16678402],\n",
      "        ...,\n",
      "        [ 0.11871535,  0.06897107, -0.13551469, ..., -0.08806603,\n",
      "         -0.11816754, -0.1946777 ],\n",
      "        [-0.19908187, -0.07998794,  0.16894463, ...,  0.11901274,\n",
      "          0.18171918,  0.19575635],\n",
      "        [-0.10029678,  0.19412562,  0.09192163, ...,  0.04214153,\n",
      "          0.16256824, -0.09778196]],\n",
      "\n",
      "       [[-0.05302794, -0.02655548,  0.04975948, ...,  0.08821997,\n",
      "          0.0399573 ,  0.08278123],\n",
      "        [ 0.0295027 ,  0.18604812, -0.03273293, ..., -0.17266464,\n",
      "         -0.18598738,  0.11996779],\n",
      "        [-0.06795737,  0.14110151, -0.01038991, ...,  0.18921804,\n",
      "         -0.17914616, -0.05641326],\n",
      "        ...,\n",
      "        [ 0.04315127,  0.05297568, -0.08300106, ...,  0.07782513,\n",
      "          0.11189708, -0.04440314],\n",
      "        [ 0.00988071,  0.07790822, -0.17600991, ..., -0.11445498,\n",
      "         -0.04292691, -0.13241109],\n",
      "        [ 0.06473669, -0.09079076,  0.04676208, ..., -0.11765775,\n",
      "         -0.13226934,  0.13251272]],\n",
      "\n",
      "       [[-0.04978809,  0.17943135, -0.17182387, ...,  0.1306333 ,\n",
      "          0.09190771, -0.01772821],\n",
      "        [ 0.13191247, -0.06587651, -0.03579316, ..., -0.1637247 ,\n",
      "          0.14624757,  0.09750485],\n",
      "        [ 0.18550932,  0.04582596,  0.06637612, ...,  0.01411957,\n",
      "         -0.19705907,  0.01426755],\n",
      "        ...,\n",
      "        [-0.19947368,  0.09731656,  0.02487443, ..., -0.20108597,\n",
      "          0.15450668,  0.16262883],\n",
      "        [ 0.13349667, -0.11367402, -0.13608328, ...,  0.1285299 ,\n",
      "         -0.00625838, -0.07058762],\n",
      "        [-0.13908164, -0.00841136, -0.14544013, ...,  0.04916704,\n",
      "          0.18449575, -0.1450177 ]]], dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[ 0.13379475, -0.06238554, -0.01892316, ..., -0.04630584,\n",
      "         -0.01716663,  0.03809382],\n",
      "        [-0.11829774,  0.02375004,  0.09959427, ..., -0.03603129,\n",
      "         -0.14043942, -0.04219282],\n",
      "        [ 0.1173799 , -0.07485745, -0.05941672, ..., -0.00186771,\n",
      "          0.116633  , -0.05201698],\n",
      "        ...,\n",
      "        [ 0.0528031 , -0.10861716,  0.09080993, ..., -0.07866371,\n",
      "          0.08048703, -0.12166885],\n",
      "        [-0.09130644,  0.07652853,  0.0008077 , ...,  0.02298717,\n",
      "          0.07047127,  0.03279233],\n",
      "        [-0.0429634 ,  0.02412671,  0.10712495, ..., -0.04317063,\n",
      "         -0.06693192,  0.12871996]],\n",
      "\n",
      "       [[ 0.0366925 ,  0.05310315,  0.09376489, ...,  0.13871321,\n",
      "         -0.04661614,  0.05935709],\n",
      "        [-0.02022593, -0.03542821, -0.09297676, ...,  0.13051623,\n",
      "         -0.13714485,  0.10038562],\n",
      "        [ 0.13780889, -0.04099358, -0.13854188, ...,  0.02323698,\n",
      "          0.05534181,  0.03852494],\n",
      "        ...,\n",
      "        [-0.08176371,  0.05936858, -0.01534382, ..., -0.0093323 ,\n",
      "          0.05781832, -0.12024358],\n",
      "        [-0.09439743, -0.10494545,  0.13176909, ..., -0.03735718,\n",
      "         -0.09911297,  0.09347655],\n",
      "        [ 0.02015838, -0.05212793,  0.02595961, ..., -0.04519923,\n",
      "          0.1178489 ,  0.06664632]],\n",
      "\n",
      "       [[-0.1048406 ,  0.04621653, -0.04685163, ...,  0.09943989,\n",
      "         -0.10415407,  0.04983476],\n",
      "        [ 0.09092987, -0.0459794 , -0.05336376, ..., -0.09157909,\n",
      "          0.04935588, -0.07433499],\n",
      "        [ 0.01915993,  0.07409744,  0.00769886, ...,  0.13415682,\n",
      "          0.13744906,  0.01813228],\n",
      "        ...,\n",
      "        [-0.00695004, -0.00525379, -0.10021594, ...,  0.1355989 ,\n",
      "         -0.1238085 ,  0.1293019 ],\n",
      "        [ 0.03917556,  0.00257331,  0.01218246, ...,  0.11053637,\n",
      "          0.0341123 ,  0.08292525],\n",
      "        [ 0.06699114,  0.14052773, -0.05796395, ..., -0.12041251,\n",
      "          0.02301119, -0.13382936]]], dtype=float32)>, <tf.Variable 'conv1d_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_3/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[ 0.07085785, -0.00997661,  0.05483532, ...,  0.02759983,\n",
      "          0.0383362 , -0.04548568],\n",
      "        [-0.05158292, -0.059498  , -0.09756612, ...,  0.04071438,\n",
      "          0.06526859, -0.06898551],\n",
      "        [ 0.04758884, -0.07324985,  0.05651087, ...,  0.02179997,\n",
      "          0.10112232, -0.00510801],\n",
      "        ...,\n",
      "        [-0.01220439,  0.03063297, -0.10183607, ...,  0.01744048,\n",
      "          0.00098982,  0.01655573],\n",
      "        [ 0.07243314,  0.07495841, -0.01382213, ..., -0.07713241,\n",
      "         -0.09002705,  0.05940165],\n",
      "        [ 0.06424153, -0.07849255, -0.01587829, ..., -0.01745739,\n",
      "         -0.0009757 ,  0.02845804]],\n",
      "\n",
      "       [[-0.0364975 , -0.02993412, -0.09373082, ..., -0.00795691,\n",
      "          0.08642511,  0.03633463],\n",
      "        [-0.05965614,  0.07971351, -0.00511782, ..., -0.00628203,\n",
      "          0.06293167,  0.07114953],\n",
      "        [-0.01702702, -0.04634343,  0.08825222, ...,  0.08237714,\n",
      "         -0.02579414,  0.05554025],\n",
      "        ...,\n",
      "        [-0.06437282,  0.08984274, -0.02801021, ..., -0.09609127,\n",
      "         -0.06582266, -0.08958357],\n",
      "        [ 0.05393587, -0.07724369, -0.00355734, ...,  0.00940988,\n",
      "          0.07926585,  0.01532098],\n",
      "        [ 0.04244567,  0.10057169, -0.03956957, ...,  0.04336882,\n",
      "         -0.0670059 , -0.07832843]],\n",
      "\n",
      "       [[ 0.07985625,  0.03242975, -0.06108885, ...,  0.07360946,\n",
      "         -0.00741334, -0.03964591],\n",
      "        [ 0.03171684,  0.00583138, -0.06633432, ..., -0.04272862,\n",
      "         -0.01340537,  0.07518776],\n",
      "        [ 0.0499638 , -0.09920418,  0.05943179, ..., -0.09444932,\n",
      "         -0.08725753,  0.06296158],\n",
      "        ...,\n",
      "        [ 0.07317826, -0.02821912,  0.06971595, ..., -0.04056829,\n",
      "          0.01205727,  0.06662694],\n",
      "        [-0.00135338,  0.04786685,  0.0272132 , ..., -0.00045963,\n",
      "         -0.03883317, -0.0345239 ],\n",
      "        [ 0.00989205,  0.07951464,  0.06779839, ..., -0.06223194,\n",
      "         -0.05742997, -0.03075766]]], dtype=float32)>, <tf.Variable 'conv1d_3/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_4/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_4/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[-0.01036817,  0.04398334, -0.07178172, ..., -0.02678285,\n",
      "         -0.06295826, -0.04513321],\n",
      "        [-0.05389285,  0.01714619, -0.02228013, ..., -0.04449769,\n",
      "         -0.04278712, -0.03134212],\n",
      "        [ 0.02720711, -0.00869343, -0.00195227, ...,  0.06130691,\n",
      "          0.03361744,  0.00753231],\n",
      "        ...,\n",
      "        [-0.07087694, -0.05963707, -0.04591219, ...,  0.01179627,\n",
      "         -0.00674469,  0.04547071],\n",
      "        [-0.02207673, -0.01144259,  0.05308178, ..., -0.00367838,\n",
      "          0.05260417,  0.06745321],\n",
      "        [ 0.05208431,  0.02245632,  0.03093936, ...,  0.00049949,\n",
      "         -0.06308321,  0.03642619]],\n",
      "\n",
      "       [[-0.00247742,  0.03286081, -0.03172522, ..., -0.03645999,\n",
      "         -0.00931445, -0.02843247],\n",
      "        [ 0.02484844, -0.05883319, -0.04428433, ...,  0.03678495,\n",
      "          0.06488843, -0.03123548],\n",
      "        [-0.06411903, -0.01250116,  0.05443251, ...,  0.03289918,\n",
      "         -0.01784275, -0.03778041],\n",
      "        ...,\n",
      "        [-0.07116367, -0.0169515 ,  0.05026194, ...,  0.01110698,\n",
      "          0.02347253,  0.01252853],\n",
      "        [-0.0701033 ,  0.03151288, -0.04380689, ..., -0.02167076,\n",
      "         -0.03935761,  0.04465368],\n",
      "        [ 0.04704425,  0.03366192,  0.05859095, ..., -0.0507988 ,\n",
      "         -0.06209216,  0.05495834]],\n",
      "\n",
      "       [[-0.04229147,  0.04285632,  0.07112695, ..., -0.01609588,\n",
      "          0.01138021,  0.02406706],\n",
      "        [-0.04908082, -0.02074957, -0.05947987, ...,  0.02606279,\n",
      "         -0.04393561, -0.03747052],\n",
      "        [-0.0426111 , -0.02925754, -0.02599743, ..., -0.0469938 ,\n",
      "          0.03678149, -0.03141776],\n",
      "        ...,\n",
      "        [ 0.00567298, -0.01815275, -0.04185885, ...,  0.06438915,\n",
      "         -0.03341541,  0.03502252],\n",
      "        [-0.06590331,  0.0088512 ,  0.01395838, ..., -0.05836108,\n",
      "         -0.04655783,  0.02802615],\n",
      "        [-0.02211833,  0.03593758, -0.05950293, ..., -0.04551223,\n",
      "          0.01436968, -0.04974049]]], dtype=float32)>, <tf.Variable 'conv1d_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_5/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_5/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv1d_transpose/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[ 0.06357075,  0.03344018, -0.01744586, ...,  0.05214003,\n",
      "         -0.07015131, -0.0044884 ],\n",
      "        [ 0.02822791, -0.06667766, -0.02342043, ..., -0.02602685,\n",
      "         -0.05848386, -0.04319899],\n",
      "        [ 0.03436247,  0.02376956,  0.07211073, ...,  0.02827296,\n",
      "          0.03267405, -0.00370213],\n",
      "        ...,\n",
      "        [-0.04117911, -0.02217587,  0.00306165, ...,  0.05321801,\n",
      "          0.03969866,  0.04122557],\n",
      "        [-0.03518832, -0.02889818,  0.01120146, ...,  0.04082831,\n",
      "         -0.02596473,  0.04043031],\n",
      "        [ 0.05053828,  0.03058732,  0.0524866 , ...,  0.01166754,\n",
      "         -0.02867044,  0.00563249]],\n",
      "\n",
      "       [[ 0.04401579, -0.05501265,  0.03973304, ..., -0.04972859,\n",
      "          0.03027579,  0.06135109],\n",
      "        [-0.00454617,  0.00147768,  0.02380183, ..., -0.0114468 ,\n",
      "          0.00891543, -0.00604074],\n",
      "        [ 0.06667466, -0.06390948,  0.02182591, ...,  0.03755801,\n",
      "          0.02908041, -0.05992632],\n",
      "        ...,\n",
      "        [-0.01000424,  0.01323941,  0.0280045 , ..., -0.02896565,\n",
      "          0.00406016,  0.00351038],\n",
      "        [ 0.0024995 , -0.02944731, -0.06329273, ...,  0.0339516 ,\n",
      "         -0.06697118, -0.0278372 ],\n",
      "        [-0.06979649, -0.06397597, -0.03851634, ...,  0.06305218,\n",
      "          0.02595241,  0.01295879]],\n",
      "\n",
      "       [[ 0.06928529, -0.01568212, -0.01551763, ...,  0.0107974 ,\n",
      "         -0.05144728, -0.04084621],\n",
      "        [-0.0010203 ,  0.06715266, -0.0328658 , ..., -0.04408873,\n",
      "          0.03268204, -0.03445717],\n",
      "        [-0.05958684,  0.05374141,  0.01869266, ...,  0.01808308,\n",
      "          0.06770283,  0.0509747 ],\n",
      "        ...,\n",
      "        [ 0.01172546,  0.043984  , -0.05716537, ..., -0.04678895,\n",
      "          0.02000861,  0.01893808],\n",
      "        [ 0.05826201, -0.02938233, -0.0539676 , ..., -0.02269533,\n",
      "         -0.02084759,  0.00227781],\n",
      "        [ 0.01200467,  0.0166528 ,  0.04979382, ...,  0.01493207,\n",
      "          0.01404916, -0.06533052]]], dtype=float32)>, <tf.Variable 'conv1d_transpose/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_6/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_6/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[-0.0810885 ,  0.0832033 ,  0.03734383, ..., -0.04036421,\n",
      "         -0.06440622, -0.01922747],\n",
      "        [-0.01389949,  0.08078475, -0.01274253, ..., -0.01633114,\n",
      "         -0.04340241, -0.0773527 ],\n",
      "        [ 0.07709698, -0.03596266,  0.0213808 , ..., -0.04842662,\n",
      "          0.07396443,  0.03815779],\n",
      "        ...,\n",
      "        [ 0.06313667, -0.05159694, -0.08083361, ...,  0.05723669,\n",
      "          0.0090304 , -0.00712682],\n",
      "        [-0.02851703,  0.0148747 , -0.00478737, ...,  0.00316287,\n",
      "          0.04245304,  0.03263195],\n",
      "        [-0.02770342,  0.06190877,  0.09544949, ...,  0.09806579,\n",
      "         -0.00888503,  0.02866039]],\n",
      "\n",
      "       [[ 0.02019098, -0.06629929, -0.0613443 , ...,  0.02195346,\n",
      "          0.05142358, -0.0414151 ],\n",
      "        [-0.03027036,  0.05721121, -0.03929336, ...,  0.01249114,\n",
      "         -0.00255801, -0.10169985],\n",
      "        [-0.0933519 , -0.07830609, -0.0805973 , ...,  0.08834438,\n",
      "          0.09885664,  0.01129909],\n",
      "        ...,\n",
      "        [ 0.06932749,  0.05070132,  0.01193494, ...,  0.05600139,\n",
      "          0.01155797, -0.00267825],\n",
      "        [-0.05159407,  0.08030657,  0.02987996, ...,  0.06105877,\n",
      "          0.03797245, -0.09759951],\n",
      "        [ 0.0987478 , -0.0100736 , -0.00743446, ..., -0.03908271,\n",
      "         -0.03593042, -0.09830267]],\n",
      "\n",
      "       [[ 0.00167651, -0.07371609, -0.01065855, ...,  0.01797654,\n",
      "         -0.0584773 ,  0.03254943],\n",
      "        [-0.08265962, -0.04833109,  0.07406427, ..., -0.08878246,\n",
      "         -0.05411711,  0.05998716],\n",
      "        [-0.0112666 ,  0.08666362, -0.03575882, ..., -0.10123817,\n",
      "         -0.08648611, -0.06484962],\n",
      "        ...,\n",
      "        [ 0.09535012,  0.03277043, -0.0412526 , ..., -0.08504554,\n",
      "         -0.08739053, -0.07783367],\n",
      "        [-0.0117376 , -0.0642553 , -0.06641664, ...,  0.03113471,\n",
      "         -0.08140802, -0.00890691],\n",
      "        [-0.06548567, -0.02202225,  0.08649831, ..., -0.08730306,\n",
      "          0.07066996,  0.06816104]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_7/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[-0.01140033, -0.02514698, -0.01468362, ..., -0.01269121,\n",
      "         -0.10168794, -0.11812234],\n",
      "        [-0.09917822, -0.06294613,  0.1058929 , ...,  0.08449639,\n",
      "          0.10257803, -0.05423988],\n",
      "        [ 0.0641861 ,  0.13174021, -0.05972781, ...,  0.05712847,\n",
      "         -0.08967473, -0.09215309],\n",
      "        ...,\n",
      "        [ 0.03393242,  0.14416954, -0.04729892, ..., -0.07284579,\n",
      "         -0.05374333, -0.1085517 ],\n",
      "        [ 0.04321352, -0.09335004, -0.10768233, ...,  0.06700821,\n",
      "         -0.02577832,  0.02466124],\n",
      "        [-0.13325824, -0.12913983,  0.08794986, ..., -0.01950075,\n",
      "         -0.0322143 , -0.06692524]],\n",
      "\n",
      "       [[-0.11701842, -0.07273129, -0.14126326, ...,  0.02820277,\n",
      "         -0.13047975, -0.11628738],\n",
      "        [ 0.11582816,  0.10195075, -0.13351172, ...,  0.05239221,\n",
      "          0.08248015,  0.00028796],\n",
      "        [-0.06183274, -0.14165492, -0.09037203, ...,  0.03626692,\n",
      "          0.01908015,  0.02989963],\n",
      "        ...,\n",
      "        [-0.03753093, -0.04559212,  0.06588608, ..., -0.0143811 ,\n",
      "         -0.11244337,  0.05656077],\n",
      "        [ 0.06083053, -0.02808101,  0.03370889, ...,  0.07762304,\n",
      "         -0.07310137,  0.13982663],\n",
      "        [ 0.11407638, -0.11070009, -0.03946128, ..., -0.13909678,\n",
      "          0.05919683,  0.12672645]],\n",
      "\n",
      "       [[-0.07224601, -0.03759865, -0.1207353 , ...,  0.05628376,\n",
      "         -0.06179461, -0.03113388],\n",
      "        [-0.12950829, -0.137544  , -0.06625595, ..., -0.03602995,\n",
      "         -0.07875242,  0.11530909],\n",
      "        [-0.10481802,  0.04102211,  0.12282652, ..., -0.1308535 ,\n",
      "         -0.0310965 ,  0.02078359],\n",
      "        ...,\n",
      "        [-0.1278022 , -0.00199948, -0.14254445, ...,  0.09691378,\n",
      "         -0.00429843, -0.11448911],\n",
      "        [-0.07001623,  0.10274634,  0.12107423, ...,  0.08973756,\n",
      "         -0.08493574,  0.12538517],\n",
      "        [ 0.1275495 , -0.07904796, -0.082724  , ..., -0.1088596 ,\n",
      "          0.10180137, -0.09491117]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_3/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[ 1.10528767e-01,  1.36512578e-01,  1.23000860e-01, ...,\n",
      "         -2.58676261e-02,  8.33673477e-02, -8.34086537e-02],\n",
      "        [-8.59153420e-02, -8.54181573e-02, -4.15620059e-02, ...,\n",
      "          7.05098510e-02,  1.42262459e-01,  9.45977867e-02],\n",
      "        [ 2.00469255e-01,  1.45462275e-01,  4.18505520e-02, ...,\n",
      "          9.22743678e-02, -4.51903641e-02,  1.59948468e-02],\n",
      "        ...,\n",
      "        [ 6.35549426e-04,  4.40821648e-02,  1.33110702e-01, ...,\n",
      "          5.10466099e-02,  1.56978577e-01,  1.57579869e-01],\n",
      "        [ 6.61850572e-02,  8.48414004e-02, -1.26805156e-01, ...,\n",
      "         -1.22843951e-01, -1.36865973e-01,  1.61420524e-01],\n",
      "        [ 1.63688362e-01,  4.88501787e-02,  1.80186957e-01, ...,\n",
      "          1.99781358e-01, -1.29618436e-01, -5.02849221e-02]],\n",
      "\n",
      "       [[-1.18544176e-01,  1.41231447e-01, -2.80861109e-02, ...,\n",
      "         -1.85701996e-01, -1.79017439e-01,  2.04104841e-01],\n",
      "        [ 1.90633029e-01, -2.90966779e-02,  2.29515433e-02, ...,\n",
      "         -8.65034834e-02,  1.09614700e-01, -1.13225281e-02],\n",
      "        [-8.52072835e-02,  1.84048086e-01,  5.78922033e-02, ...,\n",
      "         -2.03344166e-01,  7.23694563e-02,  4.12409008e-02],\n",
      "        ...,\n",
      "        [-9.62982029e-02, -2.03147694e-01, -1.84615597e-01, ...,\n",
      "         -1.22335039e-01, -1.31339550e-01,  1.76970661e-02],\n",
      "        [-6.19565845e-02, -1.83048084e-01,  8.62296224e-02, ...,\n",
      "         -1.82391137e-01,  1.18538231e-01,  2.01509625e-01],\n",
      "        [ 8.42308700e-02,  7.68045783e-02,  2.70791352e-02, ...,\n",
      "          7.99472630e-03, -1.76798165e-01, -8.24987888e-03]],\n",
      "\n",
      "       [[ 4.68746424e-02,  8.15989077e-02,  5.68775535e-02, ...,\n",
      "         -1.48805261e-01, -1.49897158e-01,  1.65621221e-01],\n",
      "        [-6.22643530e-02, -7.15079606e-02,  8.59273970e-03, ...,\n",
      "          6.72307312e-02,  1.14136219e-01, -7.74724782e-03],\n",
      "        [-2.05983073e-02,  1.31814539e-01, -7.38140941e-02, ...,\n",
      "          2.67757475e-02,  1.53829217e-01,  2.00758785e-01],\n",
      "        ...,\n",
      "        [-6.97178543e-02,  1.57007784e-01, -5.93980551e-02, ...,\n",
      "         -7.76486695e-02,  1.42783791e-01,  1.39965862e-01],\n",
      "        [ 1.72945172e-01,  9.40998793e-02,  6.10798597e-05, ...,\n",
      "         -1.47639006e-01,  1.64408445e-01, -4.10827994e-03],\n",
      "        [ 1.99552953e-01, -1.70044705e-01, -1.82093441e-01, ...,\n",
      "          7.02775717e-02, -7.40470141e-02, -3.01518738e-02]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_3/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_4/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[ 7.06569552e-02,  2.76531398e-01,  1.50795817e-01,\n",
      "         -2.26110458e-01, -1.97347999e-01, -8.47758204e-02,\n",
      "          6.16021454e-02, -8.61108303e-02, -1.56978682e-01,\n",
      "          2.13560820e-01, -2.26514339e-02,  2.23451734e-01,\n",
      "         -2.73113072e-01, -2.13321105e-01, -8.19252878e-02,\n",
      "          2.53389716e-01],\n",
      "        [-2.07036644e-01,  8.36728215e-02, -2.67067283e-01,\n",
      "          2.52237022e-01,  5.17033637e-02, -1.14582166e-01,\n",
      "         -7.33776987e-02,  1.92025512e-01,  1.40166134e-01,\n",
      "          7.04943240e-02, -1.19290650e-01, -2.47206032e-01,\n",
      "         -5.07414788e-02,  1.79167390e-01,  1.17110193e-01,\n",
      "          1.94139093e-01],\n",
      "        [ 2.83724904e-01,  1.79359496e-01, -2.57692933e-02,\n",
      "          1.02080554e-01,  1.55872107e-01,  9.73159075e-02,\n",
      "         -9.56113786e-02,  1.01261735e-01,  1.83825731e-01,\n",
      "          2.49636531e-01, -5.06680310e-02,  7.82009363e-02,\n",
      "         -7.73068070e-02,  5.27153909e-02, -2.78592736e-01,\n",
      "          7.54642189e-02],\n",
      "        [ 1.13318592e-01,  2.06685007e-01,  2.29395092e-01,\n",
      "          8.43768418e-02, -3.61547172e-02,  1.56274468e-01,\n",
      "         -9.30568427e-02, -2.68173516e-01,  2.87448943e-01,\n",
      "         -2.77744204e-01, -7.01970011e-02, -4.04335409e-02,\n",
      "         -2.10062906e-01,  1.72487199e-01, -1.51256382e-01,\n",
      "          2.62178540e-01],\n",
      "        [ 9.21833217e-02,  3.57112288e-02,  1.23444080e-01,\n",
      "          1.03195876e-01, -1.81174561e-01,  2.31655598e-01,\n",
      "         -5.47599196e-02, -2.53836632e-01,  1.18889809e-01,\n",
      "          2.02421606e-01, -2.16371596e-01,  1.23165816e-01,\n",
      "          1.94191724e-01,  1.17933482e-01, -2.15517804e-01,\n",
      "         -2.05049455e-01],\n",
      "        [ 2.56554246e-01, -5.16450107e-02, -1.14877567e-01,\n",
      "         -2.21779943e-02, -2.27789328e-01,  1.16755933e-01,\n",
      "          7.85622001e-03,  1.19748056e-01, -1.07915729e-01,\n",
      "         -2.56272346e-01, -1.64966702e-01,  2.34754801e-01,\n",
      "         -2.54223287e-01,  2.84015715e-01, -1.04408786e-01,\n",
      "         -2.67913014e-01],\n",
      "        [ 1.11590594e-01,  1.14007056e-01, -1.24500602e-01,\n",
      "          2.03782231e-01,  1.28819257e-01,  2.37059295e-01,\n",
      "         -7.66122937e-02, -2.27846384e-01,  3.30679715e-02,\n",
      "          1.29633874e-01, -1.21905953e-01, -2.72698313e-01,\n",
      "         -1.48735866e-01, -2.26206541e-01,  2.81989396e-01,\n",
      "         -2.19135895e-01],\n",
      "        [-4.44609374e-02,  1.09885931e-01,  1.68440044e-01,\n",
      "         -1.52631998e-01, -1.70691133e-01,  2.73643076e-01,\n",
      "          1.21072412e-01,  1.46608889e-01, -2.30568349e-02,\n",
      "         -2.10832298e-01,  2.43772924e-01, -2.16406196e-01,\n",
      "         -2.25976110e-03, -2.71889538e-01,  3.13614607e-02,\n",
      "          2.55221128e-01]],\n",
      "\n",
      "       [[ 1.55935287e-01,  1.51413858e-01, -1.83952019e-01,\n",
      "         -2.53200889e-01, -7.42589384e-02, -3.23446989e-02,\n",
      "          1.20468408e-01, -1.35277793e-01, -2.19070911e-03,\n",
      "         -3.73883545e-02,  6.31280839e-02, -5.72444499e-02,\n",
      "         -1.90721691e-01,  9.55091119e-02, -2.61316717e-01,\n",
      "          2.77651370e-01],\n",
      "        [-2.99263000e-02, -1.28326133e-01,  1.94723547e-01,\n",
      "         -2.34889567e-01,  9.85527039e-02,  2.07183808e-01,\n",
      "         -5.24216443e-02, -2.49310032e-01, -7.71497488e-02,\n",
      "          1.53077155e-01,  2.26026297e-01, -1.64256766e-01,\n",
      "          7.28930235e-02, -7.38249272e-02, -1.03382111e-01,\n",
      "          2.23006308e-02],\n",
      "        [ 5.56146502e-02,  1.28534734e-01,  3.64550948e-02,\n",
      "          4.45047915e-02,  2.34549105e-01, -2.03423515e-01,\n",
      "          8.59829485e-02, -1.51828527e-01,  9.76821184e-02,\n",
      "          2.38937676e-01,  2.62020528e-01,  5.76907098e-02,\n",
      "          1.21980160e-01, -2.17848450e-01,  2.69865572e-01,\n",
      "         -1.73786908e-01],\n",
      "        [-1.07360363e-01,  2.76424885e-01, -1.89089015e-01,\n",
      "          2.11435676e-01, -1.96321547e-01, -1.49262652e-01,\n",
      "         -2.26736158e-01,  2.11900175e-01, -5.08658439e-02,\n",
      "          2.02316463e-01,  2.15009987e-01,  1.57853723e-01,\n",
      "         -1.38002038e-02, -2.32735470e-01, -1.75219089e-01,\n",
      "          1.73774093e-01],\n",
      "        [-1.56862095e-01, -8.22717547e-02,  1.30634189e-01,\n",
      "         -3.21624279e-02,  2.35189319e-01,  2.42947042e-02,\n",
      "         -2.44270220e-01,  2.65629947e-01, -1.89127028e-02,\n",
      "         -9.45950896e-02,  1.47990555e-01,  2.27190614e-01,\n",
      "          1.74244732e-01,  2.70466805e-01,  1.01947784e-01,\n",
      "          2.55865514e-01],\n",
      "        [-1.70777500e-01,  1.22500271e-01,  2.81207263e-02,\n",
      "         -1.58024833e-01, -5.39489537e-02, -7.29777515e-02,\n",
      "          8.23507011e-02,  1.51336908e-01, -1.08662546e-01,\n",
      "         -2.02461392e-01, -1.00840941e-01,  5.82408905e-03,\n",
      "         -1.36350229e-01,  2.47988999e-01,  2.60877788e-01,\n",
      "          1.99382573e-01],\n",
      "        [-5.16507924e-02,  2.09114343e-01, -8.92070830e-02,\n",
      "          5.41043580e-02, -1.63754344e-01, -1.81438923e-01,\n",
      "          2.37715900e-01,  2.69953012e-01, -7.94354528e-02,\n",
      "          6.37446046e-02,  9.48693752e-02, -1.97691381e-01,\n",
      "          1.50142789e-01, -6.48102164e-03,  1.36684090e-01,\n",
      "         -1.10654294e-01],\n",
      "        [ 1.36422217e-01, -2.75887012e-01, -2.87746251e-01,\n",
      "          1.51933849e-01, -2.19535217e-01, -1.71608567e-01,\n",
      "          1.91249520e-01, -4.73170578e-02,  5.46638966e-02,\n",
      "          2.27991700e-01,  1.68578744e-01,  4.60119843e-02,\n",
      "         -2.80294389e-01, -3.10750008e-02,  9.20652151e-02,\n",
      "         -2.76210755e-01]],\n",
      "\n",
      "       [[ 5.52704632e-02, -5.69602698e-02, -1.27362922e-01,\n",
      "          9.50120986e-02,  4.68527079e-02, -2.46199116e-01,\n",
      "          1.49285197e-02, -1.00198999e-01,  2.87341654e-01,\n",
      "         -1.67094648e-01,  2.32950270e-01,  1.78561538e-01,\n",
      "         -2.49530375e-02, -1.62293240e-01, -1.27569944e-01,\n",
      "          2.57306159e-01],\n",
      "        [ 2.52484500e-01, -2.30537951e-02, -1.97855175e-01,\n",
      "          2.50145912e-01,  3.62184048e-02,  1.14167422e-01,\n",
      "          8.32977295e-02,  2.44346321e-01,  9.29064751e-02,\n",
      "          6.81332648e-02, -1.21227801e-02,  1.71307534e-01,\n",
      "         -1.87966749e-01,  2.79520035e-01, -1.40562549e-01,\n",
      "          2.05215514e-01],\n",
      "        [-2.24685371e-01,  2.65409708e-01,  2.64257967e-01,\n",
      "          1.98136747e-01, -2.33829528e-01, -2.36233592e-01,\n",
      "         -2.22285420e-01,  4.14202213e-02,  8.10788572e-02,\n",
      "          1.83466315e-01, -6.50497526e-02, -5.68817407e-02,\n",
      "         -5.52838892e-02,  1.91098988e-01, -2.78638154e-01,\n",
      "          2.22698152e-01],\n",
      "        [-2.19080776e-01, -1.93416625e-01,  2.05000371e-01,\n",
      "         -9.39686447e-02,  2.53319740e-06,  2.87939012e-01,\n",
      "         -1.98228359e-01,  1.07940435e-02, -1.98430985e-01,\n",
      "          2.74432778e-01, -1.69093341e-01,  6.89108670e-02,\n",
      "          2.26126790e-01,  1.37594938e-01,  2.73981690e-01,\n",
      "          2.79254615e-01],\n",
      "        [-2.22680897e-01,  1.49132013e-01, -2.18330503e-01,\n",
      "          2.16705322e-01, -4.69049960e-02,  1.50011063e-01,\n",
      "         -2.56153286e-01,  1.26883000e-01, -2.37327442e-01,\n",
      "         -2.20014513e-01,  2.26383746e-01, -8.03177953e-02,\n",
      "          1.72255337e-01, -2.55376667e-01,  4.12932038e-03,\n",
      "         -1.22193158e-01],\n",
      "        [ 2.26450443e-01,  2.02409238e-01,  2.57624626e-01,\n",
      "          2.35831439e-02,  1.41663611e-01,  2.01535493e-01,\n",
      "          1.13961846e-01,  2.21181273e-01,  2.39088893e-01,\n",
      "          6.37534261e-02,  2.84250796e-01, -1.47346407e-01,\n",
      "         -1.49734035e-01, -1.43004000e-01,  5.95322251e-02,\n",
      "         -1.03408545e-01],\n",
      "        [ 1.33560002e-02, -9.77948308e-03, -2.47867376e-01,\n",
      "         -1.30223244e-01, -2.29057983e-01, -1.09108806e-01,\n",
      "         -1.63524330e-01,  2.18870759e-01, -8.73536915e-02,\n",
      "         -4.93390858e-02, -9.82474536e-02, -1.35793701e-01,\n",
      "          2.70036995e-01, -2.26950198e-01,  2.78014719e-01,\n",
      "          8.78618956e-02],\n",
      "        [ 1.65205330e-01, -5.44526130e-02,  1.16562605e-01,\n",
      "         -2.32930034e-01,  1.98308736e-01, -2.64374971e-01,\n",
      "         -1.49887308e-01,  2.30056047e-02,  1.68430954e-01,\n",
      "         -2.42118523e-01,  1.20480508e-01,  1.85806930e-01,\n",
      "          1.75461560e-01, -2.68858880e-01, -1.82723209e-01,\n",
      "          2.67450452e-01]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_4/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_10/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_10/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_5/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[ 2.53488153e-01,  4.94449139e-02, -6.95442408e-02,\n",
      "          1.31414294e-01,  4.96965349e-02, -9.44592357e-02,\n",
      "         -1.35198712e-01, -5.22243977e-03],\n",
      "        [ 1.98605746e-01, -1.62788525e-01, -8.87557864e-03,\n",
      "          2.34257281e-02, -2.53522933e-01,  2.65487641e-01,\n",
      "         -1.62984461e-01,  2.59368718e-02],\n",
      "        [-2.50446349e-01, -1.64690569e-01,  1.43119037e-01,\n",
      "         -1.94374114e-01,  5.25288284e-02,  1.26185238e-01,\n",
      "         -1.33588240e-01, -1.14634335e-01],\n",
      "        [-1.79925397e-01,  1.59610361e-01, -1.73578948e-01,\n",
      "         -2.66342700e-01,  1.10838801e-01,  2.80738473e-02,\n",
      "         -1.68736100e-01, -1.08886153e-01],\n",
      "        [-5.82810938e-02, -1.50480494e-01,  2.54144967e-02,\n",
      "         -8.44169557e-02, -1.06336132e-01,  1.72587842e-01,\n",
      "         -1.02141008e-01,  2.43818849e-01],\n",
      "        [-2.55113900e-01, -1.49355963e-01,  1.86092615e-01,\n",
      "          1.10054910e-01, -1.47982359e-01,  3.63986790e-02,\n",
      "         -1.97044998e-01,  7.04728961e-02],\n",
      "        [-2.05292925e-01, -4.27044779e-02,  7.14646280e-02,\n",
      "          2.00432986e-01,  1.77385062e-01, -2.33502924e-01,\n",
      "         -2.67642736e-03, -2.15808392e-01],\n",
      "        [-2.07407340e-01, -7.04695284e-02, -2.00948805e-01,\n",
      "         -4.92322743e-02, -1.34883821e-02,  4.51764166e-02,\n",
      "         -1.16886452e-01, -1.48262203e-01],\n",
      "        [ 1.72663152e-01, -1.78588107e-01, -1.12705976e-01,\n",
      "         -1.81176990e-01, -2.21021131e-01,  3.06779444e-02,\n",
      "          1.79156482e-01,  8.49293172e-02],\n",
      "        [ 1.72726572e-01,  1.29164994e-01, -1.32229418e-01,\n",
      "          3.49437594e-02, -1.62316501e-01,  3.49079370e-02,\n",
      "          2.22568572e-01,  2.27595448e-01],\n",
      "        [-1.58935636e-01,  1.64301693e-01, -5.73495030e-02,\n",
      "         -1.41092241e-02, -1.92718789e-01,  2.27754295e-01,\n",
      "         -9.18480456e-02,  6.41452372e-02],\n",
      "        [ 2.17767328e-01, -2.24490047e-01,  2.26575106e-01,\n",
      "          1.36266053e-02,  1.41976804e-01, -7.06922263e-02,\n",
      "          3.30910385e-02, -2.18705475e-01],\n",
      "        [ 2.04471558e-01,  2.44466215e-01,  2.52901882e-01,\n",
      "          5.41485846e-02,  1.57256037e-01,  2.53829151e-01,\n",
      "         -1.34345427e-01, -8.24142247e-02],\n",
      "        [-2.33369753e-01,  1.43171668e-01, -2.53011703e-01,\n",
      "          1.65462554e-01, -2.38676041e-01,  1.26925290e-01,\n",
      "         -1.91184923e-01, -1.46726817e-01],\n",
      "        [ 1.88500404e-01,  1.83375329e-01, -1.50082618e-01,\n",
      "          7.20647573e-02,  1.92744970e-01, -1.49053603e-01,\n",
      "         -5.06794155e-02, -2.13383585e-01],\n",
      "        [-1.13538861e-01, -4.54144925e-02,  2.47189909e-01,\n",
      "         -1.58484429e-01,  1.09137535e-01,  1.75294727e-01,\n",
      "         -2.54844546e-01, -1.41610980e-01],\n",
      "        [ 2.36376375e-01, -8.70722234e-02, -1.56799793e-01,\n",
      "          2.08396584e-01,  2.34700769e-01,  1.39911890e-01,\n",
      "          1.29583687e-01,  8.98621976e-02],\n",
      "        [-1.39633238e-01,  2.34559774e-02,  1.81864977e-01,\n",
      "          2.48530596e-01, -2.18024254e-01, -5.21478504e-02,\n",
      "          1.32086486e-01, -2.17294276e-01],\n",
      "        [-1.67893648e-01,  2.52979606e-01,  2.08214164e-01,\n",
      "          1.93800807e-01, -1.79767609e-04,  1.58297122e-02,\n",
      "         -1.93892568e-01,  7.43975341e-02],\n",
      "        [ 1.56522363e-01,  2.41501361e-01, -1.80699661e-01,\n",
      "          3.35962772e-02, -2.53910989e-01,  8.12131763e-02,\n",
      "          6.73666894e-02, -2.46845394e-01]],\n",
      "\n",
      "       [[-1.80050477e-01,  1.30539805e-01, -2.21008956e-01,\n",
      "         -2.53065556e-01, -5.67593277e-02, -1.38315186e-01,\n",
      "          1.40828103e-01,  2.41659671e-01],\n",
      "        [ 1.61695987e-01,  7.30032325e-02, -1.01341128e-01,\n",
      "          1.57272607e-01,  1.08337343e-01, -2.25287631e-01,\n",
      "         -5.21921962e-02, -1.62922084e-01],\n",
      "        [ 7.77888298e-03, -3.52555960e-02, -6.85672313e-02,\n",
      "         -1.11363783e-01, -2.45950967e-01,  1.34020656e-01,\n",
      "         -1.50451437e-01,  2.62156129e-03],\n",
      "        [-7.75628984e-02,  5.80554605e-02, -6.38132095e-02,\n",
      "          2.23992467e-02,  2.41617113e-01,  1.51377738e-01,\n",
      "          2.44241804e-01,  1.97473645e-01],\n",
      "        [ 8.14449787e-03, -1.02070212e-01, -1.12239867e-01,\n",
      "         -1.45127743e-01, -2.50800133e-01, -7.70035684e-02,\n",
      "          1.10662341e-01, -3.64911556e-03],\n",
      "        [-7.18734711e-02,  1.68839395e-01,  1.31537020e-01,\n",
      "          4.95453179e-02,  2.57573158e-01,  2.16881931e-01,\n",
      "          1.46221757e-01,  5.63146174e-02],\n",
      "        [-2.33070210e-01, -1.91026837e-01,  2.24835932e-01,\n",
      "          1.88249022e-01,  2.34997541e-01, -3.91623378e-02,\n",
      "          3.42774391e-03, -2.64957815e-01],\n",
      "        [ 2.09112376e-01, -1.38493672e-01,  1.70454979e-02,\n",
      "         -6.26858622e-02,  1.06972754e-01, -3.53578776e-02,\n",
      "          1.54176354e-02, -2.03727454e-01],\n",
      "        [ 2.46729702e-01,  7.14948475e-02, -1.00765929e-01,\n",
      "          2.16725767e-01, -1.90300360e-01,  3.44679654e-02,\n",
      "          2.46806175e-01,  3.57936621e-02],\n",
      "        [ 1.07035965e-01,  2.13553965e-01, -1.35178819e-01,\n",
      "          1.55246437e-01,  2.49697834e-01,  9.61085558e-02,\n",
      "         -1.72914028e-01, -5.71540147e-02],\n",
      "        [-4.44698930e-02,  2.16834098e-01, -2.64001250e-01,\n",
      "          1.94179118e-02,  5.35024703e-02,  1.87036872e-01,\n",
      "         -2.51807719e-01,  1.89948440e-01],\n",
      "        [ 1.01081580e-01, -2.07788646e-01, -8.60762596e-03,\n",
      "          2.15939075e-01,  1.58766150e-01, -1.38247266e-01,\n",
      "         -1.86982065e-01, -8.86564404e-02],\n",
      "        [ 1.78069472e-01, -2.05274820e-02, -1.61641628e-01,\n",
      "          1.18015587e-01, -9.47659761e-02, -5.88342398e-02,\n",
      "         -2.27543890e-01,  1.72578990e-01],\n",
      "        [ 1.83556944e-01, -1.74365491e-02,  1.58370256e-01,\n",
      "          1.88868642e-02, -1.81932896e-02, -2.14911908e-01,\n",
      "         -1.30072042e-01,  3.01696658e-02],\n",
      "        [ 2.22728968e-01,  2.69103646e-02,  1.12026930e-04,\n",
      "          2.11837530e-01,  1.53242260e-01,  1.30192846e-01,\n",
      "          7.96227753e-02, -4.64819223e-02],\n",
      "        [-2.27166608e-01, -1.48689121e-01,  1.41039044e-01,\n",
      "          1.29123032e-02,  2.28112340e-01, -5.96079975e-02,\n",
      "         -1.59729213e-01,  6.01487160e-02],\n",
      "        [-1.61750719e-01, -1.20393604e-01,  8.83375108e-02,\n",
      "         -8.43007863e-02, -6.21685237e-02,  7.64238834e-03,\n",
      "          9.40057337e-02,  1.13885701e-02],\n",
      "        [ 8.61993432e-02,  7.81284869e-02, -1.07335746e-02,\n",
      "         -1.71115518e-01, -1.36207521e-01, -2.57424384e-01,\n",
      "          2.29516804e-01, -1.73793614e-01],\n",
      "        [ 1.14769727e-01,  1.25350654e-02, -1.44003421e-01,\n",
      "         -3.90859991e-02, -1.25411883e-01,  1.44143343e-01,\n",
      "         -1.47851408e-02,  4.83119488e-03],\n",
      "        [-1.73829496e-01, -1.43932104e-02, -1.52984440e-01,\n",
      "         -2.56943494e-01,  2.08634257e-01, -3.83465886e-02,\n",
      "          1.58619255e-01, -8.35680962e-03]],\n",
      "\n",
      "       [[-8.78268033e-02, -1.42124370e-01,  2.53779501e-01,\n",
      "          3.74320149e-02, -2.21667945e-01,  1.16577476e-01,\n",
      "          2.31984556e-01,  4.91834581e-02],\n",
      "        [ 2.06093639e-01,  9.30941701e-02,  4.12899554e-02,\n",
      "         -1.06455863e-01, -2.33364284e-01,  9.31683183e-02,\n",
      "          5.47886491e-02, -8.27821493e-02],\n",
      "        [ 6.25836551e-02, -7.77499229e-02, -2.47411296e-01,\n",
      "         -2.05522567e-01,  4.69993353e-02, -1.76587880e-01,\n",
      "          1.32978559e-02,  1.96718365e-01],\n",
      "        [ 1.78191960e-02, -2.51688898e-01, -2.13103786e-01,\n",
      "          6.10126555e-02, -1.06018618e-01,  6.05622828e-02,\n",
      "         -1.09411970e-01,  8.13922286e-02],\n",
      "        [ 1.34578377e-01, -4.11730856e-02, -2.63771981e-01,\n",
      "          1.19856268e-01, -1.99830383e-01,  1.51507348e-01,\n",
      "          1.06276929e-01,  2.54246980e-01],\n",
      "        [ 4.10199761e-02, -9.97100174e-02, -1.71490267e-01,\n",
      "         -7.50532746e-03, -7.90714175e-02,  7.05573261e-02,\n",
      "          1.52646661e-01,  1.62810385e-01],\n",
      "        [ 2.17882723e-01,  7.84550607e-02,  2.47430712e-01,\n",
      "          3.20282578e-03, -2.25357145e-01,  2.64292955e-02,\n",
      "          5.31354547e-03,  1.97515517e-01],\n",
      "        [-6.17918074e-02, -8.48046243e-02, -1.95966274e-01,\n",
      "          6.47109747e-03,  1.96137309e-01, -1.26010790e-01,\n",
      "         -1.89449579e-01,  1.51495159e-01],\n",
      "        [ 1.35608941e-01, -2.25388378e-01,  1.12962633e-01,\n",
      "          2.46786684e-01,  1.97411001e-01,  2.11868137e-01,\n",
      "         -2.76047289e-02,  1.90694541e-01],\n",
      "        [ 8.61439705e-02,  1.89467221e-01, -2.41000175e-01,\n",
      "          2.68143415e-02, -2.27508277e-01, -1.97849452e-01,\n",
      "          1.52529091e-01,  1.74571902e-01],\n",
      "        [ 2.25629419e-01, -7.99194574e-02, -9.89855826e-02,\n",
      "         -1.25234798e-01,  2.05572963e-01, -1.05926991e-01,\n",
      "         -4.03092355e-02, -6.06723726e-02],\n",
      "        [ 1.79865062e-02, -3.43427509e-02,  1.66991383e-01,\n",
      "         -3.92277837e-02,  1.18806660e-01, -1.24253064e-01,\n",
      "          2.18887836e-01,  2.04895943e-01],\n",
      "        [ 6.68628514e-02,  2.64581412e-01, -1.20523781e-01,\n",
      "          2.04585493e-01,  3.06045413e-02, -2.55965292e-02,\n",
      "         -2.58643091e-01, -2.19422132e-01],\n",
      "        [-6.99895918e-02, -1.80772424e-01,  1.99155718e-01,\n",
      "          6.42749071e-02,  2.02864110e-01,  3.17669809e-02,\n",
      "         -1.09273374e-01, -2.54002929e-01],\n",
      "        [ 1.37937725e-01,  1.96950883e-01, -6.40278161e-02,\n",
      "          4.82172072e-02, -1.12683862e-01, -9.91961807e-02,\n",
      "          1.38480216e-01,  1.56014830e-01],\n",
      "        [-3.03596705e-02,  3.44735086e-02,  1.31318986e-01,\n",
      "         -2.26613268e-01, -2.63253003e-01,  2.08236605e-01,\n",
      "          9.82511342e-02, -1.84199542e-01],\n",
      "        [-1.84609085e-01, -1.54935732e-01, -9.35669541e-02,\n",
      "          7.17114210e-02, -1.43562213e-01,  1.05172873e-01,\n",
      "         -1.37215316e-01, -3.94968092e-02],\n",
      "        [ 2.63615161e-01,  3.88310552e-02, -2.17945427e-01,\n",
      "         -1.86553597e-03,  1.26122743e-01, -2.91515440e-02,\n",
      "          1.34125471e-01, -1.61678582e-01],\n",
      "        [-5.70029914e-02,  2.47176319e-01, -3.97436619e-02,\n",
      "         -1.14795551e-01,  1.27410322e-01, -1.77778929e-01,\n",
      "         -1.58459961e-01,  7.98816085e-02],\n",
      "        [-1.09703615e-01,  7.51356781e-02, -1.83258533e-01,\n",
      "         -6.11813813e-02,  2.01971382e-01,  1.33668780e-02,\n",
      "         -1.71520591e-01, -1.30737796e-01]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_5/bias:0' shape=(20,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8f3f7ea323f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-97a188d5a767>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(context, target, weight, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-c5384877c902>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(context, target, weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    511\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1271\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1272\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0']."
     ]
    }
   ],
   "source": [
    "train(train_context, train_target, train_weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
