{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for func load_data \n",
    "def convert_ohc(seq):\n",
    "    \"\"\"\n",
    "    One hot encodes given amino acid sequence string.\n",
    "    \n",
    "    :param seq: string of amino acid sequence \n",
    "    :return: 2D array of one hot encoded string \n",
    "    \n",
    "    \"\"\"\n",
    "    seq_idx = [sym_codes.index(sym) for sym in seq]\n",
    "    x = np.array(seq_idx)\n",
    "    x = keras.utils.to_categorical(x, num_classes=len(sym_codes), dtype='int32')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_ohc('ASSSSSSGGHH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seqs_path, label_path):\n",
    "    \"\"\"\n",
    "    Loads sequences and lables from fasta files. \n",
    "    \n",
    "    :param seq_path: path for fasta file of amino acid sequences \n",
    "    :param label_path: path fasta file of labels of amino acid sequences where disordered residues are labeled are labeled as 1 and ordered residues are labeled as 0\n",
    "    :return: array all one hot encoded sequences and array of all labels from \n",
    "    \"\"\"\n",
    "    seq_ohc_lst = []\n",
    "    label_lst = []\n",
    "    \n",
    "    for record_seq, record_label in zip(SeqIO.parse(seqs_path, 'fasta'), SeqIO.parse(label_path, 'fasta')):\n",
    "        \n",
    "        # one hot encode each record_seq \n",
    "        seq = str(record_seq.seq)\n",
    "        seq_ohc = convert_ohc(seq)\n",
    "        seq_ohc_lst.append(seq_ohc)\n",
    "        \n",
    "        # expand the dimension of record_label for broadcasting\n",
    "        label = [int(sym) for sym in record_label]\n",
    "        label_lst.append(label)\n",
    "        \n",
    "    return np.array(seq_ohc_lst), np.array(label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_target_context(seq_ohc, label):\n",
    "    \"\"\"\n",
    "    Gets the target, context, and weight from one hot encoded sequences and labels. \n",
    "    \n",
    "    :param seq_ohc: one hot ended 2D arrays of sequences \n",
    "    :param label: array of labels corresponding to seq_ohc \n",
    "    :return: target, context and weight according to seq_ohc and label \n",
    "    \n",
    "    \"\"\"\n",
    "    weight = np.expand_dims(label, axis = 2)\n",
    "\n",
    "    # get the target from the record \n",
    "    target = weight*seq_ohc\n",
    "        \n",
    "    # get the context from the record (inverted the weight)\n",
    "    context = (np.invert(weight) + 2)*seq_ohc\n",
    "    \n",
    "    return weight, target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make generative model\n",
    "def make_generative_model():\n",
    "    \"\"\"\n",
    "    Makes generative generative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of generative model \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # convolution \n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(8, 3, strides = 1, padding='same', name='first'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "\n",
    "    model.add(keras.layers.Conv1D(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(256, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    # deconvolution \n",
    "    model.add(keras.layers.Conv1DTranspose(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(8, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    #FIXEME: PLAY AROUND WITH THE RATIO OF FILTER \n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(20, 3, strides = 1, padding='same', activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (Conv1D)               (None, 180, 8)            488       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 180, 16)           400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 180, 32)           1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 180, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 180, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 180, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 180, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 180, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 180, 64)           24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 180, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 180, 16)           1552      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, 180, 8)            392       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTr (None, 180, 20)           500       \n",
      "=================================================================\n",
      "Total params: 266,628\n",
      "Trainable params: 265,124\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generative_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make discrimator model\n",
    "def make_discriminator_model():\n",
    "    \"\"\"\n",
    "    Makes adverserial/discriminative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of discriminative model \n",
    "    \n",
    "    \"\"\"\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(25, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(13, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(7, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(4, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 90, 25)            2025      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 90, 25)            100       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 90, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 45, 13)            1313      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 45, 13)            52        \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 45, 13)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 23, 7)             371       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 23, 7)             28        \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 23, 7)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 12, 4)             116       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 4)             16        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 12, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 4,070\n",
      "Trainable params: 3,972\n",
      "Non-trainable params: 98\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tensorflow.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, generated_target, target):\n",
    "    generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "    ones_like_fake_output = tensorflow.cast(tensorflow.ones_like(fake_output), tensorflow.int64)\n",
    "    print(ones_like_fake_output.dtype)\n",
    "    print(fake_output.dtype)\n",
    "    a = cross_entropy(ones_like_fake_output, fake_output)\n",
    "    print(generated_target.dtype)\n",
    "    print(target.dtype)\n",
    "    b = cross_entropy(generated_target, target)\n",
    "    print('a')\n",
    "    print(a)\n",
    "    print('b')\n",
    "    print(b)\n",
    "    print(tensorflow.shape(target))\n",
    "    print(tensorflow.shape(generated_target))\n",
    "    print(target[0][0])\n",
    "    print(generated_target[0][0])\n",
    "    return  a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, weight):\n",
    "    \n",
    "    real_loss = cross_entropy(tensorflow.cast(tensorflow.ones_like(real_output), tensorflow.int64), real_output, weight)\n",
    "    fake_loss = cross_entropy(tensorflow.cast(tensorflow.zeros_like(fake_output), tensorflow.int64), fake_output, weight)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(context, target, weight):\n",
    "\n",
    "    with tensorflow.GradientTape() as gen_tape, tensorflow.GradientTape() as disc_tape:\n",
    "        generated_target = generator(context, training=True)*weight\n",
    "        generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "        \n",
    "        real_output = discriminator(target, training=True)\n",
    "        fake_output = discriminator(generated_target, training=True)\n",
    "        \n",
    "        print(fake_output.shape)\n",
    "        print(generated_target.shape)\n",
    "        print(target.shape)\n",
    "        \n",
    "        target = tensorflow.cast(tensorflow.constant(target), dtype = tensorflow.float32)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output, generated_target, target)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, weight)\n",
    "    \n",
    "        #backpropogration \n",
    "        print(gen_loss)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        print(gradients_of_generator)\n",
    "        print(generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, target, weight, epochs):\n",
    "    \n",
    "    # batch data \n",
    "    context_batch = np.array_split(context, BATCH_SIZE)\n",
    "    target_batch = np.array_split(target, BATCH_SIZE)\n",
    "    weight_batch = np.array_split(weight, BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for context, target, weight in zip(context_batch, target_batch, weight_batch):\n",
    "            \n",
    "            train_step(context, target, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')\n",
    "train_weight, train_target, train_context = get_weight_target_context(train_seq, train_label)\n",
    "\n",
    "\n",
    "#test_data = load_data('../../inpainting_mobidb/out/test_seq.fasta','../../inpainting_mobidb/out/test_label.fasta')\n",
    "\n",
    "#valid_data = load_data('../../inpainting_mobidb/out/validation_seq.fasta','../../inpainting_mobidb/out/validation_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "contxt = train_context[:5]\n",
    "trgt = train_target[:5]\n",
    "wght = train_weight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 20)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contxt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 20)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgt[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 180, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wght.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 180, 20), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(contxt, training=True)*wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = make_generative_model()\n",
    "g.predict(contxt)*wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n",
      "(150, 180, 20)\n",
      "(150, 180, 20)\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "a\n",
      "tf.Tensor(1.1920929e-07, shape=(), dtype=float32)\n",
      "b\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(20,), dtype=int64)\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[<tf.Variable 'first/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[ 0.20792308, -0.16447456, -0.26479656,  0.25574127,\n",
      "          0.25305048, -0.12804231,  0.09525892, -0.03784551],\n",
      "        [-0.02832726, -0.09010078, -0.22396563,  0.10030249,\n",
      "          0.06421399, -0.0742861 , -0.13432868,  0.13541797],\n",
      "        [-0.13206916,  0.16820174,  0.13754582,  0.23288593,\n",
      "          0.2612554 ,  0.22595152, -0.0340534 , -0.16224487],\n",
      "        [-0.04724893,  0.1478022 ,  0.1351313 , -0.03378265,\n",
      "         -0.14034225, -0.17224878,  0.23669252, -0.07822336],\n",
      "        [-0.2626967 , -0.00754523, -0.1707534 , -0.02136163,\n",
      "          0.07179624,  0.07891792,  0.2594665 ,  0.05237073],\n",
      "        [ 0.18645644,  0.20763719,  0.11393827,  0.03937095,\n",
      "         -0.18432526, -0.24329874,  0.03748402,  0.20728895],\n",
      "        [ 0.19557238,  0.21471304,  0.06738037, -0.09067433,\n",
      "          0.20266792,  0.06235802,  0.08058679, -0.00841099],\n",
      "        [ 0.14633855, -0.05781887, -0.23472413,  0.14705944,\n",
      "          0.14941841, -0.05985664,  0.07989678,  0.15584713],\n",
      "        [ 0.12752593, -0.21388678, -0.05894753,  0.23786929,\n",
      "          0.21782696, -0.21875365, -0.06700036, -0.09506419],\n",
      "        [ 0.13953549, -0.09812669, -0.13382573,  0.14804256,\n",
      "          0.18245769,  0.06695294,  0.15636358,  0.09684777],\n",
      "        [ 0.0381873 ,  0.05338854, -0.03033973, -0.18647218,\n",
      "         -0.0138934 ,  0.06458396,  0.2619609 , -0.08657464],\n",
      "        [ 0.16988745, -0.18153223, -0.0418008 ,  0.06679416,\n",
      "         -0.0339155 ,  0.15962851, -0.03180732, -0.23997217],\n",
      "        [-0.03268838, -0.11137977, -0.1065923 , -0.15289587,\n",
      "          0.04284051,  0.01134872, -0.16533038, -0.19094042],\n",
      "        [-0.26418954, -0.05868654, -0.09039593,  0.19412062,\n",
      "          0.15209177, -0.1711888 ,  0.23980162,  0.14382571],\n",
      "        [ 0.01494515, -0.25371492,  0.03205112, -0.05385484,\n",
      "         -0.01623321, -0.2638386 ,  0.13504508,  0.09446484],\n",
      "        [-0.16533694,  0.01978341, -0.1861569 ,  0.08084735,\n",
      "         -0.16946575,  0.09965515, -0.24354783, -0.20832147],\n",
      "        [-0.18636417, -0.11881144,  0.07557368, -0.24726404,\n",
      "         -0.17472991, -0.14717196, -0.11799258, -0.2362631 ],\n",
      "        [ 0.2392725 ,  0.06511328, -0.25169215,  0.09058881,\n",
      "         -0.04662766, -0.03724456, -0.16103494, -0.16421822],\n",
      "        [ 0.03078538, -0.18919125, -0.11340046, -0.17729172,\n",
      "         -0.1604405 , -0.07104881, -0.18334135, -0.24838533],\n",
      "        [ 0.22543755,  0.21305522, -0.19112304,  0.01515403,\n",
      "         -0.24509776, -0.01971848, -0.26427454, -0.18171236]],\n",
      "\n",
      "       [[-0.10193512,  0.17414215, -0.02989158,  0.23004657,\n",
      "          0.17394719, -0.2664841 , -0.1526942 ,  0.08871645],\n",
      "        [ 0.15066227, -0.09317151,  0.13968575, -0.02007914,\n",
      "         -0.25477925,  0.2017838 ,  0.15977299, -0.15780556],\n",
      "        [ 0.2640194 , -0.085611  , -0.09686625, -0.25853255,\n",
      "          0.14340788, -0.12351532,  0.19677088, -0.11817698],\n",
      "        [ 0.08196551,  0.12805188,  0.17925316,  0.03325331,\n",
      "         -0.25135747, -0.11102204, -0.14200592,  0.14564842],\n",
      "        [ 0.2554135 , -0.04846686,  0.24415597, -0.04496723,\n",
      "         -0.23654506, -0.15483347,  0.16262567,  0.11677405],\n",
      "        [ 0.10386476, -0.05512396, -0.20622674, -0.16846848,\n",
      "          0.24720946,  0.00294897, -0.04934162, -0.2007094 ],\n",
      "        [ 0.11301726, -0.21799067,  0.02476498, -0.22312829,\n",
      "          0.10438752, -0.10646218, -0.0914561 ,  0.09659761],\n",
      "        [-0.22661072, -0.12274016, -0.04640183,  0.2442846 ,\n",
      "         -0.03056498, -0.26176754,  0.16682309, -0.07411934],\n",
      "        [-0.23242733, -0.0818823 ,  0.06903812,  0.00177491,\n",
      "         -0.19136232,  0.21052995, -0.04324239,  0.01697382],\n",
      "        [-0.032502  ,  0.10747004, -0.15055561, -0.25234503,\n",
      "          0.2167348 ,  0.12292609, -0.09951243,  0.1384216 ],\n",
      "        [-0.13146426,  0.11177024, -0.17710775,  0.17406046,\n",
      "          0.16409051, -0.04570141, -0.1683344 ,  0.02168825],\n",
      "        [-0.04995817,  0.2625651 ,  0.14633027,  0.18326256,\n",
      "          0.20409021, -0.20650704, -0.1825462 ,  0.2642379 ],\n",
      "        [-0.17657398, -0.18535142, -0.00452781,  0.03015807,\n",
      "         -0.09468174,  0.19701666,  0.230382  , -0.0129973 ],\n",
      "        [-0.2509976 , -0.22490907,  0.17928526,  0.18226519,\n",
      "          0.04964676,  0.14701062,  0.19079152, -0.22062078],\n",
      "        [ 0.18010247,  0.00593698,  0.19854611, -0.07337134,\n",
      "         -0.18670839, -0.17136595, -0.12393326, -0.21913266],\n",
      "        [-0.15879276,  0.13489228, -0.0164766 , -0.20914307,\n",
      "          0.03430101,  0.09265175,  0.00926459, -0.01863034],\n",
      "        [ 0.25777474,  0.17229435,  0.01433986,  0.00788701,\n",
      "         -0.11481263, -0.16226953, -0.19226855,  0.23026326],\n",
      "        [-0.02462646,  0.03171888, -0.01178145,  0.09796217,\n",
      "         -0.03248212, -0.0022091 , -0.2355203 ,  0.19056505],\n",
      "        [ 0.16298658,  0.07741451, -0.09803055,  0.16379493,\n",
      "         -0.18041591,  0.18503198,  0.20573539,  0.21356276],\n",
      "        [-0.01907033,  0.19450447, -0.08344547,  0.19865748,\n",
      "         -0.10440287, -0.1244836 ,  0.19946694,  0.04711825]],\n",
      "\n",
      "       [[ 0.06867906,  0.2074754 ,  0.26200882, -0.15448931,\n",
      "         -0.21162994, -0.18646085,  0.16193143, -0.02151227],\n",
      "        [ 0.24451867, -0.11227402,  0.16267344,  0.21237254,\n",
      "         -0.216562  ,  0.13286561,  0.15103659, -0.08035645],\n",
      "        [ 0.26034716,  0.17852074,  0.18685418, -0.15433663,\n",
      "          0.17292601, -0.06116761, -0.14298013, -0.0444618 ],\n",
      "        [ 0.10700959, -0.06117392, -0.09094444,  0.26233414,\n",
      "          0.010115  , -0.22124115, -0.12265918, -0.24686076],\n",
      "        [ 0.18690649, -0.14734279,  0.00803274,  0.01375073,\n",
      "         -0.19599023, -0.19758439,  0.20226604, -0.1825455 ],\n",
      "        [-0.22976767,  0.00595808, -0.07280436, -0.00330088,\n",
      "          0.22365692,  0.15358385,  0.19523942,  0.22053507],\n",
      "        [-0.20633073, -0.17432676, -0.20241436, -0.08243673,\n",
      "         -0.17000061, -0.11716715,  0.09344557,  0.07291618],\n",
      "        [-0.25604063,  0.15345636, -0.08071202, -0.16884837,\n",
      "         -0.17146121,  0.18606043,  0.01585132,  0.16156033],\n",
      "        [-0.0209897 , -0.03654484, -0.14003429, -0.12839507,\n",
      "          0.24303517,  0.10031116, -0.04545374,  0.05477941],\n",
      "        [ 0.11692372, -0.02245189, -0.1632347 ,  0.11008516,\n",
      "         -0.16327389, -0.24112493, -0.16935971,  0.1931229 ],\n",
      "        [ 0.10158053,  0.17238969,  0.1286625 , -0.21542116,\n",
      "          0.18633422, -0.17449671,  0.15121505,  0.11970803],\n",
      "        [ 0.0835053 , -0.09170003, -0.11612953,  0.16971508,\n",
      "          0.09394544, -0.1489588 ,  0.23779133,  0.06652397],\n",
      "        [ 0.1885708 ,  0.06792608,  0.24722871, -0.05987263,\n",
      "         -0.1739217 ,  0.26399574,  0.04983118,  0.06531405],\n",
      "        [-0.21321142, -0.07302317, -0.16084021,  0.25911233,\n",
      "          0.08265325, -0.2522525 ,  0.10424161, -0.14068386],\n",
      "        [-0.17277971, -0.19567999, -0.12714423, -0.23366147,\n",
      "         -0.23872721, -0.15840515, -0.22795579, -0.20346524],\n",
      "        [ 0.19619364,  0.12260425, -0.2359529 ,  0.09689787,\n",
      "         -0.07054332, -0.24363193,  0.18120998, -0.18415782],\n",
      "        [ 0.14742422,  0.03587782,  0.05858147,  0.10058081,\n",
      "          0.20534262, -0.17864227,  0.08809635, -0.18706688],\n",
      "        [-0.03674117,  0.13380554,  0.01034048, -0.12374808,\n",
      "          0.19312915,  0.25121936,  0.11081508, -0.0595293 ],\n",
      "        [-0.05851297, -0.2074413 , -0.25038964,  0.01596206,\n",
      "          0.19819942,  0.06476638, -0.25805324, -0.02949804],\n",
      "        [-0.17429905,  0.26156208,  0.03082272,  0.05342403,\n",
      "         -0.22748916,  0.12752745,  0.13354823, -0.1509361 ]]],\n",
      "      dtype=float32)>, <tf.Variable 'first/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[-0.1979013 ,  0.04056913, -0.14447384,  0.05854347,\n",
      "          0.12636662,  0.1131556 ,  0.2638762 ,  0.09560242,\n",
      "         -0.01752567, -0.00608975, -0.08897762, -0.18733451,\n",
      "          0.16984162,  0.21461916, -0.11511652, -0.16166838],\n",
      "        [ 0.2582053 , -0.2807529 , -0.06835997,  0.13040158,\n",
      "          0.02753708, -0.06283177, -0.07893661, -0.24278799,\n",
      "          0.23575485,  0.22405863, -0.01994935, -0.1258471 ,\n",
      "          0.04195777,  0.26559353,  0.11328411,  0.01643679],\n",
      "        [ 0.0246138 , -0.27213573, -0.2483464 ,  0.00361782,\n",
      "         -0.2603853 ,  0.11009604,  0.17779261, -0.25222513,\n",
      "         -0.1468084 , -0.20463553,  0.05863583,  0.16203964,\n",
      "         -0.01926365, -0.11686181, -0.04990256,  0.02668288],\n",
      "        [ 0.03011054, -0.07297638,  0.17925459, -0.11958674,\n",
      "         -0.11510544,  0.10785118, -0.08389376,  0.01605314,\n",
      "         -0.08975349,  0.27337533, -0.26484078, -0.0601301 ,\n",
      "         -0.1906091 , -0.2521285 , -0.07103674, -0.241817  ],\n",
      "        [-0.04222411, -0.11041395, -0.18372427, -0.12093462,\n",
      "          0.27605897,  0.01873603, -0.0578815 ,  0.26777428,\n",
      "          0.2433706 ,  0.23731065,  0.22715932, -0.1416928 ,\n",
      "         -0.13542852, -0.21118386, -0.06961666,  0.13654894],\n",
      "        [ 0.25673616, -0.00571629, -0.10308066, -0.13393617,\n",
      "          0.24140519, -0.27367976, -0.23575884,  0.01158196,\n",
      "         -0.21914113, -0.12106188,  0.13053462, -0.12941007,\n",
      "         -0.2792733 , -0.2885824 , -0.09697239,  0.26445228],\n",
      "        [-0.15567608, -0.24165815,  0.02392828, -0.12984188,\n",
      "          0.0147213 , -0.22530527,  0.2660992 , -0.13762467,\n",
      "         -0.00120914, -0.00199476,  0.1639337 ,  0.11418709,\n",
      "          0.2279796 ,  0.04506448,  0.03417462, -0.27603835],\n",
      "        [-0.11209033,  0.01554355, -0.02774164, -0.20875949,\n",
      "         -0.12442993,  0.2852854 , -0.00978285,  0.10280865,\n",
      "          0.04670686, -0.19676967,  0.28453904, -0.22171727,\n",
      "          0.2177335 , -0.27738547, -0.02653918,  0.26636302]],\n",
      "\n",
      "       [[ 0.00469315,  0.28086   ,  0.2250467 ,  0.1955288 ,\n",
      "         -0.02888179, -0.02892226, -0.19626236,  0.02082929,\n",
      "          0.0116753 , -0.2524676 ,  0.24143553, -0.05099881,\n",
      "         -0.02755651,  0.15708253,  0.07689866,  0.17853773],\n",
      "        [ 0.09279132,  0.04613256, -0.07887727, -0.13729891,\n",
      "          0.14457068,  0.07288188,  0.08246392,  0.02909517,\n",
      "         -0.20088866, -0.12182316,  0.11636218,  0.07869276,\n",
      "          0.19483176, -0.18521744, -0.23967287, -0.14551538],\n",
      "        [-0.20670277,  0.1590564 ,  0.1261518 , -0.03444538,\n",
      "          0.2084716 ,  0.25036937,  0.21957177,  0.19982648,\n",
      "         -0.13311219, -0.21799195,  0.11937448, -0.09892498,\n",
      "          0.02118567, -0.19838336, -0.04484162, -0.11305809],\n",
      "        [ 0.04782781, -0.25717494, -0.17400411,  0.0577428 ,\n",
      "          0.19091317,  0.15778434, -0.2777658 ,  0.02114809,\n",
      "          0.19415402, -0.04668854, -0.23023023, -0.12580726,\n",
      "         -0.02443913, -0.25195017, -0.18921937,  0.20678681],\n",
      "        [ 0.18210301,  0.09389019, -0.13174622, -0.12063406,\n",
      "         -0.19469932, -0.12179384, -0.25646546,  0.10803878,\n",
      "          0.10190684, -0.24190585, -0.03582576,  0.20715922,\n",
      "          0.10174379, -0.09031497, -0.160483  ,  0.00072342],\n",
      "        [-0.02532214,  0.09745851,  0.06404436, -0.20268798,\n",
      "         -0.26935148, -0.22563991,  0.06526703,  0.02016643,\n",
      "         -0.25756386,  0.20917141, -0.2624507 ,  0.10887778,\n",
      "          0.03140956,  0.24661803, -0.28677663, -0.08918032],\n",
      "        [ 0.1831347 , -0.05608639, -0.02462667,  0.25820345,\n",
      "          0.08888623, -0.24483947, -0.17099485, -0.27878705,\n",
      "         -0.1379752 ,  0.07832742,  0.00686115,  0.22157753,\n",
      "          0.10080171,  0.02945971,  0.13642207,  0.24029201],\n",
      "        [ 0.26448947,  0.02369931,  0.06125644, -0.11907344,\n",
      "          0.07496956,  0.05082545, -0.24222961,  0.15393355,\n",
      "          0.0974102 , -0.12893242,  0.27370858,  0.17277077,\n",
      "         -0.10152782,  0.1683993 ,  0.15967837,  0.02673981]],\n",
      "\n",
      "       [[-0.200315  , -0.00553811,  0.23122501,  0.13021472,\n",
      "          0.07168818, -0.01098394, -0.05138052,  0.12635347,\n",
      "          0.07153884,  0.03899077,  0.08000243,  0.20762035,\n",
      "         -0.2736541 , -0.15534386,  0.01242527, -0.25825748],\n",
      "        [-0.25047696,  0.22697306,  0.03765079,  0.2054869 ,\n",
      "         -0.22109522,  0.1714924 , -0.15186626,  0.27966493,\n",
      "         -0.03425983,  0.02771404, -0.02293548,  0.20705888,\n",
      "          0.0026398 , -0.0858102 , -0.09328783,  0.05310899],\n",
      "        [ 0.16393721, -0.07235806, -0.19481274,  0.20311236,\n",
      "          0.0244877 ,  0.03342882,  0.07844999,  0.10356477,\n",
      "          0.01324251,  0.278696  ,  0.01561645, -0.0370672 ,\n",
      "          0.09893793,  0.20926204, -0.15382777, -0.21416841],\n",
      "        [-0.1215844 , -0.1655966 , -0.23186979,  0.0879882 ,\n",
      "         -0.14632311, -0.03356764, -0.07595542, -0.06450416,\n",
      "          0.0899305 ,  0.13278306, -0.09830445,  0.0011763 ,\n",
      "         -0.27708003, -0.23176992,  0.17649284,  0.00584784],\n",
      "        [ 0.28081465,  0.07622775,  0.2287637 , -0.05472502,\n",
      "         -0.04597008,  0.13733634, -0.06261545, -0.14558496,\n",
      "          0.21733493, -0.25124335, -0.13099079, -0.26233476,\n",
      "          0.02459782, -0.12744   ,  0.15954924, -0.06842212],\n",
      "        [-0.2284824 ,  0.11636138, -0.05619796,  0.01388177,\n",
      "          0.15154105, -0.26201707,  0.16314426,  0.15989447,\n",
      "          0.17595077, -0.23701036,  0.27716053, -0.04747508,\n",
      "          0.03057751, -0.18934512, -0.14351214,  0.10626233],\n",
      "        [-0.1361127 ,  0.23894328, -0.22870767,  0.27601177,\n",
      "         -0.25453272, -0.18101619,  0.1834723 ,  0.07214037,\n",
      "         -0.14029957,  0.14999971, -0.04608357, -0.26685104,\n",
      "          0.14389303,  0.09917805,  0.12183926,  0.28029102],\n",
      "        [ 0.01064029,  0.14797801,  0.06396052, -0.08050472,\n",
      "         -0.01922703,  0.01262906,  0.22177547, -0.06988233,\n",
      "          0.13781476,  0.2065793 , -0.21638858,  0.169801  ,\n",
      "          0.04685399, -0.21968484,  0.0633477 , -0.03668642]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_1/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[-0.06289449, -0.04590601, -0.185158  , ..., -0.04316382,\n",
      "          0.03501575,  0.13368359],\n",
      "        [ 0.12950757,  0.13869804, -0.15143692, ..., -0.12517315,\n",
      "          0.02782126, -0.10977832],\n",
      "        [-0.07399164, -0.03562132,  0.03586242, ..., -0.0022196 ,\n",
      "         -0.03920802,  0.16427198],\n",
      "        ...,\n",
      "        [ 0.05708101,  0.12384105,  0.06273672, ..., -0.19547608,\n",
      "          0.00145392,  0.05888698],\n",
      "        [ 0.01239149,  0.02100629,  0.0761705 , ...,  0.14121768,\n",
      "          0.09154481, -0.12617871],\n",
      "        [-0.0044248 , -0.08275929, -0.1145786 , ...,  0.09678945,\n",
      "         -0.10508566,  0.17507994]],\n",
      "\n",
      "       [[ 0.05634665, -0.18797952,  0.1563136 , ...,  0.08266917,\n",
      "         -0.09130555,  0.04358591],\n",
      "        [ 0.17314845, -0.09757688,  0.15845504, ...,  0.09860867,\n",
      "          0.03182495, -0.1214531 ],\n",
      "        [-0.17302434,  0.12539187,  0.17046222, ...,  0.07306647,\n",
      "          0.08509251, -0.18764974],\n",
      "        ...,\n",
      "        [ 0.05514589, -0.0757326 ,  0.19935167, ...,  0.17724475,\n",
      "         -0.07943694,  0.0640111 ],\n",
      "        [-0.15033132, -0.04876253,  0.12499553, ..., -0.01803462,\n",
      "         -0.15602477, -0.17580001],\n",
      "        [ 0.19337538,  0.06684923,  0.15311423, ..., -0.09623503,\n",
      "         -0.09477736, -0.01056258]],\n",
      "\n",
      "       [[-0.09572446,  0.14775258,  0.18624136, ..., -0.18117781,\n",
      "         -0.18704855, -0.10539061],\n",
      "        [ 0.1675584 , -0.0482267 ,  0.19530386, ...,  0.14501795,\n",
      "          0.04847869,  0.15121341],\n",
      "        [ 0.00112031,  0.01994014, -0.00560492, ...,  0.07925585,\n",
      "          0.0699046 , -0.08480082],\n",
      "        ...,\n",
      "        [ 0.12892133,  0.14803913, -0.12535405, ..., -0.03408748,\n",
      "         -0.15949127, -0.04489198],\n",
      "        [-0.06801178,  0.10612491,  0.1075379 , ...,  0.130615  ,\n",
      "          0.14789101, -0.20368561],\n",
      "        [-0.07893679, -0.02802567, -0.18030652, ...,  0.09335703,\n",
      "         -0.15753515, -0.04295027]]], dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[-0.08264323, -0.12629595,  0.14328414, ..., -0.0931533 ,\n",
      "          0.03747419, -0.04151486],\n",
      "        [-0.12410094,  0.04635064, -0.05258913, ...,  0.0923283 ,\n",
      "         -0.02367233, -0.02450639],\n",
      "        [-0.13961607, -0.09274149,  0.0971316 , ...,  0.12441   ,\n",
      "         -0.02152491,  0.0896464 ],\n",
      "        ...,\n",
      "        [-0.10684945, -0.01274621,  0.12569827, ..., -0.00766069,\n",
      "         -0.04453104, -0.05802507],\n",
      "        [ 0.13110772, -0.07844302, -0.1260384 , ..., -0.02552229,\n",
      "         -0.13886273,  0.05733743],\n",
      "        [-0.05647732, -0.04446517,  0.03030318, ...,  0.01261796,\n",
      "          0.08529143,  0.06124851]],\n",
      "\n",
      "       [[ 0.01517451, -0.02810108, -0.10053082, ...,  0.09478568,\n",
      "         -0.02292729,  0.04305759],\n",
      "        [ 0.05114104,  0.01493624, -0.11414877, ..., -0.13912967,\n",
      "          0.02969109,  0.10710496],\n",
      "        [-0.08964324, -0.0820545 , -0.13801157, ...,  0.114241  ,\n",
      "         -0.13221674, -0.02278282],\n",
      "        ...,\n",
      "        [-0.0616009 , -0.12847239, -0.11872904, ...,  0.05093876,\n",
      "         -0.09407333,  0.00356908],\n",
      "        [-0.09079799,  0.0839038 , -0.10864775, ..., -0.08221899,\n",
      "          0.02164964,  0.03764312],\n",
      "        [ 0.0587817 , -0.00551148,  0.00674273, ..., -0.13515283,\n",
      "          0.11083111,  0.13609928]],\n",
      "\n",
      "       [[ 0.0006462 , -0.09158763,  0.0190039 , ..., -0.07193636,\n",
      "          0.09373698, -0.02954707],\n",
      "        [-0.14159164,  0.04610333, -0.06008447, ..., -0.13759933,\n",
      "          0.00363134, -0.10380886],\n",
      "        [ 0.08767875,  0.11850998,  0.11627495, ...,  0.03757831,\n",
      "          0.05670263,  0.11373338],\n",
      "        ...,\n",
      "        [ 0.02202231,  0.02816685, -0.06793773, ...,  0.02682553,\n",
      "          0.06008635,  0.13425002],\n",
      "        [-0.06364226,  0.11412024, -0.06077623, ..., -0.10061581,\n",
      "         -0.0380603 ,  0.0211371 ],\n",
      "        [-0.09286   ,  0.11901543, -0.13316233, ..., -0.0742851 ,\n",
      "         -0.02996398,  0.05819783]]], dtype=float32)>, <tf.Variable 'conv1d_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_3/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[-0.10108173, -0.08200864,  0.07940535, ...,  0.08924383,\n",
      "          0.08316921,  0.07847041],\n",
      "        [ 0.08219096,  0.09839252,  0.0577141 , ...,  0.10094465,\n",
      "          0.09574561, -0.08047162],\n",
      "        [ 0.05959867, -0.047365  , -0.0441021 , ..., -0.00049779,\n",
      "          0.07981056,  0.01071177],\n",
      "        ...,\n",
      "        [-0.01377799,  0.03438774,  0.09788525, ...,  0.02112266,\n",
      "          0.07424279,  0.07233708],\n",
      "        [-0.04082871,  0.10205577, -0.05967863, ...,  0.03276226,\n",
      "         -0.05279921,  0.0879679 ],\n",
      "        [ 0.0663799 ,  0.01363213,  0.06087561, ...,  0.09450684,\n",
      "         -0.07926945, -0.04054029]],\n",
      "\n",
      "       [[ 0.09012128, -0.0936914 ,  0.03519475, ..., -0.09435301,\n",
      "         -0.00111876, -0.08366717],\n",
      "        [ 0.10053912, -0.07559729,  0.07169367, ...,  0.083667  ,\n",
      "          0.02269918, -0.02917104],\n",
      "        [-0.03660879, -0.04585837, -0.04733322, ..., -0.07597616,\n",
      "          0.05367477,  0.00428805],\n",
      "        ...,\n",
      "        [-0.00813051, -0.02306219, -0.06036912, ...,  0.00310807,\n",
      "          0.06482001, -0.03959471],\n",
      "        [ 0.05447216,  0.02389513, -0.07471672, ...,  0.04773529,\n",
      "         -0.07296671, -0.06137392],\n",
      "        [-0.0972547 ,  0.05243668, -0.04470202, ..., -0.08509411,\n",
      "         -0.07248342,  0.01252825]],\n",
      "\n",
      "       [[ 0.10191697, -0.08332436, -0.05075035, ..., -0.07155257,\n",
      "          0.05616558, -0.01156605],\n",
      "        [-0.06172074,  0.00080734, -0.01588167, ..., -0.00790335,\n",
      "          0.06590343,  0.03507124],\n",
      "        [ 0.04995783, -0.04490297, -0.04897671, ..., -0.06429636,\n",
      "          0.04832579, -0.03154553],\n",
      "        ...,\n",
      "        [-0.02464097, -0.00386048, -0.00102035, ...,  0.00041048,\n",
      "         -0.07051905, -0.09928109],\n",
      "        [-0.00364835,  0.08668345,  0.05690773, ..., -0.06280071,\n",
      "          0.06508969, -0.08161753],\n",
      "        [ 0.08327501, -0.03336287, -0.03687821, ..., -0.00557539,\n",
      "         -0.06148782, -0.08351822]]], dtype=float32)>, <tf.Variable 'conv1d_3/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_4/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_4/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[-0.03117111,  0.04648496, -0.05934156, ..., -0.00793003,\n",
      "          0.00374322, -0.05723373],\n",
      "        [-0.00891908, -0.06273372,  0.05351909, ...,  0.02608745,\n",
      "         -0.04907884,  0.05057942],\n",
      "        [-0.01053925, -0.04234102, -0.02021297, ...,  0.03705542,\n",
      "          0.06995472, -0.05744787],\n",
      "        ...,\n",
      "        [-0.03665132, -0.01408026,  0.02367949, ..., -0.01153048,\n",
      "         -0.05284229,  0.03257463],\n",
      "        [ 0.00540809, -0.00054538, -0.03228107, ..., -0.06995324,\n",
      "         -0.02616187, -0.05314574],\n",
      "        [-0.0034432 , -0.00515416, -0.05420114, ..., -0.03278994,\n",
      "         -0.05138597, -0.01694852]],\n",
      "\n",
      "       [[ 0.0101837 ,  0.06891091, -0.00126529, ...,  0.04710786,\n",
      "         -0.06203608, -0.03921659],\n",
      "        [-0.04664756,  0.0381005 ,  0.05546843, ...,  0.02233092,\n",
      "          0.04215492,  0.02688769],\n",
      "        [ 0.05380708, -0.00514433,  0.01821584, ...,  0.06784825,\n",
      "          0.00042235,  0.06309971],\n",
      "        ...,\n",
      "        [-0.06583348, -0.04461966,  0.05500568, ...,  0.00430135,\n",
      "         -0.00844401, -0.02758747],\n",
      "        [ 0.06701282, -0.04653076,  0.02368129, ..., -0.02649665,\n",
      "         -0.02109645, -0.061961  ],\n",
      "        [ 0.06669156, -0.03784049, -0.02465437, ..., -0.01595819,\n",
      "         -0.04537806,  0.05321088]],\n",
      "\n",
      "       [[ 0.01276606, -0.05589029, -0.03526397, ..., -0.06331231,\n",
      "         -0.04883742, -0.04760389],\n",
      "        [ 0.04096209, -0.00558098, -0.06521935, ...,  0.00916512,\n",
      "          0.00065651, -0.03947675],\n",
      "        [ 0.04379457, -0.06435342, -0.05566021, ...,  0.01864149,\n",
      "          0.02142676,  0.06361687],\n",
      "        ...,\n",
      "        [ 0.05900134,  0.03634443,  0.02485012, ...,  0.02905672,\n",
      "          0.03590782,  0.0560745 ],\n",
      "        [ 0.05034708, -0.00901898,  0.04196894, ...,  0.00764958,\n",
      "          0.05282369, -0.02839601],\n",
      "        [ 0.05055353,  0.04483618, -0.00634979, ..., -0.03675494,\n",
      "         -0.04480127, -0.03061994]]], dtype=float32)>, <tf.Variable 'conv1d_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_5/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_5/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv1d_transpose/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[ 0.05193184,  0.00558221,  0.06833702, ..., -0.06896845,\n",
      "         -0.02049216,  0.02018293],\n",
      "        [ 0.01606429, -0.03001149,  0.06011811, ..., -0.02425632,\n",
      "          0.01792794,  0.00770015],\n",
      "        [-0.01590785,  0.04429426,  0.06881809, ...,  0.04073507,\n",
      "          0.02652866,  0.05027831],\n",
      "        ...,\n",
      "        [-0.04998843, -0.03119952,  0.02699284, ..., -0.06164762,\n",
      "         -0.05158909,  0.01060508],\n",
      "        [-0.03507945,  0.06711593,  0.04465564, ...,  0.06311195,\n",
      "          0.05454274,  0.06343047],\n",
      "        [ 0.02484629,  0.03703257, -0.02641921, ..., -0.00746244,\n",
      "         -0.03416545,  0.01773252]],\n",
      "\n",
      "       [[ 0.00958741,  0.06723994,  0.04968005, ..., -0.0208638 ,\n",
      "          0.02609509,  0.02237108],\n",
      "        [ 0.03666224, -0.07024635,  0.07076758, ..., -0.07035117,\n",
      "          0.02645023,  0.04772815],\n",
      "        [-0.01229566,  0.01565047, -0.01242538, ..., -0.00746451,\n",
      "          0.06587018, -0.03768231],\n",
      "        ...,\n",
      "        [ 0.00327845, -0.00157139, -0.00088222, ..., -0.03517558,\n",
      "          0.01144981, -0.00294964],\n",
      "        [-0.02441702, -0.05068366,  0.037861  , ...,  0.02831597,\n",
      "         -0.05182797, -0.07031412],\n",
      "        [-0.02136294, -0.06793039,  0.00403732, ..., -0.0296693 ,\n",
      "          0.00398913, -0.02683237]],\n",
      "\n",
      "       [[ 0.00928117, -0.01329248,  0.06302865, ..., -0.06489304,\n",
      "         -0.0399827 ,  0.03374241],\n",
      "        [-0.03905493, -0.04556068, -0.06792455, ...,  0.07136624,\n",
      "         -0.03708821,  0.05216473],\n",
      "        [-0.06030853,  0.04481769, -0.06070355, ...,  0.05180703,\n",
      "          0.03929953,  0.06390427],\n",
      "        ...,\n",
      "        [ 0.02465378,  0.02301795, -0.05787358, ..., -0.01386622,\n",
      "          0.01873063, -0.01345437],\n",
      "        [ 0.00539088,  0.00908934,  0.05203792, ..., -0.05343582,\n",
      "          0.01513432, -0.01006955],\n",
      "        [ 0.07074232, -0.07065821,  0.00783946, ..., -0.07127342,\n",
      "         -0.027539  ,  0.05605888]]], dtype=float32)>, <tf.Variable 'conv1d_transpose/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_6/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_6/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[-0.08360721, -0.01999547, -0.03486562, ..., -0.00772649,\n",
      "         -0.01849075,  0.08969015],\n",
      "        [ 0.0847742 ,  0.03114021, -0.06201939, ...,  0.00951391,\n",
      "         -0.04638067,  0.06635837],\n",
      "        [-0.03615539, -0.07697526, -0.06121115, ...,  0.08345582,\n",
      "          0.07403058,  0.00348465],\n",
      "        ...,\n",
      "        [ 0.01619686,  0.01666129, -0.09446455, ..., -0.09698623,\n",
      "         -0.00707553, -0.05212658],\n",
      "        [-0.07505234, -0.07147008, -0.09314162, ...,  0.01497578,\n",
      "          0.01991592, -0.08330842],\n",
      "        [-0.00396237, -0.03371936, -0.05192992, ...,  0.05374311,\n",
      "         -0.09741175, -0.02809723]],\n",
      "\n",
      "       [[-0.07872414, -0.05540306,  0.04324578, ..., -0.03166442,\n",
      "          0.03398004, -0.05226333],\n",
      "        [ 0.07200724,  0.01209764,  0.04281861, ...,  0.03430226,\n",
      "         -0.03642162,  0.0265332 ],\n",
      "        [ 0.09917854,  0.00537427,  0.07243142, ..., -0.02515042,\n",
      "         -0.06687322,  0.03897588],\n",
      "        ...,\n",
      "        [ 0.04821274, -0.03087037, -0.07318391, ...,  0.08379984,\n",
      "         -0.04599031, -0.01136114],\n",
      "        [-0.0531955 ,  0.08608529,  0.08792478, ...,  0.03467299,\n",
      "         -0.00309152, -0.07999006],\n",
      "        [-0.08018463,  0.05002029, -0.06225058, ...,  0.05774713,\n",
      "         -0.01095959,  0.09853353]],\n",
      "\n",
      "       [[ 0.01654486, -0.06844105, -0.08345542, ...,  0.07245992,\n",
      "         -0.09297626, -0.04898498],\n",
      "        [-0.07539555, -0.09839679, -0.02653667, ...,  0.02969261,\n",
      "          0.0106058 , -0.01374083],\n",
      "        [ 0.07384773,  0.04738362, -0.06389244, ..., -0.0649171 ,\n",
      "          0.0037779 , -0.04906735],\n",
      "        ...,\n",
      "        [-0.06793649,  0.06065091, -0.01553679, ..., -0.00419015,\n",
      "          0.09682906,  0.09998952],\n",
      "        [-0.02653823,  0.09103416,  0.05353242, ...,  0.02065257,\n",
      "         -0.02111328,  0.01062965],\n",
      "        [-0.08815125, -0.07019931, -0.07773939, ..., -0.03430385,\n",
      "         -0.00409964, -0.07610997]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_7/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[-0.03748389,  0.0253353 , -0.03010724, ...,  0.00210923,\n",
      "         -0.11409405,  0.04804558],\n",
      "        [ 0.11795223,  0.1156511 ,  0.08601606, ..., -0.0512993 ,\n",
      "         -0.14144906,  0.00536075],\n",
      "        [-0.08221917,  0.06184117,  0.01608628, ...,  0.0796718 ,\n",
      "          0.10650143,  0.1034507 ],\n",
      "        ...,\n",
      "        [ 0.0775561 , -0.10400344,  0.12968057, ..., -0.12175474,\n",
      "         -0.1182306 ,  0.04910728],\n",
      "        [ 0.00446929,  0.10912803,  0.04779924, ..., -0.03412919,\n",
      "          0.02757257, -0.09442152],\n",
      "        [ 0.10352142, -0.03697706,  0.10410805, ...,  0.12093782,\n",
      "         -0.08134157,  0.13135538]],\n",
      "\n",
      "       [[-0.13797355,  0.13347772, -0.01088627, ...,  0.06555998,\n",
      "         -0.09834471, -0.02131344],\n",
      "        [ 0.07869709,  0.08696097, -0.02414544, ..., -0.13836613,\n",
      "          0.00171259, -0.03332689],\n",
      "        [ 0.12224033, -0.1003252 ,  0.133582  , ...,  0.1356777 ,\n",
      "          0.14308247, -0.1192741 ],\n",
      "        ...,\n",
      "        [-0.03885761,  0.03957918, -0.09729202, ..., -0.04103711,\n",
      "         -0.01169676,  0.02490586],\n",
      "        [ 0.0148396 , -0.03459173,  0.0287395 , ...,  0.10390103,\n",
      "         -0.06735726,  0.06538177],\n",
      "        [-0.14326213, -0.04493449,  0.05535685, ..., -0.0900992 ,\n",
      "         -0.12513766,  0.03193955]],\n",
      "\n",
      "       [[-0.11583224,  0.07885756, -0.1400878 , ..., -0.13119292,\n",
      "          0.01627934,  0.07606131],\n",
      "        [-0.13406602,  0.03507297,  0.1049277 , ...,  0.02167539,\n",
      "          0.01115689, -0.02232111],\n",
      "        [ 0.05175862, -0.0276023 ,  0.09090395, ...,  0.09081586,\n",
      "          0.11221093, -0.13581645],\n",
      "        ...,\n",
      "        [ 0.08321404, -0.11232998, -0.07145372, ...,  0.10211734,\n",
      "          0.06385194, -0.06765249],\n",
      "        [-0.00958055, -0.09383516,  0.05378552, ...,  0.13360053,\n",
      "          0.03538169, -0.04819355],\n",
      "        [-0.02699247, -0.06158394,  0.11701834, ..., -0.02065715,\n",
      "          0.08988681,  0.08667104]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_3/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[ 1.20567858e-01,  1.80502743e-01, -6.85101748e-02, ...,\n",
      "          2.94739902e-02,  6.83397353e-02, -8.33575502e-02],\n",
      "        [-1.12861723e-01, -1.48541689e-01, -9.90225822e-02, ...,\n",
      "          1.59030825e-01, -1.51746646e-01, -2.84922868e-02],\n",
      "        [-1.30022481e-01, -1.72825247e-01,  1.27482206e-01, ...,\n",
      "         -1.41742676e-02, -2.62743831e-02, -5.66947609e-02],\n",
      "        ...,\n",
      "        [ 1.09464437e-01, -1.80090666e-02, -9.30163935e-02, ...,\n",
      "          1.69479728e-01, -1.92742452e-01,  9.24701989e-03],\n",
      "        [-6.76679909e-02, -1.67953670e-02, -7.06984848e-02, ...,\n",
      "         -2.57468224e-03,  1.88031524e-01,  9.49273109e-02],\n",
      "        [ 1.67508870e-02, -1.34300888e-02,  5.71708083e-02, ...,\n",
      "         -1.45515323e-01,  1.74806148e-01, -1.71348885e-01]],\n",
      "\n",
      "       [[-7.94640929e-02,  1.75824970e-01, -1.64586365e-01, ...,\n",
      "         -5.93309999e-02,  4.20976281e-02,  1.32515699e-01],\n",
      "        [ 1.10768080e-02, -5.73565066e-03,  2.08885074e-02, ...,\n",
      "          6.15441799e-02,  1.01112932e-01, -6.47187680e-02],\n",
      "        [-1.93908811e-01,  1.16100699e-01, -1.00801356e-01, ...,\n",
      "          1.56133026e-02, -1.20771222e-01,  3.36357504e-02],\n",
      "        ...,\n",
      "        [ 2.48941928e-02, -5.17391413e-02,  2.33650208e-05, ...,\n",
      "          1.41264856e-01,  1.44794673e-01,  1.49720043e-01],\n",
      "        [-7.74890482e-02,  6.12195134e-02, -1.63222268e-01, ...,\n",
      "          1.06215179e-02, -2.02291057e-01,  2.04025894e-01],\n",
      "        [-5.61629236e-02, -1.77561462e-01,  1.29364491e-01, ...,\n",
      "          4.58967090e-02,  1.01458371e-01,  4.15271968e-02]],\n",
      "\n",
      "       [[-1.74912721e-01,  2.23056823e-02, -5.14226556e-02, ...,\n",
      "         -6.03797287e-02,  1.58253431e-01,  1.26408309e-01],\n",
      "        [-9.21722129e-02, -1.58833236e-01, -1.59384340e-01, ...,\n",
      "          1.96842343e-01,  1.20570660e-01,  1.21597052e-01],\n",
      "        [ 1.80613190e-01, -4.90795374e-02, -1.61560446e-01, ...,\n",
      "         -1.49210095e-02, -1.38916820e-01,  1.34329498e-01],\n",
      "        ...,\n",
      "        [ 9.26508009e-03, -3.43619585e-02, -1.00203633e-01, ...,\n",
      "         -9.67361033e-02, -6.39051199e-04, -2.03028321e-03],\n",
      "        [-5.39319366e-02,  8.40572417e-02,  2.03319490e-02, ...,\n",
      "         -4.12242562e-02,  3.33503634e-02, -2.02508658e-01],\n",
      "        [-1.35035813e-01, -6.41876757e-02,  1.54893249e-01, ...,\n",
      "          1.11241728e-01, -1.70555994e-01,  1.94512337e-01]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_3/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_4/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[-4.61161882e-02,  2.68619537e-01,  8.78254175e-02,\n",
      "          7.50101805e-02,  1.78886175e-01,  1.32295787e-02,\n",
      "          2.77191818e-01,  9.02517140e-02,  1.62114501e-01,\n",
      "          1.24645263e-01,  1.30081177e-03,  1.29722744e-01,\n",
      "         -1.13815039e-01, -2.30089068e-01,  1.30559236e-01,\n",
      "          2.82857120e-02],\n",
      "        [-1.27874777e-01,  1.62418574e-01, -2.75566339e-01,\n",
      "          9.56309736e-02,  9.81810689e-03, -2.64510632e-01,\n",
      "         -1.25316665e-01,  1.06570601e-01,  1.32613003e-01,\n",
      "         -9.16424394e-03,  1.48423672e-01, -2.52063870e-02,\n",
      "          2.14985907e-01,  6.53573871e-02,  2.10021824e-01,\n",
      "         -2.09787190e-02],\n",
      "        [ 2.65993476e-02, -2.43855119e-02,  9.83867049e-03,\n",
      "          1.24172300e-01, -2.45878458e-01, -2.21549124e-01,\n",
      "          1.45581514e-01, -2.88571715e-02,  2.38393247e-01,\n",
      "          1.03489906e-01, -2.14542270e-01, -1.61796510e-02,\n",
      "          2.02527553e-01,  5.92330992e-02, -1.87237054e-01,\n",
      "          1.82841659e-01],\n",
      "        [ 1.21677309e-01,  1.94045901e-02, -3.92753482e-02,\n",
      "          1.42087638e-02,  1.50359392e-01, -2.18253076e-01,\n",
      "          8.94043446e-02, -2.03768536e-01, -1.45248339e-01,\n",
      "         -2.08442956e-01, -2.69059241e-01,  2.43844092e-01,\n",
      "          2.10351825e-01,  4.06992137e-02,  1.33763969e-01,\n",
      "          2.55639970e-01],\n",
      "        [-1.95271745e-01,  5.24992049e-02, -1.50601864e-01,\n",
      "          2.47051775e-01, -1.99128866e-01, -1.49302229e-01,\n",
      "          2.80343592e-02,  8.04662704e-06, -5.47929555e-02,\n",
      "          1.94470406e-01, -4.15162444e-02,  5.52440286e-02,\n",
      "          2.49880612e-01, -2.46041238e-01,  2.33646631e-01,\n",
      "         -1.32290274e-01],\n",
      "        [-1.24866486e-01,  3.44133079e-02,  2.44443536e-01,\n",
      "          2.79234469e-01,  9.20539796e-02, -7.42724538e-03,\n",
      "         -1.67784154e-01, -7.63288140e-03, -8.08352977e-02,\n",
      "          4.60826159e-02, -7.19771683e-02,  2.70282865e-01,\n",
      "          2.28719890e-01,  3.44707668e-02,  1.03387415e-01,\n",
      "         -1.38946533e-01],\n",
      "        [ 1.01484179e-01,  1.44953430e-01,  1.33576751e-01,\n",
      "         -2.78061956e-01, -1.58274874e-01,  6.72350228e-02,\n",
      "         -5.41846007e-02,  4.23122644e-02,  1.03947997e-01,\n",
      "          1.60269737e-02,  2.01672733e-01,  1.36102051e-01,\n",
      "          2.82475948e-01, -1.08217180e-01,  2.56543040e-01,\n",
      "          1.22420698e-01],\n",
      "        [ 6.74836934e-02, -1.22919887e-01, -2.74580419e-01,\n",
      "         -2.87402272e-02, -4.60161120e-02,  1.99750155e-01,\n",
      "          1.77125156e-01,  2.43487835e-01, -3.38710248e-02,\n",
      "         -2.75157809e-01, -1.90983117e-02, -1.76915526e-03,\n",
      "         -1.29265398e-01, -1.12531647e-01,  6.38862550e-02,\n",
      "         -1.32000253e-01]],\n",
      "\n",
      "       [[ 5.38005531e-02,  1.46499515e-01,  2.58212686e-02,\n",
      "         -1.35503680e-01,  2.45114565e-01,  2.69677818e-01,\n",
      "          1.60276532e-01,  2.17029691e-01, -1.66104525e-01,\n",
      "         -1.78264886e-01, -1.75716281e-01,  2.27050483e-02,\n",
      "         -1.35555297e-01, -1.29497349e-02,  1.54768527e-02,\n",
      "          5.36446571e-02],\n",
      "        [ 2.73759544e-01, -1.33380607e-01, -7.89162964e-02,\n",
      "          1.87918097e-01, -2.29766414e-01, -1.18105277e-01,\n",
      "          2.61355758e-01, -1.53290734e-01, -3.08418870e-02,\n",
      "          1.62487060e-01,  1.87643528e-01, -1.09946758e-01,\n",
      "         -2.81208873e-01,  2.17967451e-01, -1.57030433e-01,\n",
      "         -1.64209634e-01],\n",
      "        [ 2.35997260e-01, -1.44266605e-01, -1.87117636e-01,\n",
      "         -2.86058456e-01,  2.11619616e-01,  1.44785762e-01,\n",
      "          3.31409276e-02, -9.27753448e-02, -2.62327701e-01,\n",
      "          7.60917068e-02, -1.42942742e-01,  6.86761737e-03,\n",
      "          8.29636455e-02, -1.69492736e-01, -8.27370137e-02,\n",
      "          1.72881007e-01],\n",
      "        [-2.03364193e-01, -1.34253934e-01, -2.03144014e-01,\n",
      "         -7.24462867e-02,  1.98379010e-01,  2.60704756e-02,\n",
      "         -8.91710222e-02,  2.85179317e-01, -8.25595856e-03,\n",
      "         -5.82485497e-02,  2.34276295e-01, -7.40208775e-02,\n",
      "         -5.78832179e-02, -4.40441370e-02,  1.32547677e-01,\n",
      "          2.56193042e-01],\n",
      "        [-2.35024199e-01, -1.86481088e-01, -1.28543690e-01,\n",
      "          2.68295646e-01,  3.31290960e-02,  2.26090968e-01,\n",
      "         -2.29174584e-01, -1.12479955e-01, -2.25853682e-01,\n",
      "          1.61409944e-01,  6.60558939e-02,  1.53007090e-01,\n",
      "         -7.99618959e-02, -7.05484301e-02, -2.23029628e-01,\n",
      "          1.95186257e-01],\n",
      "        [-2.58732587e-01,  8.34868550e-02,  8.64272118e-02,\n",
      "         -2.46966794e-01, -9.91517603e-02,  1.32709742e-03,\n",
      "          2.79769301e-01, -7.14735091e-02, -2.29668811e-01,\n",
      "         -6.24509007e-02,  2.04500288e-01,  1.17449492e-01,\n",
      "         -4.11233753e-02,  5.55995107e-02,  7.18226731e-02,\n",
      "          1.90047830e-01],\n",
      "        [-3.67173254e-02,  4.79189456e-02, -2.45679215e-01,\n",
      "         -1.13665536e-01, -2.71558762e-01,  1.07165664e-01,\n",
      "          6.96218014e-03,  1.44722372e-01, -2.23450571e-01,\n",
      "          2.53117383e-02, -1.92223191e-01, -1.02627516e-01,\n",
      "         -2.31856093e-01,  2.36772776e-01, -2.80057818e-01,\n",
      "         -7.72593170e-02],\n",
      "        [-1.06305063e-01, -8.97100568e-03,  2.46865273e-01,\n",
      "          2.33600378e-01,  1.83688194e-01, -1.76457942e-01,\n",
      "         -2.74073601e-01,  1.60075337e-01,  1.66367292e-01,\n",
      "          1.24069840e-01,  2.14176118e-01,  2.45807588e-01,\n",
      "         -9.28799659e-02,  8.95950496e-02, -1.35789990e-01,\n",
      "          2.38698721e-02]],\n",
      "\n",
      "       [[-3.31021249e-02, -1.17752820e-01, -7.80148953e-02,\n",
      "          2.12551892e-01,  8.84391963e-02,  1.08191580e-01,\n",
      "          8.48494768e-02, -2.81299025e-01,  2.19829977e-02,\n",
      "         -9.70509946e-02, -4.67818081e-02, -2.33410105e-01,\n",
      "         -1.18618026e-01,  2.18815565e-01,  2.87452459e-01,\n",
      "         -4.16355878e-02],\n",
      "        [-2.29570746e-01, -2.16538146e-01,  1.06400847e-02,\n",
      "         -4.59327698e-02,  4.38266993e-03, -2.57424414e-01,\n",
      "         -6.32756352e-02,  4.01313305e-02,  2.55724788e-02,\n",
      "         -2.16874287e-01,  1.63767904e-01, -2.33601093e-01,\n",
      "          1.92620248e-01,  1.97343618e-01,  2.76379943e-01,\n",
      "         -3.37168574e-02],\n",
      "        [-7.09064603e-02, -9.41301137e-02, -2.54362851e-01,\n",
      "         -2.30048314e-01, -1.66516513e-01,  5.64423203e-03,\n",
      "          2.77072191e-02, -5.14231920e-02,  1.44193113e-01,\n",
      "          2.37637222e-01,  2.55652845e-01,  7.41882026e-02,\n",
      "          7.21153021e-02,  1.40860647e-01,  1.40442312e-01,\n",
      "          2.77702212e-01],\n",
      "        [-8.78254175e-02,  6.42128289e-02, -1.97394326e-01,\n",
      "          1.35742426e-02, -6.11469895e-02, -2.76696056e-01,\n",
      "          1.30941302e-01, -2.35588014e-01,  2.47059166e-01,\n",
      "         -3.41233313e-02,  1.18981212e-01,  1.37033761e-02,\n",
      "         -1.15277231e-01,  1.55039102e-01,  1.74804628e-01,\n",
      "          1.28499150e-01],\n",
      "        [-9.59667861e-02,  6.49429858e-02,  2.36574471e-01,\n",
      "          2.69393682e-01,  2.16767192e-02, -2.10300893e-01,\n",
      "          1.68848544e-01, -2.00161040e-01,  1.16270453e-01,\n",
      "          7.00201988e-02, -1.11183286e-01, -2.51990855e-01,\n",
      "          1.19572073e-01, -1.44177675e-02, -2.63554513e-01,\n",
      "         -1.97382569e-02],\n",
      "        [-2.51682520e-01,  6.79323673e-02, -1.36789680e-03,\n",
      "         -2.88214266e-01, -1.64772958e-01,  2.56509244e-01,\n",
      "          2.72197902e-01, -2.70691156e-01, -1.22420222e-01,\n",
      "          1.31040692e-01, -2.10744888e-01,  2.87191272e-01,\n",
      "         -1.56808749e-01, -9.85416770e-03, -2.23807976e-01,\n",
      "          1.60603434e-01],\n",
      "        [ 2.73188829e-01, -4.41346318e-02,  1.78814828e-02,\n",
      "          2.84068406e-01,  1.21902019e-01, -1.20826215e-01,\n",
      "         -1.98137850e-01,  1.05071664e-02, -3.85574400e-02,\n",
      "         -1.90605655e-01,  2.02056170e-01, -1.21765897e-01,\n",
      "          1.43828094e-02, -1.00393638e-01,  2.51632750e-01,\n",
      "          1.65082663e-01],\n",
      "        [ 1.75722688e-01,  4.12653089e-02, -5.72022647e-02,\n",
      "         -2.23683953e-01,  8.15684795e-02,  2.11547673e-01,\n",
      "          1.94411695e-01,  1.02244347e-01, -8.39351863e-02,\n",
      "          2.14378059e-01, -6.45523518e-02, -5.88974953e-02,\n",
      "          9.15130079e-02,  2.41360664e-01, -1.56293795e-01,\n",
      "         -1.42457187e-02]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_4/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_10/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_10/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_5/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[-0.1971983 , -0.2128649 , -0.16396913,  0.13892666,\n",
      "         -0.04134877, -0.02480437, -0.05771928,  0.14930645],\n",
      "        [-0.24456696, -0.12226807,  0.11539644, -0.147919  ,\n",
      "          0.13052419, -0.03196338, -0.21715651,  0.1023609 ],\n",
      "        [-0.03591064, -0.06494583,  0.17279181,  0.25722095,\n",
      "         -0.24598454,  0.01634833,  0.02499789,  0.2402089 ],\n",
      "        [ 0.23042876, -0.19815978,  0.13028976, -0.14086239,\n",
      "          0.23827174,  0.18841162, -0.18999547, -0.06907827],\n",
      "        [-0.11773112,  0.25789186, -0.01803844, -0.26661423,\n",
      "         -0.09070893,  0.07949993, -0.0728222 , -0.07716988],\n",
      "        [-0.24762067, -0.19053364,  0.17612672,  0.20684054,\n",
      "          0.19900954,  0.08925846, -0.06828183,  0.1250003 ],\n",
      "        [-0.02533643, -0.19299349,  0.05425641, -0.18393224,\n",
      "          0.21665215, -0.21699975, -0.13866208,  0.15023032],\n",
      "        [-0.02554759, -0.01453984, -0.25125355,  0.03917918,\n",
      "          0.07780573,  0.0085111 , -0.14314039, -0.19421525],\n",
      "        [ 0.00345898,  0.0011158 , -0.00946409, -0.23973946,\n",
      "          0.13661355, -0.09415343,  0.20120114, -0.15212975],\n",
      "        [-0.26222116, -0.25167346,  0.1811583 , -0.26273927,\n",
      "         -0.13509421,  0.24020746,  0.07348254, -0.24828222],\n",
      "        [-0.25789618, -0.08945154, -0.13832022,  0.05982471,\n",
      "          0.10124943,  0.14915588,  0.01766339, -0.00756657],\n",
      "        [ 0.2610844 , -0.02053455,  0.24649581,  0.2334064 ,\n",
      "         -0.01519811, -0.26344898,  0.23381236, -0.06871353],\n",
      "        [-0.07530709,  0.01325792,  0.01597977, -0.12087737,\n",
      "         -0.08923189,  0.03959379, -0.11116122,  0.18157887],\n",
      "        [ 0.0115996 ,  0.07843664,  0.2385669 , -0.05987428,\n",
      "         -0.2263403 , -0.00623551,  0.04495978,  0.14086181],\n",
      "        [-0.11958526, -0.1299485 , -0.02612662, -0.10579483,\n",
      "          0.04948977,  0.20499483, -0.04586205, -0.22412945],\n",
      "        [ 0.15124896, -0.07236245,  0.16579229, -0.15115051,\n",
      "         -0.26290208, -0.25665256, -0.1696422 , -0.14329313],\n",
      "        [ 0.1423091 , -0.11591403, -0.05905063, -0.2631206 ,\n",
      "          0.2563673 , -0.01917547, -0.03733924, -0.213196  ],\n",
      "        [-0.26206237, -0.02578101, -0.23798187,  0.24006769,\n",
      "          0.10626918,  0.08710435,  0.08666697, -0.2335151 ],\n",
      "        [-0.00479767, -0.24979812, -0.2606323 , -0.03680329,\n",
      "          0.06392509, -0.04850727, -0.1964612 , -0.19703594],\n",
      "        [ 0.09218314,  0.26307425,  0.07918617, -0.26466662,\n",
      "          0.21409163, -0.09508432,  0.07231441,  0.02853554]],\n",
      "\n",
      "       [[-0.23539306,  0.01757649,  0.23481348,  0.206909  ,\n",
      "          0.10488352, -0.02900811,  0.08055997, -0.24704248],\n",
      "        [-0.16041738,  0.13809529, -0.18275769, -0.10052207,\n",
      "         -0.07281047,  0.24518612,  0.09640205, -0.14493474],\n",
      "        [ 0.14514762,  0.04356825, -0.1241118 ,  0.21977025,\n",
      "         -0.12352991,  0.04220301,  0.07438761,  0.19738698],\n",
      "        [-0.05074665, -0.26122314, -0.22370452, -0.12923974,\n",
      "         -0.16240609, -0.21512052,  0.19708213,  0.13825127],\n",
      "        [ 0.05561072, -0.10977338,  0.19472271,  0.18017256,\n",
      "          0.07055962,  0.06518683,  0.2341375 , -0.01250711],\n",
      "        [ 0.25597998, -0.116138  , -0.0947786 ,  0.11671755,\n",
      "         -0.08362313, -0.2204444 ,  0.11741573, -0.14691313],\n",
      "        [ 0.23576751,  0.2430276 ,  0.13819271, -0.13610697,\n",
      "          0.11547154,  0.21442598,  0.19839415,  0.02346861],\n",
      "        [-0.12542163, -0.03118835,  0.1340757 ,  0.0137836 ,\n",
      "          0.08067805,  0.01070103, -0.05186117, -0.00401473],\n",
      "        [ 0.01499543,  0.09430471, -0.19653995, -0.09298137,\n",
      "         -0.00867581,  0.01212478, -0.14432998, -0.11687122],\n",
      "        [-0.21389812, -0.11967057, -0.18548854, -0.09568176,\n",
      "          0.25823525, -0.24853073, -0.13675442, -0.23949969],\n",
      "        [-0.25303778, -0.18838441,  0.14586896,  0.12777036,\n",
      "         -0.05105072,  0.11884311,  0.15898809, -0.05402574],\n",
      "        [-0.0333823 ,  0.12565485,  0.08358362, -0.15858689,\n",
      "          0.09151044, -0.02412352, -0.24095276,  0.16594708],\n",
      "        [-0.18197775,  0.16897434,  0.00116065,  0.16878033,\n",
      "         -0.0182254 , -0.07753244,  0.15539655, -0.01796982],\n",
      "        [ 0.12660962, -0.25125074, -0.06952117, -0.14057751,\n",
      "         -0.06435227, -0.06047669, -0.00253522, -0.2008039 ],\n",
      "        [-0.10027987,  0.07939792,  0.16189155, -0.05597137,\n",
      "         -0.06460333,  0.06304175,  0.2625582 ,  0.00265431],\n",
      "        [-0.17216104,  0.1553812 ,  0.06497705, -0.2549125 ,\n",
      "          0.04305214,  0.19506171, -0.00943974, -0.01939078],\n",
      "        [-0.21646202, -0.17162007, -0.09823553, -0.02456063,\n",
      "         -0.02837569,  0.21327972,  0.07597378, -0.15659168],\n",
      "        [-0.23162791,  0.06993714, -0.20637426, -0.06406209,\n",
      "          0.12273595, -0.1554592 ,  0.00736985,  0.10594565],\n",
      "        [ 0.03807935, -0.20057847, -0.01256618, -0.21453851,\n",
      "          0.14331919,  0.20639527,  0.21454725,  0.19599247],\n",
      "        [ 0.24110988, -0.04442166,  0.08756077,  0.07071152,\n",
      "         -0.23971984,  0.05730629,  0.22755855, -0.23485309]],\n",
      "\n",
      "       [[ 0.264258  ,  0.2293329 ,  0.1558651 ,  0.24569425,\n",
      "          0.05093455, -0.13038586, -0.18181291, -0.19250934],\n",
      "        [-0.24216542,  0.16884595, -0.13640104, -0.18517664,\n",
      "         -0.17048922,  0.06347057, -0.1004089 , -0.21021287],\n",
      "        [-0.18868658, -0.25049236,  0.2573181 , -0.20955229,\n",
      "          0.0583376 ,  0.19115803, -0.13090123, -0.2072864 ],\n",
      "        [ 0.19918332, -0.16353144, -0.06705011, -0.20175952,\n",
      "          0.18231031,  0.05445012, -0.04825155,  0.25542173],\n",
      "        [ 0.19543684,  0.0953663 , -0.14662537,  0.11966938,\n",
      "         -0.13907403, -0.25090915,  0.13209084,  0.17293882],\n",
      "        [ 0.13414669,  0.07348615, -0.03946163,  0.26619717,\n",
      "          0.25625542,  0.18678555,  0.26276502,  0.05404472],\n",
      "        [ 0.14603245, -0.00845802, -0.04372941,  0.08054534,\n",
      "         -0.25642973,  0.17281857,  0.098456  ,  0.24371734],\n",
      "        [ 0.21478403,  0.155965  ,  0.00261584, -0.05091295,\n",
      "         -0.08517987, -0.18567702, -0.2131329 , -0.04970361],\n",
      "        [-0.11161904,  0.26257977, -0.17278646,  0.20777896,\n",
      "          0.16786301, -0.03651777, -0.20608726, -0.17539236],\n",
      "        [ 0.18969756,  0.12395811, -0.1397703 , -0.17535762,\n",
      "         -0.07096967,  0.19379285, -0.13102186, -0.21511364],\n",
      "        [ 0.03158239,  0.21342272,  0.17070714,  0.03349277,\n",
      "         -0.11757673, -0.1710745 , -0.0206314 ,  0.09119976],\n",
      "        [-0.18448833, -0.10951844, -0.21486692,  0.2221739 ,\n",
      "          0.16848612, -0.15856707, -0.01948355,  0.20051238],\n",
      "        [ 0.18707523, -0.02341183, -0.23114121, -0.00771898,\n",
      "         -0.2611736 ,  0.13761574, -0.10711601, -0.1761682 ],\n",
      "        [ 0.1285587 ,  0.15881813,  0.12162367, -0.2181144 ,\n",
      "         -0.01062608,  0.15959367,  0.11276084, -0.01005051],\n",
      "        [ 0.06531483, -0.1833285 ,  0.04053634, -0.05909091,\n",
      "          0.03430235, -0.22370833,  0.15782404, -0.15824777],\n",
      "        [ 0.18278813, -0.26140824,  0.13030112, -0.18667015,\n",
      "         -0.14321062,  0.05261746,  0.03740826, -0.09193279],\n",
      "        [ 0.04333633, -0.04329044,  0.11780229, -0.03380233,\n",
      "         -0.06367315, -0.08467694,  0.0500654 , -0.05990602],\n",
      "        [-0.02988547, -0.26063207,  0.03070426,  0.1768829 ,\n",
      "         -0.18846987, -0.14569333, -0.11903299,  0.19711632],\n",
      "        [ 0.01145583,  0.03992379,  0.16716966, -0.163355  ,\n",
      "         -0.06245004, -0.22311611,  0.15277326,  0.22796297],\n",
      "        [-0.07648151, -0.07637624,  0.05684313,  0.12420994,\n",
      "         -0.00943649, -0.15097228,  0.19700822,  0.05260447]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_5/bias:0' shape=(20,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-8f3f7ea323f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-97a188d5a767>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(context, target, weight, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-c5384877c902>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(context, target, weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    511\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1271\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1272\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0']."
     ]
    }
   ],
   "source": [
    "train(train_context, train_target, train_weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
