{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossary\n",
    "* sequences: string representing amino acid sequence\n",
    "* label: binary string representing disordered and ordered segments with 1 as target(disordered region) and 0 as context\n",
    "* target: disordered region as one hot encoded vector from the sequences that we want the neural network to reproduce from the given context \n",
    "* weight: labels \n",
    "* context: one hot encoded vector that represents the sequences around the target with the target masked (zero-'d out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "BATCH_SIZE = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for func load_data \n",
    "def convert_ohc(seq):\n",
    "    \"\"\"\n",
    "    One hot encodes given amino acid sequence string.\n",
    "    \n",
    "    :param seq: string of amino acid sequence \n",
    "    :return: 2D array of one hot encoded string \n",
    "    \n",
    "    \"\"\"\n",
    "    seq_idx = [sym_codes.index(sym) for sym in seq]\n",
    "    x = np.array(seq_idx)\n",
    "    x = keras.utils.to_categorical(x, num_classes=len(sym_codes), dtype='int32')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seqs_path, label_path):\n",
    "    \"\"\"\n",
    "    Loads sequences and lables from fasta files. \n",
    "    \n",
    "    :param seq_path: path for fasta file of amino acid sequences \n",
    "    :param label_path: path fasta file of labels of amino acid sequences where disordered residues are labeled are labeled as 1 and ordered residues are labeled as 0\n",
    "    :return: array all one hot encoded sequences and array of all labels from \n",
    "    \"\"\"\n",
    "    seq_ohc_lst = []\n",
    "    label_lst = []\n",
    "    \n",
    "    for record_seq, record_label in zip(SeqIO.parse(seqs_path, 'fasta'), SeqIO.parse(label_path, 'fasta')):\n",
    "        \n",
    "        # one hot encode each record_seq \n",
    "        seq = str(record_seq.seq)\n",
    "        seq_ohc = convert_ohc(seq)\n",
    "        seq_ohc_lst.append(seq_ohc)\n",
    "        \n",
    "        # expand the dimension of record_label for broadcasting\n",
    "        label = [int(sym) for sym in record_label]\n",
    "        label_lst.append(label)\n",
    "        \n",
    "    return np.array(seq_ohc_lst), np.array(label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_target_context(seq_ohc, label):\n",
    "    \"\"\"\n",
    "    Gets the target, context, and weight from one hot encoded sequences and labels. \n",
    "    \n",
    "    :param seq_ohc: one hot ended 2D arrays of sequences \n",
    "    :param label: array of labels corresponding to seq_ohc \n",
    "    :return: target, context and weight according to seq_ohc and label \n",
    "    \n",
    "    \"\"\"\n",
    "    weight = np.expand_dims(label, axis = 2)\n",
    "\n",
    "    # get the target from the record \n",
    "    target = weight*seq_ohc\n",
    "        \n",
    "    # get the context from the record (inverted the weight)\n",
    "    context = (np.invert(weight) + 2)*seq_ohc\n",
    "    \n",
    "    return weight, target, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make generative model\n",
    "def make_generative_model():\n",
    "    \"\"\"\n",
    "    Makes generative generative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of generative model \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # convolution \n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(8, 3, strides = 1, padding='same', name='first'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "\n",
    "    model.add(keras.layers.Conv1D(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(256, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    # deconvolution \n",
    "    model.add(keras.layers.Conv1DTranspose(128, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(64, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(32, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(16, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1DTranspose(8, 3, strides = 1, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    #FIXEME: PLAY AROUND WITH THE RATIO OF FILTER \n",
    "    \n",
    "    # added last layer to transform filters to probability classes \n",
    "    model.add(keras.layers.Conv1DTranspose(20, 3, strides = 1, padding='same', activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (Conv1D)               (None, 180, 8)            488       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 180, 16)           400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 180, 32)           1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 180, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 180, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 180, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 180, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 180, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 180, 128)          512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 180, 64)           24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 180, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 180, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 180, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 180, 32)           128       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 180, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 180, 16)           1552      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 180, 16)           64        \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 180, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, 180, 8)            392       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 180, 8)            32        \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTr (None, 180, 20)           500       \n",
      "=================================================================\n",
      "Total params: 266,628\n",
      "Trainable params: 265,124\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generative_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make discrimator model\n",
    "def make_discriminator_model():\n",
    "    \"\"\"\n",
    "    Makes adverserial/discriminative model for DCGAN based off of architecture from \"Protein Loop Modeling Using \n",
    "    Deep Generative Adversarial Network\" paper. \n",
    "    \n",
    "    :return: model instance of discriminative model \n",
    "    \n",
    "    \"\"\"\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(keras.Input(shape=((180, 20))))\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(25, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(13, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(7, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(4, 4, strides = 2, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 90, 25)            2025      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 90, 25)            100       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 90, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 45, 13)            1313      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 45, 13)            52        \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 45, 13)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 23, 7)             371       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 23, 7)             28        \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 23, 7)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 12, 4)             116       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 4)             16        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 12, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 4,070\n",
      "Trainable params: 3,972\n",
      "Non-trainable params: 98\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tensorflow.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, generated_target, target):\n",
    "    generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "    ones_like_fake_output = tensorflow.cast(tensorflow.ones_like(fake_output), tensorflow.int64)\n",
    "    a = cross_entropy(ones_like_fake_output, fake_output)\n",
    "    b = cross_entropy(generated_target, target)\n",
    "    return  a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, weight):\n",
    "    \n",
    "    real_loss = cross_entropy(tensorflow.cast(tensorflow.ones_like(real_output), tensorflow.int64), real_output, weight)\n",
    "    fake_loss = cross_entropy(tensorflow.cast(tensorflow.zeros_like(fake_output), tensorflow.int64), fake_output, weight)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(context, target, weight):\n",
    "\n",
    "    with tensorflow.GradientTape() as gen_tape, tensorflow.GradientTape() as disc_tape:\n",
    "        generated_target = generator(context, training=True)*weight\n",
    "        generated_target = tensorflow.cast(generated_target, tensorflow.int64)\n",
    "        \n",
    "        real_output = discriminator(target, training=True)\n",
    "        fake_output = discriminator(generated_target, training=True)\n",
    "        \n",
    "        \n",
    "        target = tensorflow.cast(tensorflow.constant(target), dtype = tensorflow.float32)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output, generated_target, target)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, weight)\n",
    "    \n",
    "        # backpropogration\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, target, weight, epochs):\n",
    "    \n",
    "    # batch data \n",
    "    context_batch = np.array_split(context, BATCH_SIZE)\n",
    "    target_batch = np.array_split(target, BATCH_SIZE)\n",
    "    weight_batch = np.array_split(weight, BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for context, target, weight in zip(context_batch, target_batch, weight_batch):\n",
    "            \n",
    "            train_step(context, target, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_seq, train_label = load_data('../../inpainting_mobidb/out/train_seq.fasta', '../../inpainting_mobidb/out/train_label.fasta')\n",
    "train_weight, train_target, train_context = get_weight_target_context(train_seq, train_label)\n",
    "\n",
    "\n",
    "#test_data = load_data('../../inpainting_mobidb/out/test_seq.fasta','../../inpainting_mobidb/out/test_label.fasta')\n",
    "\n",
    "#valid_data = load_data('../../inpainting_mobidb/out/validation_seq.fasta','../../inpainting_mobidb/out/validation_label.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n",
      "(150, 180, 20)\n",
      "(150, 180, 20)\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int64'>\n",
      "<dtype: 'float32'>\n",
      "a\n",
      "tf.Tensor(1.1920929e-07, shape=(), dtype=float32)\n",
      "b\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([150 180  20], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(20,), dtype=int64)\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[<tf.Variable 'first/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[-0.16022187,  0.17067975, -0.16519868, -0.02088495,\n",
      "         -0.03232104,  0.20495439,  0.21268955, -0.10696983],\n",
      "        [ 0.12821862, -0.19825575, -0.11454456,  0.10251898,\n",
      "         -0.09339109,  0.05534342,  0.04034612,  0.21767762],\n",
      "        [-0.07791011, -0.0576379 , -0.05873185,  0.06412551,\n",
      "         -0.04002205,  0.2489815 ,  0.13703284,  0.2489681 ],\n",
      "        [-0.09171799, -0.04702367,  0.24725774, -0.18580568,\n",
      "          0.22825596,  0.03053701, -0.08179334,  0.12759072],\n",
      "        [ 0.1268956 , -0.22421427, -0.22812113,  0.26645502,\n",
      "          0.15619466,  0.23908976,  0.03492445,  0.20692319],\n",
      "        [-0.12747125, -0.19792166, -0.21934325,  0.0651426 ,\n",
      "          0.11775038,  0.18243438,  0.0063557 ,  0.20345187],\n",
      "        [ 0.00781876, -0.14720547, -0.14030135, -0.18796125,\n",
      "         -0.2016148 , -0.08153948, -0.06887265, -0.10669972],\n",
      "        [-0.07129522, -0.24275756,  0.24817494, -0.10868441,\n",
      "         -0.06946899,  0.12682965,  0.16520548,  0.08634946],\n",
      "        [-0.02656373, -0.11636657,  0.235688  , -0.05746752,\n",
      "          0.03377691,  0.20437115,  0.12956217,  0.17932904],\n",
      "        [ 0.16303125, -0.13573134, -0.11704856, -0.08217745,\n",
      "         -0.02333058,  0.00362936,  0.07609046,  0.02370316],\n",
      "        [ 0.03565073, -0.06216183, -0.21743503,  0.13860193,\n",
      "         -0.19015393, -0.1853525 , -0.02516337,  0.06850567],\n",
      "        [-0.25190485,  0.24337605,  0.13165441,  0.23860094,\n",
      "         -0.09837164,  0.01469651,  0.14451635,  0.20917004],\n",
      "        [-0.0955219 ,  0.152969  ,  0.20383021,  0.00184444,\n",
      "         -0.18856628, -0.16519803,  0.15524298, -0.17478727],\n",
      "        [-0.08915766,  0.10129505, -0.12150565,  0.05438906,\n",
      "         -0.13749065,  0.2141535 , -0.03014487, -0.12206116],\n",
      "        [-0.20953247,  0.0313971 ,  0.03929508,  0.08196029,\n",
      "         -0.05646272, -0.16749394,  0.02162665,  0.07175648],\n",
      "        [-0.12391134,  0.2566906 ,  0.04203445, -0.11779892,\n",
      "         -0.08480124,  0.02567154, -0.25216314, -0.25760484],\n",
      "        [-0.0722463 ,  0.24486294, -0.19681337,  0.10845554,\n",
      "         -0.1481907 , -0.08673075, -0.17267177,  0.194718  ],\n",
      "        [-0.18077001,  0.07075959,  0.09861383,  0.09101796,\n",
      "          0.19178554,  0.24118641,  0.25188813,  0.2541853 ],\n",
      "        [ 0.08215529, -0.14104024,  0.04003638,  0.11127973,\n",
      "          0.25598815,  0.23143184,  0.07250297, -0.22719094],\n",
      "        [-0.08743404,  0.1689128 ,  0.24387941,  0.202643  ,\n",
      "          0.13560659, -0.25623125,  0.13778752, -0.19093692]],\n",
      "\n",
      "       [[ 0.19135621,  0.0806832 , -0.17934197, -0.13871472,\n",
      "         -0.03516296, -0.2128737 , -0.02471191, -0.00512123],\n",
      "        [ 0.03720218,  0.11451358,  0.1397984 ,  0.04509556,\n",
      "          0.24926862,  0.22428685, -0.1443454 ,  0.19184971],\n",
      "        [-0.2383136 ,  0.03579238,  0.09893882, -0.2291434 ,\n",
      "          0.08524805, -0.07372078, -0.09209388, -0.2672539 ],\n",
      "        [-0.10539824, -0.21912247, -0.00265497, -0.02025756,\n",
      "         -0.21255146,  0.17057294,  0.24289289,  0.21861327],\n",
      "        [-0.1718942 , -0.09010823, -0.20801803,  0.08304065,\n",
      "          0.21884969,  0.13237399,  0.1350187 , -0.17971703],\n",
      "        [ 0.1706928 ,  0.08205384, -0.10822423,  0.07160458,\n",
      "          0.09453779, -0.13747409,  0.0058625 ,  0.0034517 ],\n",
      "        [ 0.25039956, -0.14408478, -0.12901136, -0.2579699 ,\n",
      "          0.22665724,  0.03100783,  0.21135679,  0.03141353],\n",
      "        [-0.16305284, -0.16275278,  0.1353412 ,  0.22249052,\n",
      "         -0.02095032, -0.17659691,  0.04996225,  0.16871047],\n",
      "        [-0.1353696 ,  0.2547374 ,  0.06889501, -0.2332332 ,\n",
      "         -0.21823466, -0.25497735, -0.162186  , -0.17657664],\n",
      "        [ 0.0977723 ,  0.16228539, -0.15866457,  0.08224925,\n",
      "          0.13430661,  0.21950185, -0.04964282,  0.17905015],\n",
      "        [-0.26650545, -0.03947335, -0.09392998, -0.18827929,\n",
      "         -0.21101364, -0.09179242, -0.14019053,  0.19506788],\n",
      "        [-0.07946564, -0.17630598, -0.21453564,  0.21010658,\n",
      "          0.20617786, -0.07044576, -0.12505116, -0.20491296],\n",
      "        [-0.13276912,  0.13608563,  0.18388617, -0.17114687,\n",
      "         -0.12232535,  0.1438933 , -0.25922263,  0.20235038],\n",
      "        [-0.01885298, -0.25315693, -0.04934181,  0.18331218,\n",
      "          0.08017382, -0.16647288, -0.25982025,  0.19223383],\n",
      "        [ 0.2664545 ,  0.07423958,  0.2359812 ,  0.10969043,\n",
      "         -0.17104748, -0.22298378,  0.25084272,  0.23279485],\n",
      "        [ 0.24428341,  0.0330078 ,  0.07250556,  0.04944426,\n",
      "         -0.05808827,  0.09095716,  0.01098087,  0.04421049],\n",
      "        [-0.18675363, -0.06118424, -0.14208582, -0.04728371,\n",
      "          0.10131779, -0.19042633,  0.10228667, -0.218912  ],\n",
      "        [ 0.01300272,  0.05831653,  0.21704781, -0.17909805,\n",
      "         -0.11510114, -0.18705198,  0.10128325, -0.15749338],\n",
      "        [ 0.20998546, -0.06090452, -0.26028824, -0.26046702,\n",
      "          0.03566289,  0.02290398,  0.18338934,  0.00690821],\n",
      "        [-0.1716832 , -0.2617838 , -0.09129891,  0.00504547,\n",
      "          0.05659378,  0.25768182,  0.07969293,  0.23144126]],\n",
      "\n",
      "       [[ 0.06006047,  0.11147407,  0.01163498, -0.19750333,\n",
      "          0.23338333, -0.15404207, -0.11544746, -0.09490788],\n",
      "        [ 0.1633915 ,  0.07473049, -0.06792423, -0.25626367,\n",
      "         -0.22473072,  0.09486359,  0.26488027,  0.02906501],\n",
      "        [-0.00284433, -0.16554755,  0.2375513 ,  0.09273574,\n",
      "         -0.15668428,  0.05584118,  0.22727582,  0.01187479],\n",
      "        [ 0.16823792, -0.13690673, -0.17941493, -0.07846531,\n",
      "          0.25431827,  0.16102475, -0.14148162,  0.10942599],\n",
      "        [-0.05808356,  0.21646526, -0.02395874,  0.10654125,\n",
      "         -0.08943452, -0.22253951,  0.19352344,  0.082405  ],\n",
      "        [-0.08071208, -0.09950662,  0.0478512 , -0.0607807 ,\n",
      "          0.20678371, -0.24528916,  0.10131258,  0.25192085],\n",
      "        [ 0.02660415, -0.16440243,  0.10338232,  0.2069833 ,\n",
      "          0.03088662, -0.10548165, -0.1449975 , -0.08533733],\n",
      "        [-0.26597735, -0.00114301, -0.09424704,  0.07136586,\n",
      "          0.09794664, -0.09159654,  0.09795046, -0.05324422],\n",
      "        [-0.02815413, -0.1124855 ,  0.14038417,  0.07594505,\n",
      "          0.12886193,  0.02281693,  0.04890272, -0.20807022],\n",
      "        [ 0.13071522,  0.0933992 , -0.12375344, -0.23636371,\n",
      "         -0.02826634,  0.16868562, -0.04169744,  0.00655049],\n",
      "        [-0.25540522,  0.23510435, -0.01597908,  0.17252731,\n",
      "         -0.19732791, -0.12712474, -0.02068806, -0.08653221],\n",
      "        [ 0.05308256, -0.08636653,  0.01692259,  0.22016576,\n",
      "          0.2657365 , -0.1124272 ,  0.0995239 ,  0.1511581 ],\n",
      "        [-0.00784892, -0.04499872,  0.2527586 ,  0.16894001,\n",
      "          0.2625762 ,  0.16600895,  0.07638282,  0.02037889],\n",
      "        [ 0.08441147,  0.22703695,  0.1965966 , -0.20069069,\n",
      "          0.15426195,  0.2237421 ,  0.16430667,  0.12537009],\n",
      "        [ 0.03218824, -0.19445872, -0.18836889, -0.2549686 ,\n",
      "         -0.10451642,  0.24495539, -0.11303318, -0.01893339],\n",
      "        [-0.01306236, -0.02361076,  0.2595109 , -0.09753372,\n",
      "         -0.042487  , -0.2031785 ,  0.24004468,  0.1573799 ],\n",
      "        [-0.21187176,  0.26635376,  0.20436719, -0.012692  ,\n",
      "          0.23709634,  0.14122814, -0.06177588, -0.04730123],\n",
      "        [-0.04654972, -0.06172638, -0.11176005, -0.22373235,\n",
      "         -0.18341261, -0.2628892 ,  0.129453  ,  0.23142216],\n",
      "        [-0.2661021 ,  0.26268092,  0.08350384,  0.10721546,\n",
      "          0.09919089, -0.09681687, -0.07564875, -0.15744254],\n",
      "        [-0.257316  , -0.16391204,  0.00595668,  0.24021414,\n",
      "          0.12230355, -0.17557651,  0.06973234, -0.12659912]]],\n",
      "      dtype=float32)>, <tf.Variable 'first/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[ 2.61210918e-01, -2.22101793e-01, -1.63589299e-01,\n",
      "         -4.71063852e-02,  2.74657428e-01,  2.01788574e-01,\n",
      "          1.94250941e-02, -2.55116969e-01, -2.35773221e-01,\n",
      "          1.70007080e-01,  1.87822878e-02, -1.89142823e-02,\n",
      "          1.18978381e-01, -1.62743852e-01,  4.38412428e-02,\n",
      "         -4.78183776e-02],\n",
      "        [-1.33241788e-01, -2.14921087e-01, -8.83978456e-02,\n",
      "          2.21703351e-02,  1.63037598e-01, -1.85294598e-01,\n",
      "          2.33925462e-01, -3.36683989e-02, -5.89680523e-02,\n",
      "         -1.35786533e-02,  1.63351864e-01,  2.43097842e-02,\n",
      "         -1.32377744e-02,  1.68411911e-01,  7.33209848e-02,\n",
      "         -8.12234730e-02],\n",
      "        [-1.83564246e-01,  1.33606553e-01,  1.24121934e-01,\n",
      "          5.74498177e-02,  1.93670303e-01, -1.80087537e-01,\n",
      "         -2.32332021e-01, -6.76399916e-02, -2.55966157e-01,\n",
      "         -1.81518346e-01, -2.33383328e-01, -2.77820587e-01,\n",
      "          2.18194067e-01,  3.62848043e-02,  1.44038796e-01,\n",
      "         -8.89664888e-03],\n",
      "        [-2.26467252e-01,  1.05962932e-01,  2.88594544e-01,\n",
      "         -2.59009749e-01, -1.73795983e-01, -5.01634032e-02,\n",
      "         -2.53827274e-01,  2.22389281e-01, -1.46462828e-01,\n",
      "          2.00129390e-01, -2.19283462e-01, -2.46568292e-01,\n",
      "         -1.69078276e-01,  2.86137462e-01, -1.38806701e-02,\n",
      "         -3.69811058e-02],\n",
      "        [-2.69164473e-01, -9.58056003e-02, -2.87322074e-01,\n",
      "          1.58585012e-02, -7.18464702e-02,  2.60899842e-01,\n",
      "          1.93262666e-01, -8.69386047e-02,  2.20341921e-01,\n",
      "          4.71127927e-02, -9.18570161e-02, -1.14366949e-01,\n",
      "         -7.38287121e-02, -8.55306387e-02,  2.53272593e-01,\n",
      "          1.38883591e-02],\n",
      "        [-2.76174843e-01, -2.88669199e-01,  1.64832979e-01,\n",
      "          9.97744799e-02, -1.22951418e-01, -1.63393289e-01,\n",
      "          1.02815896e-01,  2.52674997e-01, -1.49741054e-01,\n",
      "          2.67808020e-01, -7.84237832e-02,  2.78093159e-01,\n",
      "         -4.02294099e-02,  2.59968340e-02, -2.77889132e-01,\n",
      "         -2.14090645e-02],\n",
      "        [-1.02765918e-01,  1.05256140e-02, -2.31933787e-01,\n",
      "          4.42007184e-02,  2.41448641e-01, -1.96247756e-01,\n",
      "         -2.75356978e-01,  2.56209075e-01, -2.32314050e-01,\n",
      "          1.18601918e-01,  1.52298957e-01,  3.90363932e-02,\n",
      "          3.50177288e-05,  1.81208968e-01,  1.58473969e-01,\n",
      "         -1.88646808e-01],\n",
      "        [-1.68124139e-02, -7.78254867e-02,  2.68168867e-01,\n",
      "          2.79009044e-02, -1.78683147e-01,  2.25271642e-01,\n",
      "         -2.04174951e-01, -2.01297835e-01, -2.37288892e-01,\n",
      "          3.76952589e-02,  2.83255279e-01, -2.81978279e-01,\n",
      "         -2.54646271e-01, -7.89167732e-02,  1.93774313e-01,\n",
      "          1.12217665e-01]],\n",
      "\n",
      "       [[ 5.27339578e-02,  2.35862613e-01, -2.67349809e-01,\n",
      "          2.62169778e-01, -2.81781554e-01,  2.19789624e-01,\n",
      "         -1.83517992e-01,  1.04454547e-01,  1.90781772e-01,\n",
      "          1.76473081e-01,  2.83701062e-01,  4.43442762e-02,\n",
      "          2.19555676e-01, -1.34567305e-01, -5.71650267e-02,\n",
      "          2.55838394e-01],\n",
      "        [ 1.89074010e-01, -2.39280701e-01, -2.48671472e-02,\n",
      "         -6.83841407e-02,  9.43559110e-02,  1.33857012e-01,\n",
      "         -8.52405429e-02,  1.94683224e-01, -1.79964304e-03,\n",
      "         -3.95624936e-02,  2.02272534e-02,  1.54912740e-01,\n",
      "         -2.67689735e-01,  2.67051160e-02,  2.94521451e-02,\n",
      "          1.34867519e-01],\n",
      "        [-2.41452426e-01,  2.64723837e-01,  4.42679524e-02,\n",
      "         -2.32034281e-01, -2.13773355e-01,  4.17140424e-02,\n",
      "          1.40703708e-01,  4.86029387e-02,  2.32897341e-01,\n",
      "          9.22071338e-02,  8.57519209e-02, -1.07768029e-01,\n",
      "         -1.17751777e-01, -1.82818592e-01, -9.91995931e-02,\n",
      "         -2.70562589e-01],\n",
      "        [-5.11370748e-02, -2.00287610e-01, -1.44468188e-01,\n",
      "          2.02863485e-01,  1.73231065e-01, -2.15134308e-01,\n",
      "          1.12661183e-01,  9.90485847e-02, -2.85380602e-01,\n",
      "          4.97907996e-02, -1.11142099e-02, -9.08152014e-02,\n",
      "         -1.97387934e-01,  1.75220877e-01,  2.88299501e-01,\n",
      "         -2.81351805e-03],\n",
      "        [-3.36265564e-02, -1.57237113e-01,  1.01872981e-01,\n",
      "          1.06624842e-01, -9.32126641e-02, -2.85312921e-01,\n",
      "          1.14553124e-01, -2.71434069e-01, -6.10105097e-02,\n",
      "          2.74234533e-01,  1.49131119e-01, -2.68559992e-01,\n",
      "          4.61485982e-02, -7.69895315e-03, -1.05009571e-01,\n",
      "         -7.64314979e-02],\n",
      "        [-7.67986774e-02,  2.47520387e-01, -2.62421578e-01,\n",
      "          8.45879316e-04,  2.80842006e-01, -7.12821037e-02,\n",
      "          2.75612950e-01,  2.70946026e-01, -1.71127826e-01,\n",
      "          1.37930602e-01,  4.26151752e-02, -2.36049280e-01,\n",
      "         -1.55490950e-01,  1.25513226e-01,  9.64596868e-03,\n",
      "          3.66454422e-02],\n",
      "        [ 4.85095382e-03, -3.16990912e-02, -2.52840638e-01,\n",
      "          5.22124171e-02, -6.75844550e-02,  1.91339850e-02,\n",
      "         -1.11910909e-01, -2.55824089e-01, -1.62836313e-02,\n",
      "         -6.56604767e-04,  3.84235680e-02,  1.18634343e-01,\n",
      "          1.42374188e-01, -1.37206346e-01, -7.81901181e-02,\n",
      "         -1.82075694e-01],\n",
      "        [-4.88789827e-02, -3.53694260e-02, -2.03506589e-01,\n",
      "          1.75669074e-01, -2.60530114e-02,  1.05866790e-01,\n",
      "         -1.69173181e-02, -2.25011736e-01, -6.66011423e-02,\n",
      "          2.50510573e-01,  2.58387625e-02,  1.38644457e-01,\n",
      "          3.57773006e-02, -2.06992120e-01, -5.55976629e-02,\n",
      "          2.84982324e-02]],\n",
      "\n",
      "       [[ 2.24930048e-01,  5.99744916e-03, -1.84032261e-01,\n",
      "          2.98123360e-02,  1.26095146e-01, -1.78813994e-01,\n",
      "          1.06824636e-02,  2.44643688e-02,  2.55816698e-01,\n",
      "         -5.13893217e-02,  1.09085202e-01,  2.83604562e-01,\n",
      "         -5.12322038e-02, -5.45981079e-02, -6.37070984e-02,\n",
      "          1.18935585e-01],\n",
      "        [ 2.43076205e-01, -3.98954749e-03, -2.18626589e-01,\n",
      "          2.22762406e-01,  2.73844182e-01,  1.32375360e-01,\n",
      "          1.74748331e-01,  1.16860777e-01, -2.78782755e-01,\n",
      "          2.60878563e-01, -2.17661798e-01, -7.98840523e-02,\n",
      "          1.12870336e-02, -2.01635778e-01, -2.55761743e-01,\n",
      "          2.60855556e-01],\n",
      "        [ 1.41458124e-01,  9.30981934e-02, -1.71257228e-01,\n",
      "         -1.53555498e-01,  1.51279867e-01, -1.27150252e-01,\n",
      "          1.62065357e-01,  3.90645266e-02, -1.22997388e-01,\n",
      "         -6.23864084e-02,  1.76923960e-01, -2.23155513e-01,\n",
      "          1.74060881e-01,  2.68620431e-01, -2.06095517e-01,\n",
      "          2.09601909e-01],\n",
      "        [ 2.37855077e-01, -1.08773768e-01, -2.46089756e-01,\n",
      "          1.60214573e-01, -8.15838426e-02,  2.85370946e-01,\n",
      "          4.83084917e-02, -1.55017078e-01, -3.08396816e-02,\n",
      "          8.11514854e-02, -1.89865083e-01,  1.79096252e-01,\n",
      "         -1.23227194e-01, -2.19229221e-01, -7.63860643e-02,\n",
      "         -1.22958839e-01],\n",
      "        [ 8.05969536e-02, -1.17181420e-01,  3.21148038e-02,\n",
      "         -1.82696775e-01,  1.37519985e-01, -5.06597012e-02,\n",
      "          6.74618185e-02,  1.79508448e-01, -1.51768655e-01,\n",
      "         -2.65207618e-01, -1.99947342e-01, -2.18463197e-01,\n",
      "         -2.65873015e-01, -2.59845436e-01, -8.13396424e-02,\n",
      "         -1.08641699e-01],\n",
      "        [-2.77853549e-01, -2.64252603e-01, -2.77099907e-02,\n",
      "         -1.84255272e-01, -2.62317777e-01, -4.14998531e-02,\n",
      "         -1.16736338e-01, -7.89022595e-02,  2.48956680e-01,\n",
      "          1.15670502e-01,  1.84551269e-01,  9.16951299e-02,\n",
      "         -6.04373366e-02,  2.68581808e-02, -7.14047551e-02,\n",
      "         -1.97577402e-01],\n",
      "        [ 1.58937514e-01,  1.69063956e-01, -1.86115891e-01,\n",
      "          2.50829697e-01, -6.34317994e-02,  8.68877470e-02,\n",
      "          1.48247540e-01,  8.43358934e-02,  2.56106973e-01,\n",
      "         -1.70814395e-01, -4.36815619e-02, -2.85220444e-02,\n",
      "         -1.22849613e-01, -4.43298966e-02,  7.75995255e-02,\n",
      "         -1.97446913e-01],\n",
      "        [ 2.71843851e-01,  5.85276484e-02,  7.35740066e-02,\n",
      "         -2.54967630e-01,  2.65270054e-01,  7.79807568e-02,\n",
      "          4.64219153e-02,  1.39774650e-01, -7.27453381e-02,\n",
      "         -7.90529847e-02,  1.15412116e-01,  3.18298638e-02,\n",
      "         -1.77053571e-01,  1.76862240e-01, -9.14805979e-02,\n",
      "         -1.57553092e-01]]], dtype=float32)>, <tf.Variable 'conv1d/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_1/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[-0.06223252,  0.01602881,  0.02938396, ..., -0.20075148,\n",
      "          0.07819653,  0.19512329],\n",
      "        [ 0.00353892, -0.03907317,  0.11710089, ..., -0.00127941,\n",
      "          0.05255729,  0.14400041],\n",
      "        [-0.1423131 , -0.07114802, -0.04139133, ..., -0.01758897,\n",
      "         -0.1790699 ,  0.16866958],\n",
      "        ...,\n",
      "        [-0.12077668, -0.05995169,  0.0517185 , ..., -0.11640818,\n",
      "          0.12431943,  0.14010409],\n",
      "        [ 0.03470258,  0.14392543,  0.11332378, ...,  0.18866926,\n",
      "          0.11539513, -0.17705251],\n",
      "        [ 0.00048476,  0.108538  , -0.05241376, ..., -0.09618281,\n",
      "         -0.09310214,  0.14095193]],\n",
      "\n",
      "       [[-0.11454058, -0.15487754,  0.19395572, ...,  0.06479228,\n",
      "         -0.12566459,  0.1365622 ],\n",
      "        [ 0.01695524, -0.12514263, -0.05958325, ..., -0.01680413,\n",
      "          0.09514958,  0.02254727],\n",
      "        [ 0.18405923, -0.11710013, -0.07112652, ...,  0.03617233,\n",
      "          0.16458052, -0.09041538],\n",
      "        ...,\n",
      "        [-0.10592551,  0.04471265, -0.15095577, ...,  0.14140958,\n",
      "          0.10783151, -0.02546267],\n",
      "        [-0.20287979, -0.17527223, -0.09342373, ...,  0.10515621,\n",
      "          0.00913864, -0.13558978],\n",
      "        [-0.19711362, -0.08942623,  0.20326349, ..., -0.02549163,\n",
      "          0.1420154 , -0.16319536]],\n",
      "\n",
      "       [[-0.04765077, -0.07147828,  0.04005517, ..., -0.20403515,\n",
      "          0.06937817,  0.18724999],\n",
      "        [-0.02208887,  0.16631672,  0.1295616 , ..., -0.03926769,\n",
      "         -0.14993298,  0.0951961 ],\n",
      "        [ 0.04144184, -0.02950831,  0.03458545, ...,  0.14887545,\n",
      "          0.0455471 , -0.17400995],\n",
      "        ...,\n",
      "        [ 0.19811776,  0.04866403,  0.09645739, ...,  0.03715837,\n",
      "         -0.06271127,  0.02479082],\n",
      "        [-0.10154182, -0.14002144,  0.16374189, ..., -0.06170541,\n",
      "         -0.05978784, -0.00621925],\n",
      "        [-0.06515498,  0.05869818, -0.09924503, ...,  0.01533131,\n",
      "         -0.17715631, -0.13173541]]], dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[ 0.06929518, -0.04021987,  0.08361731, ...,  0.06635699,\n",
      "         -0.09774675,  0.13411647],\n",
      "        [-0.06458776, -0.1361487 , -0.11573468, ..., -0.04237325,\n",
      "          0.0214728 , -0.0567124 ],\n",
      "        [ 0.03919117, -0.12863994,  0.08417894, ...,  0.0272664 ,\n",
      "         -0.04679257,  0.1263257 ],\n",
      "        ...,\n",
      "        [ 0.08127344,  0.08817612,  0.04765624, ...,  0.08759099,\n",
      "          0.05178945, -0.02798439],\n",
      "        [ 0.05669948, -0.07024339,  0.04656982, ...,  0.00462204,\n",
      "         -0.0312833 , -0.13690758],\n",
      "        [-0.06507859,  0.05880201, -0.00196971, ...,  0.05611414,\n",
      "         -0.0817123 , -0.07474616]],\n",
      "\n",
      "       [[-0.03111336, -0.04834366,  0.12649569, ...,  0.04732715,\n",
      "         -0.06876956, -0.11491772],\n",
      "        [ 0.02760637, -0.04536919, -0.08934522, ..., -0.00672352,\n",
      "         -0.09222461,  0.12404883],\n",
      "        [-0.08947303,  0.13168111, -0.08507116, ..., -0.02763224,\n",
      "         -0.00864954,  0.07132255],\n",
      "        ...,\n",
      "        [ 0.06226806, -0.05504025, -0.09308472, ...,  0.10134175,\n",
      "         -0.01853757, -0.08160214],\n",
      "        [-0.07546625, -0.05198357, -0.07971375, ...,  0.01996674,\n",
      "          0.06563491, -0.14051774],\n",
      "        [ 0.05299592,  0.05111144,  0.03027758, ...,  0.12154225,\n",
      "         -0.1416109 ,  0.13730001]],\n",
      "\n",
      "       [[-0.02436007, -0.05467168, -0.01415098, ...,  0.0775883 ,\n",
      "         -0.06642915,  0.04322411],\n",
      "        [ 0.0544616 , -0.03815228, -0.06145788, ...,  0.09597249,\n",
      "         -0.0636359 ,  0.13299483],\n",
      "        [-0.0138222 ,  0.13009188, -0.02422792, ..., -0.03079422,\n",
      "          0.13336527, -0.136346  ],\n",
      "        ...,\n",
      "        [ 0.07430813,  0.01923439, -0.04938871, ..., -0.0327998 ,\n",
      "         -0.14211085, -0.14044651],\n",
      "        [ 0.05265699,  0.04702891, -0.03649229, ...,  0.01168782,\n",
      "         -0.13068204,  0.11297807],\n",
      "        [-0.00451636, -0.00361623, -0.08383288, ...,  0.09632061,\n",
      "         -0.0375907 ,  0.00416446]]], dtype=float32)>, <tf.Variable 'conv1d_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_3/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[-0.05719381, -0.05101882,  0.012225  , ..., -0.03054582,\n",
      "         -0.09828106, -0.04506325],\n",
      "        [-0.07928865, -0.06116604, -0.06852818, ..., -0.00753083,\n",
      "          0.04727361,  0.0045136 ],\n",
      "        [-0.06108965, -0.07228133, -0.08408074, ..., -0.09751162,\n",
      "          0.06059667, -0.05299062],\n",
      "        ...,\n",
      "        [-0.06744473,  0.04677835, -0.09650285, ..., -0.05113776,\n",
      "          0.02925095,  0.00870124],\n",
      "        [ 0.0342845 , -0.01926918, -0.08732004, ...,  0.0971967 ,\n",
      "          0.05642465, -0.05485035],\n",
      "        [-0.0286232 ,  0.09480208, -0.00929033, ..., -0.00609167,\n",
      "          0.01040773, -0.06718225]],\n",
      "\n",
      "       [[-0.05477586,  0.08306783, -0.04209807, ...,  0.09337373,\n",
      "         -0.07445718,  0.05353503],\n",
      "        [ 0.00096723,  0.0841918 ,  0.08626904, ...,  0.07792325,\n",
      "          0.05810036, -0.05420982],\n",
      "        [-0.06268586,  0.08578171, -0.02671971, ...,  0.06589535,\n",
      "          0.0369948 , -0.07335478],\n",
      "        ...,\n",
      "        [-0.07873604, -0.02636804, -0.04939819, ..., -0.03769704,\n",
      "          0.0259966 ,  0.08698322],\n",
      "        [-0.04523173, -0.00717006, -0.08319619, ...,  0.09916782,\n",
      "          0.04614815,  0.09045257],\n",
      "        [ 0.02698906,  0.03885539,  0.02422388, ...,  0.07779501,\n",
      "         -0.09280766, -0.05612292]],\n",
      "\n",
      "       [[-0.0171676 ,  0.03726043,  0.0008388 , ..., -0.03686985,\n",
      "          0.00199386,  0.05168766],\n",
      "        [-0.07792003,  0.05443738, -0.00280093, ..., -0.08405709,\n",
      "         -0.10024877, -0.06669864],\n",
      "        [ 0.10173866, -0.01060904, -0.00311172, ..., -0.0499216 ,\n",
      "         -0.05100809,  0.01901704],\n",
      "        ...,\n",
      "        [ 0.02753934, -0.08873932, -0.10188559, ...,  0.0261149 ,\n",
      "         -0.01604611, -0.01256348],\n",
      "        [ 0.00293418,  0.00071988,  0.02472809, ...,  0.02140946,\n",
      "          0.00378364,  0.09025601],\n",
      "        [-0.03630543,  0.09291385,  0.05151236, ..., -0.03520001,\n",
      "         -0.08463886,  0.07803258]]], dtype=float32)>, <tf.Variable 'conv1d_3/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_4/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_4/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[ 0.0014028 , -0.00327466,  0.05777228, ..., -0.05113369,\n",
      "          0.05790333, -0.06449512],\n",
      "        [-0.04304564,  0.0500759 ,  0.0226683 , ...,  0.00238816,\n",
      "         -0.01664963,  0.03099005],\n",
      "        [ 0.03261579,  0.00233391, -0.00588111, ...,  0.02126995,\n",
      "          0.0360772 , -0.01407466],\n",
      "        ...,\n",
      "        [ 0.05058089, -0.06460847, -0.04622865, ..., -0.06693096,\n",
      "          0.01286891,  0.01272183],\n",
      "        [ 0.06309436, -0.02972237, -0.05855979, ..., -0.01514256,\n",
      "          0.01054592, -0.06811769],\n",
      "        [-0.02252585, -0.03943948, -0.05271026, ..., -0.05616391,\n",
      "         -0.06051903, -0.02906863]],\n",
      "\n",
      "       [[-0.07010386, -0.06880215, -0.00551531, ...,  0.04988633,\n",
      "          0.02946518, -0.00177781],\n",
      "        [-0.03714979,  0.0510658 , -0.02393967, ..., -0.02624212,\n",
      "          0.0240758 ,  0.00244004],\n",
      "        [-0.0589388 ,  0.0141404 , -0.03781707, ...,  0.00700833,\n",
      "         -0.02962047, -0.04921845],\n",
      "        ...,\n",
      "        [-0.00526928, -0.04968227, -0.06840379, ...,  0.03903775,\n",
      "         -0.05177021, -0.05822339],\n",
      "        [-0.0213994 , -0.05534967,  0.05611572, ..., -0.04111874,\n",
      "         -0.06949868, -0.05579456],\n",
      "        [-0.00142391, -0.01179294, -0.04292563, ..., -0.02658456,\n",
      "          0.00887501, -0.00513875]],\n",
      "\n",
      "       [[-0.03525539,  0.01036256,  0.04727145, ..., -0.06736356,\n",
      "          0.03928779, -0.05458701],\n",
      "        [ 0.02705476, -0.00144637, -0.07213819, ...,  0.06480356,\n",
      "         -0.06101358,  0.02509488],\n",
      "        [-0.01463845, -0.05433002, -0.00809407, ...,  0.05004546,\n",
      "          0.06226857, -0.05270563],\n",
      "        ...,\n",
      "        [ 0.0396006 , -0.02353874, -0.03412472, ..., -0.06025703,\n",
      "         -0.0075739 , -0.02977197],\n",
      "        [ 0.06455286, -0.00958154,  0.00104011, ..., -0.06172103,\n",
      "         -0.04176369,  0.01659898],\n",
      "        [-0.03603363,  0.00605161, -0.06724975, ...,  0.03959572,\n",
      "         -0.00364942, -0.04425033]]], dtype=float32)>, <tf.Variable 'conv1d_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_5/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_5/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv1d_transpose/kernel:0' shape=(3, 128, 256) dtype=float32, numpy=\n",
      "array([[[ 0.02362145,  0.00842507, -0.02127202, ..., -0.06687323,\n",
      "         -0.01579386, -0.01291824],\n",
      "        [ 0.06081691, -0.04229695,  0.03040068, ..., -0.00440781,\n",
      "          0.02097602, -0.01414753],\n",
      "        [-0.01107014, -0.04350543, -0.06350255, ..., -0.03048908,\n",
      "         -0.02381313, -0.05394334],\n",
      "        ...,\n",
      "        [ 0.03505827, -0.04443647, -0.05340237, ...,  0.02973609,\n",
      "         -0.01873012, -0.06804352],\n",
      "        [-0.04253876, -0.02275747,  0.03662383, ...,  0.00421508,\n",
      "         -0.05576823, -0.06184779],\n",
      "        [ 0.03906708, -0.01627104, -0.03280164, ..., -0.07071223,\n",
      "          0.05617854,  0.03827492]],\n",
      "\n",
      "       [[ 0.04810745, -0.00277466, -0.05793441, ..., -0.00882999,\n",
      "         -0.05556432, -0.00904588],\n",
      "        [-0.0613953 ,  0.02640627, -0.05473554, ..., -0.06840786,\n",
      "         -0.00533873,  0.02384923],\n",
      "        [ 0.03624813, -0.03277879, -0.03155075, ..., -0.03485303,\n",
      "         -0.05136462,  0.0227892 ],\n",
      "        ...,\n",
      "        [-0.03065552,  0.01335254, -0.04150259, ...,  0.01258442,\n",
      "         -0.03166908,  0.06375585],\n",
      "        [-0.05135343,  0.01464985,  0.0166853 , ..., -0.02523933,\n",
      "         -0.01086517,  0.06868967],\n",
      "        [ 0.01349333,  0.03581619,  0.01094861, ..., -0.0639893 ,\n",
      "          0.05884984, -0.05761169]],\n",
      "\n",
      "       [[ 0.04994645, -0.05102053,  0.05628674, ..., -0.04315387,\n",
      "         -0.06854992,  0.04942078],\n",
      "        [ 0.00537921,  0.03099319,  0.02228095, ..., -0.01277483,\n",
      "          0.04509953, -0.02043101],\n",
      "        [ 0.03017625, -0.05908803,  0.03962297, ...,  0.00952978,\n",
      "          0.05778265, -0.04434839],\n",
      "        ...,\n",
      "        [-0.04199284, -0.00399971,  0.01480315, ...,  0.03784621,\n",
      "          0.05505167,  0.05499527],\n",
      "        [ 0.03958773,  0.06838201, -0.02015782, ..., -0.03606959,\n",
      "         -0.00531028,  0.0104429 ],\n",
      "        [ 0.02577689,  0.04362736,  0.00796101, ..., -0.06953502,\n",
      "         -0.06290171, -0.00679888]]], dtype=float32)>, <tf.Variable 'conv1d_transpose/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_6/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_6/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/kernel:0' shape=(3, 64, 128) dtype=float32, numpy=\n",
      "array([[[ 0.06572463, -0.01294693,  0.06236497, ...,  0.02887076,\n",
      "         -0.05510045, -0.08677252],\n",
      "        [ 0.05977665, -0.08508961, -0.04710904, ...,  0.0103129 ,\n",
      "         -0.09781644, -0.08135826],\n",
      "        [-0.07912576,  0.0717943 , -0.08823379, ..., -0.05298018,\n",
      "          0.05258575, -0.02968784],\n",
      "        ...,\n",
      "        [ 0.00266318,  0.05034839, -0.06755643, ...,  0.03756063,\n",
      "         -0.04614915, -0.08828998],\n",
      "        [-0.09519806,  0.04127759, -0.01719356, ...,  0.0940256 ,\n",
      "         -0.00159027,  0.01414776],\n",
      "        [ 0.08888739, -0.0382541 , -0.07396314, ...,  0.01738061,\n",
      "          0.04691084, -0.09073658]],\n",
      "\n",
      "       [[-0.04898573, -0.01673134, -0.05288308, ..., -0.07201977,\n",
      "         -0.0081462 , -0.08983829],\n",
      "        [-0.06892608, -0.05923542, -0.09095337, ...,  0.02542634,\n",
      "         -0.03884181, -0.0393506 ],\n",
      "        [-0.01571038,  0.00685954,  0.02724174, ...,  0.03964919,\n",
      "          0.02075445, -0.01967246],\n",
      "        ...,\n",
      "        [ 0.0994883 ,  0.01340569, -0.01592087, ...,  0.01615199,\n",
      "         -0.01756664,  0.0935338 ],\n",
      "        [-0.04525539,  0.00605004,  0.06795414, ...,  0.06303081,\n",
      "          0.03748283,  0.090654  ],\n",
      "        [-0.04691933, -0.02440728, -0.09302155, ...,  0.04014908,\n",
      "          0.01492563, -0.09923087]],\n",
      "\n",
      "       [[ 0.08139792,  0.05636445, -0.04130173, ..., -0.04395586,\n",
      "          0.02279   ,  0.01152223],\n",
      "        [-0.09376565,  0.04634607,  0.0272852 , ..., -0.02702911,\n",
      "         -0.02412788, -0.00924936],\n",
      "        [-0.0382489 ,  0.07729085, -0.0353445 , ...,  0.09763321,\n",
      "         -0.0314307 , -0.10054635],\n",
      "        ...,\n",
      "        [ 0.05664341, -0.07488684, -0.02387274, ..., -0.00540615,\n",
      "          0.03312908,  0.03114551],\n",
      "        [-0.00562669, -0.01580881,  0.05686682, ..., -0.0368863 ,\n",
      "          0.03021176, -0.04691079],\n",
      "        [-0.04473124, -0.00018398,  0.09263635, ...,  0.03345717,\n",
      "         -0.0127828 , -0.0769975 ]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_7/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\n",
      "array([[[ 0.05883893,  0.07012397, -0.03888432, ..., -0.07370187,\n",
      "          0.1299746 ,  0.1425322 ],\n",
      "        [ 0.13213325,  0.11125496, -0.02922335, ...,  0.02581546,\n",
      "          0.04110029, -0.12403394],\n",
      "        [-0.08028992,  0.00961018, -0.14331901, ...,  0.04059932,\n",
      "          0.11591271,  0.13534516],\n",
      "        ...,\n",
      "        [ 0.08842185,  0.07882428, -0.11013751, ...,  0.00332682,\n",
      "         -0.01205531, -0.00796489],\n",
      "        [ 0.03126657,  0.03283466,  0.03432187, ..., -0.12289119,\n",
      "          0.06627308, -0.0739729 ],\n",
      "        [-0.08079957,  0.07412405, -0.14170481, ..., -0.00628123,\n",
      "         -0.08081964, -0.04522428]],\n",
      "\n",
      "       [[-0.07092569,  0.07758184, -0.04323512, ..., -0.04418154,\n",
      "          0.01152632, -0.0165716 ],\n",
      "        [-0.00463925,  0.00136687, -0.0793476 , ..., -0.10347159,\n",
      "          0.06388704, -0.05442663],\n",
      "        [ 0.12652108, -0.06537388, -0.10329974, ..., -0.10550721,\n",
      "         -0.03122032,  0.07055506],\n",
      "        ...,\n",
      "        [-0.0552481 ,  0.11829823, -0.04666253, ..., -0.05526929,\n",
      "          0.14297101, -0.13473193],\n",
      "        [ 0.13413408, -0.06111362,  0.05065373, ...,  0.00105155,\n",
      "          0.03247353, -0.12419513],\n",
      "        [ 0.04939377,  0.01130432,  0.01522712, ...,  0.09843266,\n",
      "         -0.03600097, -0.11040118]],\n",
      "\n",
      "       [[-0.05618615,  0.09145655,  0.0321153 , ...,  0.13790128,\n",
      "          0.03616112,  0.01816797],\n",
      "        [ 0.06067124,  0.09396693, -0.02797771, ..., -0.06398171,\n",
      "         -0.00043625,  0.09039089],\n",
      "        [ 0.09202945, -0.03543096,  0.05264333, ...,  0.01748168,\n",
      "         -0.00038663,  0.0301051 ],\n",
      "        ...,\n",
      "        [-0.12354903,  0.05913013, -0.11726181, ..., -0.08532681,\n",
      "          0.03254996, -0.08767751],\n",
      "        [ 0.10417475, -0.05905415, -0.07546212, ..., -0.14173923,\n",
      "         -0.06179237,  0.0440971 ],\n",
      "        [-0.03902389, -0.02664931,  0.14223418, ...,  0.13440418,\n",
      "         -0.04274712, -0.04076721]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_8/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_3/kernel:0' shape=(3, 16, 32) dtype=float32, numpy=\n",
      "array([[[-0.14907274, -0.1656893 , -0.03806707, ..., -0.1736541 ,\n",
      "          0.13922775,  0.03267682],\n",
      "        [ 0.01406053, -0.18775038,  0.17467025, ...,  0.13262683,\n",
      "          0.1728014 ,  0.07045835],\n",
      "        [ 0.04169296,  0.00630198,  0.1393669 , ..., -0.20390412,\n",
      "         -0.03933845,  0.05041218],\n",
      "        ...,\n",
      "        [ 0.01587142,  0.05968052, -0.01839739, ...,  0.1695131 ,\n",
      "         -0.01568231, -0.10322969],\n",
      "        [ 0.05690345,  0.14470571, -0.17150554, ..., -0.16642052,\n",
      "          0.18100315, -0.02753179],\n",
      "        [-0.04907949, -0.10782862,  0.05934033, ..., -0.12259998,\n",
      "         -0.15065631, -0.16362941]],\n",
      "\n",
      "       [[-0.12406296, -0.10062713, -0.04490916, ..., -0.18441635,\n",
      "          0.16957489, -0.0635038 ],\n",
      "        [ 0.19931382,  0.06122282,  0.07681695, ..., -0.10401879,\n",
      "         -0.1378528 , -0.10004775],\n",
      "        [ 0.06653669, -0.189263  , -0.08017196, ...,  0.10006326,\n",
      "         -0.18414874, -0.1070119 ],\n",
      "        ...,\n",
      "        [ 0.04588223,  0.1900937 , -0.02979986, ..., -0.1995424 ,\n",
      "         -0.09376226, -0.02955464],\n",
      "        [ 0.10231486, -0.00196405, -0.18180892, ...,  0.06930637,\n",
      "         -0.03687809, -0.06415093],\n",
      "        [-0.02737013,  0.12994373,  0.15128878, ...,  0.08471537,\n",
      "          0.0109528 , -0.05778486]],\n",
      "\n",
      "       [[ 0.04186928,  0.06979626,  0.19340983, ...,  0.17040047,\n",
      "         -0.12169351, -0.1796686 ],\n",
      "        [-0.00573984,  0.09189826,  0.07204929, ...,  0.1293498 ,\n",
      "          0.04055615,  0.17391822],\n",
      "        [ 0.16716751, -0.01531453, -0.1390342 , ..., -0.08878703,\n",
      "          0.18211815, -0.13765293],\n",
      "        ...,\n",
      "        [ 0.1055446 , -0.05903807, -0.01741335, ...,  0.14452061,\n",
      "         -0.13747358,  0.12573004],\n",
      "        [-0.18924038, -0.18575032, -0.05199358, ..., -0.19245088,\n",
      "         -0.19336797, -0.00650857],\n",
      "        [-0.12230516,  0.03349929,  0.12408242, ..., -0.06504644,\n",
      "         -0.18395305, -0.20192334]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_3/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/gamma:0' shape=(16,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_9/beta:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_4/kernel:0' shape=(3, 8, 16) dtype=float32, numpy=\n",
      "array([[[ 0.22499609, -0.06763174,  0.01454091,  0.11335942,\n",
      "         -0.10956904,  0.11375844,  0.09775534, -0.13733836,\n",
      "          0.2357505 ,  0.06770089,  0.16560298,  0.04256955,\n",
      "         -0.23154046, -0.02990627,  0.00521579, -0.0221042 ],\n",
      "        [ 0.2785685 ,  0.21741533,  0.10424146, -0.08833081,\n",
      "          0.02285123,  0.03428116,  0.01824969,  0.28108227,\n",
      "         -0.19369042,  0.12968117,  0.16679513, -0.09466144,\n",
      "         -0.01737052,  0.22788584, -0.27543625,  0.2702837 ],\n",
      "        [-0.17592695,  0.15992737,  0.15646675,  0.05412424,\n",
      "          0.07077926,  0.21018183, -0.21106535,  0.03284231,\n",
      "          0.07305133,  0.07557827,  0.11561   ,  0.14568543,\n",
      "         -0.03916825, -0.09603906, -0.14805627, -0.25612485],\n",
      "        [-0.15205725,  0.06415159, -0.11861135,  0.25272006,\n",
      "          0.24359554, -0.18067577,  0.1724574 ,  0.16421512,\n",
      "         -0.2810236 , -0.09959368,  0.15541688, -0.09485635,\n",
      "         -0.2674881 , -0.10476296,  0.17222339,  0.15267393],\n",
      "        [ 0.1207388 , -0.28810945, -0.20461303,  0.27077526,\n",
      "          0.0084751 , -0.24273232,  0.11289525,  0.11880633,\n",
      "          0.17692432, -0.04256397,  0.22521883, -0.2285025 ,\n",
      "          0.13194373, -0.08666565, -0.05821468, -0.08111912],\n",
      "        [-0.27178025, -0.02495676, -0.11652352, -0.28655103,\n",
      "          0.09446281,  0.00088331, -0.20317855,  0.1206342 ,\n",
      "         -0.1586927 , -0.13295823, -0.06738734, -0.16692403,\n",
      "          0.09615406,  0.06514212,  0.21191335, -0.24703659],\n",
      "        [-0.19236264,  0.05875516, -0.16224039, -0.20821625,\n",
      "         -0.24675633,  0.12182027, -0.1296502 , -0.06129153,\n",
      "          0.24999654,  0.06622651, -0.11932258,  0.14284626,\n",
      "         -0.09644368, -0.15070523, -0.12686077,  0.18498212],\n",
      "        [ 0.08311686,  0.16482556, -0.20229098, -0.07246549,\n",
      "          0.12581119, -0.18085101,  0.07187751,  0.14825442,\n",
      "         -0.26581672,  0.00539488,  0.2118302 , -0.14160575,\n",
      "         -0.22158912,  0.15509066,  0.02990454, -0.23132214]],\n",
      "\n",
      "       [[-0.06319153,  0.02476829,  0.23008567,  0.10960242,\n",
      "         -0.14052112,  0.11820781, -0.16476539, -0.17440799,\n",
      "         -0.06209025, -0.07880536,  0.20131952, -0.10258223,\n",
      "          0.23600936, -0.17665926, -0.05994619,  0.27518153],\n",
      "        [-0.05645943, -0.03557163,  0.07320467,  0.24273401,\n",
      "         -0.05281332,  0.0570302 , -0.10807636,  0.22835839,\n",
      "         -0.05229802,  0.27747762,  0.27905607, -0.03308105,\n",
      "          0.07633093, -0.12008841, -0.21311429, -0.10265332],\n",
      "        [ 0.08119717,  0.06713364,  0.22387677,  0.22449428,\n",
      "         -0.1687307 , -0.24149613,  0.21760136,  0.1589722 ,\n",
      "         -0.10389975, -0.15770541,  0.07211304,  0.24439913,\n",
      "          0.15588972,  0.19890022, -0.2044636 ,  0.19261825],\n",
      "        [-0.08304659, -0.08666673, -0.13927484,  0.15678164,\n",
      "          0.18008119,  0.26853782, -0.22113955, -0.2055834 ,\n",
      "         -0.19608141, -0.13041313,  0.09499565,  0.10157138,\n",
      "         -0.14842333, -0.04827043,  0.15048754, -0.23147397],\n",
      "        [ 0.08772501,  0.08354235, -0.09329072, -0.10889001,\n",
      "         -0.10998999, -0.07721087, -0.05117576, -0.1830948 ,\n",
      "         -0.11475484,  0.09909993, -0.01915333, -0.13883324,\n",
      "          0.04829493, -0.11183086,  0.17878899, -0.28126743],\n",
      "        [-0.00129125,  0.21670502,  0.06784359, -0.01934844,\n",
      "         -0.13638395,  0.20210838, -0.21909136,  0.08198687,\n",
      "          0.02087376,  0.24255699,  0.25190556,  0.23279631,\n",
      "         -0.02983215,  0.15944937,  0.1421937 , -0.24449651],\n",
      "        [ 0.018722  ,  0.2280736 , -0.01374674, -0.25697595,\n",
      "         -0.16554263,  0.05886281,  0.02936503,  0.10016364,\n",
      "          0.09053913,  0.06351748, -0.2540524 , -0.11329018,\n",
      "          0.16584864,  0.01988205,  0.27951205, -0.04945864],\n",
      "        [ 0.06642494,  0.08210051,  0.08035338,  0.24595892,\n",
      "         -0.27964467, -0.15010639,  0.26741213,  0.2295354 ,\n",
      "         -0.07979383,  0.0594669 , -0.06141403,  0.0455887 ,\n",
      "         -0.04916716, -0.22483636, -0.17704193,  0.02426657]],\n",
      "\n",
      "       [[-0.27444965,  0.20900884,  0.12676084, -0.08076261,\n",
      "          0.20721298, -0.16620088,  0.06979209,  0.02892435,\n",
      "         -0.17926162, -0.00135344, -0.01096609,  0.17043036,\n",
      "         -0.18533541, -0.23858447, -0.11532073,  0.01613173],\n",
      "        [-0.0061596 , -0.19591492,  0.23939693, -0.21308386,\n",
      "          0.19626373,  0.09247053,  0.10142457,  0.20264551,\n",
      "          0.15948558,  0.21311808, -0.06625728,  0.0087893 ,\n",
      "         -0.2689074 , -0.14393094,  0.21812767, -0.0109213 ],\n",
      "        [-0.26900673, -0.20127857,  0.11415938, -0.26129282,\n",
      "          0.06610271,  0.04575658, -0.13835098,  0.05262846,\n",
      "          0.26995933,  0.16232029,  0.05055943,  0.19187054,\n",
      "          0.22504944, -0.10695168,  0.14094186, -0.21894304],\n",
      "        [-0.08848298, -0.03246272, -0.00425279, -0.07729332,\n",
      "         -0.22477615, -0.17869739,  0.03857338, -0.15190741,\n",
      "          0.03686535, -0.0923052 ,  0.254937  ,  0.28520083,\n",
      "         -0.06275222, -0.02087238,  0.20573047,  0.02422816],\n",
      "        [-0.14651003,  0.05858186,  0.2688582 ,  0.05769697,\n",
      "          0.28279394, -0.06405564, -0.11235462,  0.05596617,\n",
      "         -0.13829805,  0.08734977,  0.06404048, -0.09905478,\n",
      "         -0.06391646, -0.27958453, -0.01348394, -0.16883641],\n",
      "        [ 0.1844331 , -0.09285545, -0.08955783, -0.14059064,\n",
      "          0.24482143,  0.05981407, -0.26026264, -0.05010077,\n",
      "          0.1815432 ,  0.04196697, -0.20069817, -0.09981503,\n",
      "         -0.01628548,  0.05478799, -0.24312186, -0.01233155],\n",
      "        [ 0.26186013, -0.03659913,  0.27710545,  0.07479584,\n",
      "         -0.03867753,  0.22299421, -0.02953139,  0.1692749 ,\n",
      "         -0.25359443, -0.03114182, -0.02294725,  0.16250178,\n",
      "         -0.05960056, -0.2524135 ,  0.19401672,  0.22187263],\n",
      "        [-0.1253323 , -0.03788018, -0.14539604, -0.1065432 ,\n",
      "         -0.21175092,  0.05257836,  0.25212157, -0.25309804,\n",
      "         -0.2140821 ,  0.23909926,  0.24687988,  0.14010671,\n",
      "         -0.17446442, -0.09003815,  0.24359488,  0.02985388]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_4/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_10/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_10/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_5/kernel:0' shape=(3, 20, 8) dtype=float32, numpy=\n",
      "array([[[-0.14425471,  0.20573553,  0.2646763 ,  0.0348427 ,\n",
      "          0.12562159, -0.06579241, -0.00189835,  0.21304542],\n",
      "        [ 0.11879104,  0.13887128,  0.05814332, -0.20183757,\n",
      "          0.14396402,  0.08994129, -0.17166626, -0.01644608],\n",
      "        [ 0.26572356, -0.20786868, -0.1455699 ,  0.202059  ,\n",
      "          0.20038515, -0.15679216,  0.24145874, -0.2221744 ],\n",
      "        [ 0.06161824,  0.07429227, -0.03948712,  0.03559861,\n",
      "         -0.26616883,  0.22072917,  0.0600116 ,  0.12111312],\n",
      "        [-0.07473858, -0.11198652, -0.2538086 ,  0.05357739,\n",
      "          0.24407598, -0.19844562,  0.22282758,  0.0164097 ],\n",
      "        [-0.20455939,  0.12655291, -0.09391537, -0.13905096,\n",
      "         -0.01686275,  0.06042477, -0.15690067,  0.0391598 ],\n",
      "        [-0.18110237, -0.04988942,  0.0495559 ,  0.01197466,\n",
      "         -0.07642251,  0.11342263, -0.23135455,  0.1133891 ],\n",
      "        [ 0.01835239, -0.08199011, -0.1260601 ,  0.03368929,\n",
      "          0.05966273, -0.08711639,  0.2080046 , -0.25526315],\n",
      "        [ 0.03533205,  0.0492222 , -0.13853502,  0.18801045,\n",
      "         -0.17812926,  0.00089285,  0.1137206 ,  0.19329208],\n",
      "        [ 0.26587453,  0.25221702, -0.25081336,  0.26156715,\n",
      "          0.03565282, -0.21183282, -0.20157346, -0.06624623],\n",
      "        [-0.09050286, -0.07651789,  0.23740777,  0.11133695,\n",
      "         -0.0229907 , -0.20267376,  0.1856885 , -0.06853434],\n",
      "        [ 0.13617548, -0.0996974 , -0.02428606, -0.00194201,\n",
      "         -0.02240945,  0.18034685, -0.11766034,  0.07407358],\n",
      "        [-0.15910965, -0.13399695, -0.18377778,  0.0037967 ,\n",
      "         -0.1369765 , -0.04378262,  0.10110524,  0.25399068],\n",
      "        [-0.20959829, -0.26244733, -0.16682035,  0.23594871,\n",
      "          0.06071207, -0.01359996,  0.11203104, -0.06964034],\n",
      "        [ 0.18330371, -0.17862105,  0.03177458,  0.07866609,\n",
      "         -0.13029882, -0.08704738,  0.1844325 ,  0.22386459],\n",
      "        [-0.25895426,  0.26429906,  0.22481266, -0.06709261,\n",
      "         -0.03303343,  0.13725439, -0.18175647,  0.01630595],\n",
      "        [-0.07396367, -0.08250962,  0.10450712, -0.01021343,\n",
      "          0.23674646, -0.24807972, -0.01906899, -0.18416303],\n",
      "        [ 0.18781209,  0.08209327, -0.1715169 ,  0.01760566,\n",
      "          0.20237678, -0.11811721, -0.05691665, -0.23274906],\n",
      "        [-0.03365655,  0.00846654,  0.2474607 ,  0.10796481,\n",
      "          0.07686344, -0.17374596,  0.10664678, -0.10349295],\n",
      "        [-0.12262285,  0.173722  , -0.13812543, -0.20403904,\n",
      "         -0.00272122, -0.03748854, -0.20047836,  0.03680056]],\n",
      "\n",
      "       [[ 0.10120615, -0.23354569, -0.0581049 , -0.11597991,\n",
      "         -0.00875106,  0.16398028, -0.18264185, -0.13146707],\n",
      "        [-0.25576475, -0.02590348,  0.10047057, -0.14850555,\n",
      "          0.17196524,  0.04767299, -0.18379602, -0.21349108],\n",
      "        [ 0.02163869, -0.15558141,  0.05217034,  0.22673789,\n",
      "          0.0135988 ,  0.02738693,  0.02413309,  0.24156454],\n",
      "        [ 0.07472342,  0.08025095,  0.17124978,  0.01709762,\n",
      "          0.10245711, -0.03438959,  0.14322972,  0.06898874],\n",
      "        [-0.0691084 , -0.01177227,  0.18008041,  0.25444868,\n",
      "          0.17112541, -0.16859043,  0.18168795,  0.20865199],\n",
      "        [-0.04539798, -0.04353385, -0.21972679,  0.05293027,\n",
      "         -0.0145357 , -0.23237973, -0.1250913 , -0.11599915],\n",
      "        [ 0.08161065,  0.18103501,  0.15566954,  0.07179371,\n",
      "         -0.23379534, -0.01382145, -0.10829712, -0.21049578],\n",
      "        [ 0.02441618,  0.09588   , -0.04772721, -0.24857068,\n",
      "         -0.22388867, -0.17032948, -0.00034919, -0.1870168 ],\n",
      "        [-0.08579363,  0.2521626 , -0.1484231 , -0.02256595,\n",
      "          0.21018267,  0.11587414, -0.17370066, -0.12842438],\n",
      "        [ 0.073511  ,  0.2394875 , -0.0206112 , -0.05583137,\n",
      "         -0.00144288, -0.03969663,  0.24817702,  0.06881484],\n",
      "        [ 0.16939732, -0.0037407 ,  0.05855069, -0.0839265 ,\n",
      "          0.20669508,  0.08228222, -0.25408393,  0.10024509],\n",
      "        [ 0.12613344, -0.07606   ,  0.01700905,  0.14183858,\n",
      "         -0.21297425,  0.11596793, -0.12449138,  0.0742617 ],\n",
      "        [ 0.17145988,  0.2421079 , -0.04557703, -0.09813263,\n",
      "          0.0158053 ,  0.23068702,  0.2651315 ,  0.20869437],\n",
      "        [-0.08014446,  0.09576052, -0.13795893, -0.26237366,\n",
      "          0.26367566,  0.17871916,  0.04241455, -0.2069353 ],\n",
      "        [-0.00129804,  0.20999616,  0.12450725, -0.077695  ,\n",
      "         -0.18917952, -0.08939368,  0.07086089,  0.1454835 ],\n",
      "        [-0.11468786, -0.0239943 ,  0.09765741,  0.05478925,\n",
      "          0.20607004,  0.2368553 , -0.1575055 ,  0.11429796],\n",
      "        [ 0.25635746,  0.14122987,  0.14465177,  0.07407418,\n",
      "         -0.00254065,  0.07023785, -0.1510513 , -0.19205756],\n",
      "        [ 0.11509165,  0.02460048, -0.07603152,  0.14217076,\n",
      "          0.07397068,  0.11215416, -0.20336398,  0.04698899],\n",
      "        [-0.07221508,  0.03967708,  0.21314603,  0.22365358,\n",
      "         -0.1204953 ,  0.04831401, -0.23695324,  0.02258328],\n",
      "        [ 0.1586301 ,  0.2552648 , -0.20172536, -0.23585248,\n",
      "         -0.11180764,  0.25493553,  0.0751003 ,  0.12994015]],\n",
      "\n",
      "       [[ 0.18047091, -0.1326775 , -0.26424557,  0.1331923 ,\n",
      "         -0.26156226, -0.0671687 ,  0.20050365,  0.19112146],\n",
      "        [ 0.07656378,  0.2649177 ,  0.05915272, -0.01156226,\n",
      "          0.21776116, -0.10538365, -0.23818693,  0.07473162],\n",
      "        [ 0.1833775 ,  0.01662526,  0.03016257,  0.12421498,\n",
      "          0.12909523,  0.12500674, -0.04386239,  0.17744625],\n",
      "        [-0.06132646, -0.1645955 ,  0.02192906,  0.11796772,\n",
      "          0.09220493, -0.10149546, -0.20536837, -0.0344238 ],\n",
      "        [-0.18786217, -0.12298892, -0.00301492,  0.03216219,\n",
      "         -0.14664212, -0.04474504,  0.0508391 , -0.16986948],\n",
      "        [ 0.13783824, -0.11460471,  0.13403887, -0.13340339,\n",
      "         -0.21440354,  0.11627352, -0.00214788, -0.08613791],\n",
      "        [-0.0041796 , -0.13073066, -0.23562953,  0.08113682,\n",
      "         -0.23500755, -0.24169344,  0.15549234,  0.05696061],\n",
      "        [-0.01082337,  0.0963755 , -0.06431526, -0.19528797,\n",
      "          0.2032015 , -0.00915682,  0.17072666, -0.0404751 ],\n",
      "        [-0.23974738, -0.05498518,  0.10483202, -0.02157274,\n",
      "         -0.05146216, -0.20971572, -0.1919883 , -0.07931533],\n",
      "        [-0.07630825, -0.0805629 , -0.11790057, -0.05246995,\n",
      "          0.02748004,  0.11886483,  0.04145989, -0.08089164],\n",
      "        [-0.19168067, -0.24782956,  0.1042667 ,  0.03779313,\n",
      "         -0.22560394,  0.03048232,  0.11010274, -0.02538332],\n",
      "        [ 0.09129953,  0.09356084,  0.08107287, -0.06977759,\n",
      "          0.1015918 , -0.02555831,  0.17285284, -0.22098233],\n",
      "        [-0.04777792,  0.20272174, -0.12148079, -0.13443273,\n",
      "         -0.19960903,  0.24733713, -0.1891926 ,  0.05428037],\n",
      "        [ 0.02178538,  0.02100855,  0.02273193, -0.2166881 ,\n",
      "         -0.05275236, -0.21130095, -0.09186958, -0.16990937],\n",
      "        [-0.12607355, -0.05072001, -0.08665468, -0.12921323,\n",
      "         -0.2501113 ,  0.17616871, -0.18061759, -0.23928419],\n",
      "        [ 0.17685631,  0.15899801, -0.25941482, -0.0853235 ,\n",
      "         -0.13462344,  0.22020328, -0.08677663, -0.23251323],\n",
      "        [-0.02870168, -0.16684705, -0.13287917, -0.19114536,\n",
      "         -0.00899428, -0.2394215 ,  0.25918958,  0.08397976],\n",
      "        [-0.0028832 , -0.11119504,  0.21459025, -0.11924289,\n",
      "          0.13937071,  0.21248072, -0.02005704,  0.15823567],\n",
      "        [ 0.19817215, -0.1377995 , -0.17020205,  0.08608368,\n",
      "          0.07213268, -0.10522453,  0.03362921,  0.14752585],\n",
      "        [-0.11468957,  0.02342787,  0.00863332, -0.18487397,\n",
      "         -0.09795912,  0.15630704, -0.26587877, -0.03207572]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_transpose_5/bias:0' shape=(20,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8f3f7ea323f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-97a188d5a767>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(context, target, weight, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-c5384877c902>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(context, target, weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    511\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1271\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1272\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['first/kernel:0', 'first/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv1d/kernel:0', 'conv1d/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv1d_1/kernel:0', 'conv1d_1/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv1d_2/kernel:0', 'conv1d_2/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv1d_3/kernel:0', 'conv1d_3/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv1d_4/kernel:0', 'conv1d_4/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv1d_transpose/kernel:0', 'conv1d_transpose/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'conv1d_transpose_1/kernel:0', 'conv1d_transpose_1/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv1d_transpose_2/kernel:0', 'conv1d_transpose_2/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv1d_transpose_3/kernel:0', 'conv1d_transpose_3/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv1d_transpose_4/kernel:0', 'conv1d_transpose_4/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv1d_transpose_5/kernel:0', 'conv1d_transpose_5/bias:0']."
     ]
    }
   ],
   "source": [
    "train(train_context, train_target, train_weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
