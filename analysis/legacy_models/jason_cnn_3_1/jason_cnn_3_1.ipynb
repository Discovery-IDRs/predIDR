{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase batch size to 64\n",
    "\n",
    "import os\n",
    "from math import floor\n",
    "\n",
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../../../src')\n",
    "from metrics import *\n",
    "\n",
    "from pandas.core.common import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jason_cnn_3_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Label, batch, and pad protein sequence data.\n",
    "\n",
    "    Only complete batches are returned, so a single epoch may not train on every example.\"\"\"\n",
    "    def __init__(self, records, batch_size, sym_codes, shuffle=True):\n",
    "        self.records = records\n",
    "        self.indices = np.arange(len(self.records))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.ctable = {}  # Category table\n",
    "        for i, sym_code in enumerate(sym_codes):\n",
    "            self.ctable[sym_code] = i\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of batches.\"\"\"\n",
    "        return floor(len(self.records) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        records = [self.records[i] for i in indices]\n",
    "        max_len = max([len(record[0]) for record in records])\n",
    "        x = np.zeros((self.batch_size, max_len))\n",
    "        y = np.zeros((self.batch_size, max_len))\n",
    "        for i, (syms, labels) in enumerate(records):\n",
    "            x[i, :len(syms)] = [self.ctable.get(sym, 0) for sym in syms]\n",
    "            y[i, :len(syms)] = [int(label) for label in labels]\n",
    "\n",
    "        x = keras.utils.to_categorical(x, num_classes=len(self.ctable))\n",
    "        y = keras.utils.to_categorical(y, num_classes=2)\n",
    "        for i, (syms, _) in enumerate(records):\n",
    "            x[i, len(syms):, :] = 0\n",
    "            y[i, len(syms):, :] = 0\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffles data after each epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def load_data(seqs_path, labels_path):\n",
    "    # Load files\n",
    "    seqs = {}\n",
    "    for record in SeqIO.parse(seqs_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        seq = str(record.seq)\n",
    "        seqs[accession] = seq\n",
    "    labels = {}\n",
    "    for record in SeqIO.parse(labels_path, 'fasta'):\n",
    "        accession = record.description.split('|')[0]\n",
    "        label = str(record.seq)\n",
    "        labels[accession] = label\n",
    "\n",
    "    # Bundle seqs and labels into single object\n",
    "    records = []\n",
    "    for accession, seq in seqs.items():\n",
    "        records.append((seq, labels[accession]))\n",
    "\n",
    "    return records\n",
    "\n",
    "def decode_sym(batch, sym_codes):\n",
    "    \"\"\"Decodes residue symbols in batch of proteins from encoded form.\"\"\"\n",
    "    ctable, i = {}, 0\n",
    "    for sym_code in sym_codes:\n",
    "        ctable[i] = sym_code\n",
    "        i += 1\n",
    "        \n",
    "    decoded_sym = []\n",
    "    for protein in batch:\n",
    "        decoded_protein = []\n",
    "        for residue in protein:\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = ctable[np.argmax(residue)]\n",
    "                decoded_protein.append(decoded_residue)\n",
    "        decoded_sym.append(\"\".join(decoded_protein))\n",
    "                           \n",
    "    return decoded_sym\n",
    "\n",
    "def decode_label_by_protein(batch_to_be_decoded, original_batch):\n",
    "    \"\"\"\n",
    "    Decodes residue labels in batch of proteins from encoded form.\n",
    "    Outputs list of str where each str is labels of one protein.\n",
    "    \n",
    "    batch_to_be_decoded:\n",
    "    batch of labels which want to be decoded\n",
    "    \n",
    "    original_batch:\n",
    "    original batch of labels generated by BatchGenerator which\n",
    "    batch_to_be_decoded is derived from (this is needed in order\n",
    "    to remove unwanted masked values)\n",
    "    \"\"\"\n",
    "    decoded_labels = []\n",
    "    for x in np.arange(len(original_batch)):\n",
    "        protein = original_batch[x]\n",
    "        decoded_protein = []\n",
    "        for y in np.arange(len(protein)):\n",
    "            residue = protein[y]\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = np.argmax(batch_to_be_decoded[x][y])\n",
    "                decoded_protein.append(str(decoded_residue))\n",
    "        decoded_labels.append(\"\".join(decoded_protein))\n",
    "    return decoded_labels\n",
    "\n",
    "def decode_label_to_lst(batch_to_be_decoded, original_batch):\n",
    "    \"\"\"\n",
    "    Decodes residue labels in batch of proteins from encoded form.\n",
    "    Outputs list of int where each int is label for one residue.\n",
    "    \n",
    "    batch_to_be_decoded:\n",
    "    batch of labels which want to be decoded\n",
    "    \n",
    "    original_batch:\n",
    "    original batch of labels generated by BatchGenerator which\n",
    "    batch_to_be_decoded is derived from (this is needed in order\n",
    "    to remove unwanted masked values)\n",
    "    \"\"\"\n",
    "    decoded_labels = []\n",
    "    for x in np.arange(len(original_batch)):\n",
    "        protein = original_batch[x]\n",
    "        for y in np.arange(len(protein)):\n",
    "            residue = protein[y]\n",
    "            if sum(residue) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                decoded_residue = np.argmax(batch_to_be_decoded[x][y])\n",
    "                decoded_labels.append(decoded_residue)\n",
    "    return decoded_labels\n",
    "                           \n",
    "class MaskedConv1D(keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(filters, kernel_size, **kwargs)\n",
    "        self.supports_masking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sym_codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_records = load_data('../../mobidb_validation/split_data/out/train_as_fasta.fasta', '../../mobidb_validation/split_data/out/train_labels_as_fasta.fasta')\n",
    "validation_records = load_data('../../mobidb_validation/split_data/out/val_as_fasta.fasta', '../../mobidb_validation/split_data/out/val_labels_as_fasta.fasta')\n",
    "test_records = load_data('../../mobidb_validation/split_data/out/test_as_fasta.fasta', '../../mobidb_validation/split_data/out/test_labels_as_fasta.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch data\n",
    "train_batches = BatchGenerator(train_records, 64, sym_codes)\n",
    "validation_batches = BatchGenerator(validation_records, 32, sym_codes)\n",
    "test_batches = BatchGenerator(test_records, 32, sym_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "inputs = keras.layers.Input(shape=(None, 20), name='input1')\n",
    "x = layers.Masking(mask_value=0, name='mask1')(inputs)\n",
    "x = MaskedConv1D(128, 20, padding='same', activation='relu', name='conv1d1')(x)\n",
    "x = MaskedConv1D(128, 20, padding='same', activation='relu', name='conv1d2')(x)\n",
    "outputs = layers.Dense(2, activation='softmax', name='dense1')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Epochs are written explicitly in a training loop since Keras\n",
    "# does not support generators for calculating validation metrics\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "histories = []\n",
    "\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Fit\n",
    "    print(f'EPOCH {i}')\n",
    "    history = model.fit(train_batches, epochs=1)\n",
    "    histories.append(history)\n",
    "\n",
    "    # Evaluate\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for batch in validation_batches:\n",
    "        true_labels.append(decode_label_to_lst(batch[1], batch[1]))\n",
    "        pred_labels.append(decode_label_to_lst(model.predict(batch[0]), batch[1]))\n",
    "    true_labels = list(flatten(true_labels))\n",
    "    pred_labels = list(flatten(pred_labels))\n",
    "    \n",
    "    batch_metrics_df = get_binary_metrics(true_labels, pred_labels)\n",
    "    print(\"Label Accuracy:\", batch_metrics_df.loc[0].at[\"Accuracy\"])\n",
    "    \n",
    "    metrics_df = metrics_df.append(batch_metrics_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy = (metrics_df[\"Sensitivity\"].values[49]+metrics_df[\"Specificity\"].values[49])/2\n",
    "balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_ticks = np.arange(num_epochs)\n",
    "y_axis_ticks = np.arange(11)/10\n",
    "\n",
    "metrics_fig = metrics_df.plot(figsize = (12, 5), use_index = True, title = model_name + \" training metrics\", \n",
    "                              xticks = x_axis_ticks, yticks = y_axis_ticks)\n",
    "\n",
    "metrics_fig = metrics_fig.legend(bbox_to_anchor=(1, 1))\n",
    "metrics_fig = metrics_fig.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "if not os.path.exists('out_model/'):\n",
    "    os.mkdir('out_model/')\n",
    "\n",
    "model.save('out_model/' + model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics df\n",
    "if not os.path.exists('out_metrics/'):\n",
    "    os.mkdir('out_metrics/')\n",
    "\n",
    "metrics_df.to_csv(\"out_metrics/training_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"out_model/\" + model_name + \".h5\", custom_objects={\"MaskedConv1D\": MaskedConv1D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv (\"out_metrics/training_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-outreach",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
